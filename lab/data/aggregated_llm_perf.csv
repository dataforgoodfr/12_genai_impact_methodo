model,parameters_count,gpu,energy_per_token,throughput,latency,experiment_name
EleutherAI/gpt-neox-20b,20.0,NVIDIA A100-SXM4-80GB,0.00327,27.4,9.34,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.00179,42.3,6.05,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00183,39.9,6.41,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.0012100000000000001,54.8,4.67,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.0023,30.8,8.31,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-12b,12.0,NVIDIA A100-SXM4-80GB,0.0022800000000000003,36.6,6.99,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00119,55.5,4.61,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-12b-deduped,12.0,NVIDIA A100-SXM4-80GB,0.00226,36.6,7.0,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.000821,81.3,3.15,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.000545,114.0,2.25,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/polyglot-ko-12.8b,12.8,NVIDIA A100-SXM4-80GB,0.00251,33.4,7.67,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.00117,54.5,4.7,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.00113,60.8,4.21,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.000581,107.0,2.4,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.0011799999999999998,55.5,4.61,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.000589,106.0,2.42,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.00161,42.5,6.03,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.00162,42.2,6.07,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.000314,198.0,1.29,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00155,45.5,5.63,pytorch+cuda+float16+gptq-4bit+exllama-v1
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.00129,50.8,5.04,pytorch+cuda+float16+gptq-4bit+exllama-v1
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.00142,46.2,5.54,pytorch+cuda+float16+gptq-4bit+exllama-v1
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.0013599999999999999,52.2,4.9,pytorch+cuda+float16+gptq-4bit+exllama-v1
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.00137,50.4,5.08,pytorch+cuda+float16+gptq-4bit+exllama-v1
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.000761,85.9,2.98,pytorch+cuda+float16+gptq-4bit+exllama-v1
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.0019700000000000004,39.1,6.54,pytorch+cuda+float16+gptq-4bit+exllama-v1
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.000312,198.0,1.29,pytorch+cuda+float16+gptq-4bit+exllama-v1
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000314,200.0,1.28,pytorch+cuda+float16+gptq-4bit+exllama-v1
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.000312,200.0,1.28,pytorch+cuda+float16+gptq-4bit+exllama-v1
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000305,203.0,1.26,pytorch+cuda+float16+gptq-4bit+exllama-v1
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.000309,202.0,1.27,pytorch+cuda+float16+gptq-4bit+exllama-v1
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.00128,48.1,5.32,pytorch+cuda+float16+gptq-4bit+exllama-v1
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.00129,48.9,5.24,pytorch+cuda+float16+gptq-4bit+exllama-v1
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.00131,50.4,5.08,pytorch+cuda+float16+gptq-4bit+exllama-v1
robowaifudev/megatron-gpt2-345m,0.345,NVIDIA A100-SXM4-80GB,0.0009609999999999999,64.8,3.95,pytorch+cuda+float16+gptq-4bit+exllama-v1
meta-llama/Llama-2-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.0019,40.1,6.38,pytorch+cuda+float16+gptq-4bit+exllama-v1
meta-llama/Llama-2-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.00266,31.8,8.06,pytorch+cuda+float16+gptq-4bit+exllama-v1
meta-llama/Llama-2-70b-hf,70.0,NVIDIA A100-SXM4-80GB,0.00812,13.1,19.6,pytorch+cuda+float16+gptq-4bit+exllama-v1
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.001,76.2,3.36,pytorch+cuda+float16+gptq-4bit+exllama-v1
mistralai/Mistral-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00234,31.7,8.08,pytorch+cuda+float16+gptq-4bit+exllama-v1
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.0019,37.2,6.88,pytorch+cuda+float16+gptq-4bit+exllama-v1
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.00189,37.0,6.92,pytorch+cuda+float16+gptq-4bit+exllama-v1
matsuo-lab/weblab-10b,10.0,NVIDIA A100-SXM4-80GB,0.00217,36.4,7.04,pytorch+cuda+float16+gptq-4bit+exllama-v1
augmxnt/shisa-base-7b-v1,7.0,NVIDIA A100-SXM4-80GB,0.00231,32.4,7.91,pytorch+cuda+float16+gptq-4bit+exllama-v1
AI-Sweden-Models/gpt-sw3-126m,0.126,NVIDIA A100-SXM4-80GB,0.000441,143.0,1.79,pytorch+cuda+float16+gptq-4bit+exllama-v1
AI-Sweden-Models/gpt-sw3-6.7b-v2,6.7,NVIDIA A100-SXM4-80GB,0.0014500000000000001,57.8,4.43,pytorch+cuda+float16+gptq-4bit+exllama-v1
AI-Sweden-Models/gpt-sw3-40b,40.0,NVIDIA A100-SXM4-80GB,0.00452,23.1,11.1,pytorch+cuda+float16+gptq-4bit+exllama-v1
AI-Sweden-Models/gpt-sw3-20b,20.0,NVIDIA A100-SXM4-80GB,0.0027300000000000002,34.7,7.37,pytorch+cuda+float16+gptq-4bit+exllama-v1
AI-Sweden-Models/gpt-sw3-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00146,54.6,4.69,pytorch+cuda+float16+gptq-4bit+exllama-v1
AI-Sweden-Models/gpt-sw3-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00094,75.5,3.39,pytorch+cuda+float16+gptq-4bit+exllama-v1
AI-Sweden-Models/gpt-sw3-356m,0.356,NVIDIA A100-SXM4-80GB,0.000857,75.5,3.39,pytorch+cuda+float16+gptq-4bit+exllama-v1
uukuguy/Orca-2-7b-f16,7.0,NVIDIA A100-SXM4-80GB,0.00191,40.1,6.39,pytorch+cuda+float16+gptq-4bit+exllama-v1
01-ai/Yi-34B-200K,34.0,NVIDIA A100-SXM4-80GB,0.00503,19.1,13.4,pytorch+cuda+float16+gptq-4bit+exllama-v1
01-ai/Yi-34B,34.0,NVIDIA A100-SXM4-80GB,0.00505,19.4,13.2,pytorch+cuda+float16+gptq-4bit+exllama-v1
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.00203,36.5,7.01,pytorch+cuda+float16+gptq-4bit+exllama-v1
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.00202,36.7,6.97,pytorch+cuda+float16+gptq-4bit+exllama-v1
scb10x/typhoon-7b,7.0,NVIDIA A100-SXM4-80GB,0.00231,32.0,8.0,pytorch+cuda+float16+gptq-4bit+exllama-v1
TheBloke/Llama-2-13B-fp16,13.0,NVIDIA A100-SXM4-80GB,0.00263,31.6,8.1,pytorch+cuda+float16+gptq-4bit+exllama-v1
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.0026699999999999996,26.4,9.7,pytorch+cuda+float16+gptq-4bit+exllama-v1
Salesforce/codegen-16B-nl,16.0,NVIDIA A100-SXM4-80GB,0.00318,26.2,9.76,pytorch+cuda+float16+gptq-4bit+exllama-v1
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.00265,27.1,9.44,pytorch+cuda+float16+gptq-4bit+exllama-v1
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.0019,39.3,6.52,pytorch+cuda+float16+gptq-4bit+exllama-v1
deepseek-ai/deepseek-llm-67b-base,67.0,NVIDIA A100-SXM4-80GB,0.0085,12.0,21.3,pytorch+cuda+float16+gptq-4bit+exllama-v1
cyberagent/calm2-7b-chat,7.0,NVIDIA A100-SXM4-80GB,0.0019199999999999998,39.3,6.51,pytorch+cuda+float16+gptq-4bit+exllama-v1
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.00203,37.1,6.9,pytorch+cuda+float16+gptq-4bit+exllama-v1
cerebras/Cerebras-GPT-111M,0.111,NVIDIA A100-SXM4-80GB,0.000374,166.0,1.54,pytorch+cuda+float16+gptq-4bit+exllama-v1
cerebras/Cerebras-GPT-13B,13.0,NVIDIA A100-SXM4-80GB,0.00203,44.6,5.74,pytorch+cuda+float16+gptq-4bit+exllama-v1
cerebras/Cerebras-GPT-6.7B,6.7,NVIDIA A100-SXM4-80GB,0.00143,55.3,4.63,pytorch+cuda+float16+gptq-4bit+exllama-v1
cerebras/Cerebras-GPT-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.0012300000000000002,57.4,4.46,pytorch+cuda+float16+gptq-4bit+exllama-v1
cerebras/Cerebras-GPT-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.00091,77.1,3.32,pytorch+cuda+float16+gptq-4bit+exllama-v1
itsliupeng/openllama-7b-base,7.0,NVIDIA A100-SXM4-80GB,0.0019,39.6,6.47,pytorch+cuda+float16+gptq-4bit+exllama-v1
itsliupeng/openllama-7b-icl,7.0,NVIDIA A100-SXM4-80GB,0.00195,39.0,6.57,pytorch+cuda+float16+gptq-4bit+exllama-v1
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.000314,202.0,1.27,pytorch+cuda+float16+gptq-4bit+exllama-v1
tiiuae/falcon-rw-1b,1.0,NVIDIA A100-SXM4-80GB,0.000972,69.9,3.66,pytorch+cuda+float16+gptq-4bit+exllama-v1
tiiuae/falcon-40b,40.0,NVIDIA A100-SXM4-80GB,0.00617,15.1,16.9,pytorch+cuda+float16+gptq-4bit+exllama-v1
facebook/xglm-7.5B,7.5,NVIDIA A100-SXM4-80GB,0.0015799999999999998,51.9,4.93,pytorch+cuda+float16+gptq-4bit+exllama-v1
facebook/xglm-564M,0.564,NVIDIA A100-SXM4-80GB,0.000958,71.3,3.59,pytorch+cuda+float16+gptq-4bit+exllama-v1
facebook/xglm-4.5B,4.5,NVIDIA A100-SXM4-80GB,0.00196,36.6,7.0,pytorch+cuda+float16+gptq-4bit+exllama-v1
chargoddard/Yi-34B-Llama,34.0,NVIDIA A100-SXM4-80GB,0.00502,19.4,13.2,pytorch+cuda+float16+gptq-4bit+exllama-v1
chargoddard/llama-2-26b-trenchcoat-stack,26.0,NVIDIA A100-SXM4-80GB,0.00528,15.7,16.3,pytorch+cuda+float16+gptq-4bit+exllama-v1
bigscience/bloom-7b1,7.0,NVIDIA A100-SXM4-80GB,0.0015,54.1,4.73,pytorch+cuda+float16+gptq-4bit+exllama-v1
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.00129,54.9,4.66,pytorch+cuda+float16+gptq-4bit+exllama-v1
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.000603,105.0,2.43,pytorch+cuda+float16+gptq-4bit+exllama-v1
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.000352,184.0,1.39,pytorch+cuda+float16+gptq-4bit+exllama-v1
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.00037,170.0,1.51,pytorch+cuda+float16+gptq-4bit+exllama-v1
seungduk/KoSOLAR-10.7B-v0.1,10.7,NVIDIA A100-SXM4-80GB,0.00314,24.2,10.6,pytorch+cuda+float16+gptq-4bit+exllama-v1
TurkuNLP/gpt3-finnish-13B,13.0,NVIDIA A100-SXM4-80GB,0.00218,41.2,6.22,pytorch+cuda+float16+gptq-4bit+exllama-v1
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.00126,52.4,4.89,pytorch+cuda+float16+gptq-4bit+exllama-v1
stabilityai/japanese-stablelm-base-gamma-7b,7.0,NVIDIA A100-SXM4-80GB,0.00227,32.1,7.98,pytorch+cuda+float16+gptq-4bit+exllama-v1
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.0011400000000000002,79.3,3.23,pytorch+cuda+float16+gptq-4bit+exllama-v1
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.000932,81.3,3.15,pytorch+cuda+float16+gptq-4bit+exllama-v1
stabilityai/stablelm-3b-4e1t,3.0,NVIDIA A100-SXM4-80GB,0.00172,40.5,6.32,pytorch+cuda+float16+gptq-4bit+exllama-v1
huggyllama/llama-65b,65.0,NVIDIA A100-SXM4-80GB,0.00776,13.5,18.9,pytorch+cuda+float16+gptq-4bit+exllama-v1
huggyllama/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.0027199999999999998,31.3,8.18,pytorch+cuda+float16+gptq-4bit+exllama-v1
NucleusAI/nucleus-22B-token-500B,22.0,NVIDIA A100-SXM4-80GB,0.00307,31.4,8.16,pytorch+cuda+float16+gptq-4bit+exllama-v1
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.000212,301.0,0.851,pytorch+cuda+float16+gptq-4bit+exllama-v1
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.000365,166.0,1.54,pytorch+cuda+float16+gptq-4bit+exllama-v1
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.000376,170.0,1.51,pytorch+cuda+float16+gptq-4bit+exllama-v1
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.000386,167.0,1.53,pytorch+cuda+float16+gptq-4bit+exllama-v1
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.000281,264.0,0.968,pytorch+cuda+float16+gptq-4bit+exllama-v1
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.00195,37.4,6.85,pytorch+cuda+float16+gptq-4bit+exllama-v1
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.00191,39.9,6.42,pytorch+cuda+float16+gptq-4bit+exllama-v1
openlm-research/open_llama_13b,13.0,NVIDIA A100-SXM4-80GB,0.00265,31.1,8.22,pytorch+cuda+float16+gptq-4bit+exllama-v1
abhinand/tamil-llama-7b-base-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00195,39.6,6.47,pytorch+cuda+float16+gptq-4bit+exllama-v1
abhinand/tamil-llama-13b-base-v0.1,13.0,NVIDIA A100-SXM4-80GB,0.00265,31.4,8.15,pytorch+cuda+float16+gptq-4bit+exllama-v1
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.00181,42.4,6.04,pytorch+cuda+float16+gptq-4bit+exllama-v1
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.00162,42.7,6.0,pytorch+cuda+float16+gptq-4bit+exllama-v1
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.0018,42.0,6.1,pytorch+cuda+float16+gptq-4bit+exllama-v1
Devio/test-22B,22.0,NVIDIA A100-SXM4-80GB,0.0030199999999999997,30.5,8.39,pytorch+cuda+float16+gptq-4bit+exllama-v1
internlm/internlm-20b,20.0,NVIDIA A100-SXM4-80GB,0.00477,17.3,14.8,pytorch+cuda+float16+gptq-4bit+exllama-v1
Delcos/Starling-LM-11B-alpha,11.0,NVIDIA A100-SXM4-80GB,0.00358,21.0,12.2,pytorch+cuda+float16+gptq-4bit+exllama-v1
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.00244,27.7,9.25,pytorch+cuda+float16+gptq-4bit+exllama-v1
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.00162,42.3,6.05,pytorch+cuda+float16+gptq-4bit+exllama-v1
upstage/SOLAR-10.7B-v1.0,10.7,NVIDIA A100-SXM4-80GB,0.00315,24.4,10.5,pytorch+cuda+float16+gptq-4bit+exllama-v1
huggingface/llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00191,38.0,6.73,pytorch+cuda+float16+gptq-4bit+exllama-v1
huggingface/llama-65b,65.0,NVIDIA A100-SXM4-80GB,0.007730000000000001,13.5,18.9,pytorch+cuda+float16+gptq-4bit+exllama-v1
huggingface/llama-30b,30.0,NVIDIA A100-SXM4-80GB,0.00463,21.3,12.0,pytorch+cuda+float16+gptq-4bit+exllama-v1
huggingface/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00264,31.3,8.19,pytorch+cuda+float16+gptq-4bit+exllama-v1
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.0020700000000000002,36.3,7.05,pytorch+cuda+float16+gptq-4bit+exllama-v1
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00188,40.4,6.34,pytorch+cuda+float16+gptq-4bit+exllama-v1
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.0019,39.0,6.56,pytorch+cuda+float16+gptq-4bit+exllama-v1
codellama/CodeLlama-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.00262,32.3,7.92,pytorch+cuda+float16+gptq-4bit+exllama-v1
EleutherAI/gpt-neox-20b,20.0,NVIDIA A100-SXM4-80GB,0.00325,25.6,10.0,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00189,39.4,6.49,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.00124,52.6,4.87,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.0022299999999999998,31.1,8.22,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-12b,12.0,NVIDIA A100-SXM4-80GB,0.00226,35.3,7.25,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00124,53.9,4.75,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-12b-deduped,12.0,NVIDIA A100-SXM4-80GB,0.00231,35.7,7.18,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.000916,76.0,3.37,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.000569,116.0,2.2,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/polyglot-ko-12.8b,12.8,NVIDIA A100-SXM4-80GB,0.00257,31.4,8.16,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.00125,52.8,4.85,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.0011,60.5,4.23,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.00065,102.0,2.5,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.00126,53.1,4.82,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.00064,103.0,2.49,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.00166,40.3,6.36,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.0016899999999999999,39.8,6.44,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.000327,184.0,1.39,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00153,44.8,5.72,pytorch+cuda+float16+awq-4bit+gemv
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.0012699999999999999,50.1,5.11,pytorch+cuda+float16+awq-4bit+gemv
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.00133,48.9,5.24,pytorch+cuda+float16+awq-4bit+gemv
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.00125,55.8,4.59,pytorch+cuda+float16+awq-4bit+gemv
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.00126,52.7,4.86,pytorch+cuda+float16+awq-4bit+gemv
Locutusque/TinyMistral-248M-v2,0.248,NVIDIA A100-SXM4-80GB,0.000775,85.9,2.98,pytorch+cuda+float16+awq-4bit+gemv
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.0007589999999999999,84.5,3.03,pytorch+cuda+float16+awq-4bit+gemv
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.00177,41.3,6.2,pytorch+cuda+float16+awq-4bit+gemv
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.000325,192.0,1.33,pytorch+cuda+float16+awq-4bit+gemv
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000344,195.0,1.31,pytorch+cuda+float16+awq-4bit+gemv
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.000324,192.0,1.33,pytorch+cuda+float16+awq-4bit+gemv
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000324,191.0,1.34,pytorch+cuda+float16+awq-4bit+gemv
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.00032300000000000004,194.0,1.32,pytorch+cuda+float16+awq-4bit+gemv
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.0013,51.4,4.98,pytorch+cuda+float16+awq-4bit+gemv
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.0012699999999999999,52.4,4.89,pytorch+cuda+float16+awq-4bit+gemv
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.00129,52.6,4.87,pytorch+cuda+float16+awq-4bit+gemv
Deci/DeciLM-7B,7.0,NVIDIA A100-SXM4-80GB,0.0019,38.2,6.7,pytorch+cuda+float16+awq-4bit+gemv
robowaifudev/megatron-gpt2-345m,0.345,NVIDIA A100-SXM4-80GB,0.0011,61.4,4.17,pytorch+cuda+float16+awq-4bit+gemv
instructkr/ko-wand-136M,0.136,NVIDIA A100-SXM4-80GB,0.0005020000000000001,125.0,2.05,pytorch+cuda+float16+awq-4bit+gemv
TencentARC/LLaMA-Pro-8B,8.0,NVIDIA A100-SXM4-80GB,0.00226,33.5,7.64,pytorch+cuda+float16+awq-4bit+gemv
meta-llama/Llama-2-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.0018599999999999999,40.0,6.4,pytorch+cuda+float16+awq-4bit+gemv
meta-llama/Llama-2-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.00248,32.3,7.93,pytorch+cuda+float16+awq-4bit+gemv
meta-llama/Llama-2-70b-hf,70.0,NVIDIA A100-SXM4-80GB,0.0071400000000000005,15.0,17.1,pytorch+cuda+float16+awq-4bit+gemv
team-lucid/mptk-1b,1.0,NVIDIA A100-SXM4-80GB,0.0007999999999999999,83.9,3.05,pytorch+cuda+float16+awq-4bit+gemv
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.000923,81.5,3.14,pytorch+cuda+float16+awq-4bit+gemv
mistralai/Mistral-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00217,32.7,7.83,pytorch+cuda+float16+awq-4bit+gemv
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.0019,35.5,7.21,pytorch+cuda+float16+awq-4bit+gemv
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.00194,35.6,7.19,pytorch+cuda+float16+awq-4bit+gemv
matsuo-lab/weblab-10b,10.0,NVIDIA A100-SXM4-80GB,0.00227,35.0,7.31,pytorch+cuda+float16+awq-4bit+gemv
augmxnt/shisa-base-7b-v1,7.0,NVIDIA A100-SXM4-80GB,0.00218,34.1,7.5,pytorch+cuda+float16+awq-4bit+gemv
AI-Sweden-Models/gpt-sw3-126m,0.126,NVIDIA A100-SXM4-80GB,0.000494,135.0,1.9,pytorch+cuda+float16+awq-4bit+gemv
AI-Sweden-Models/gpt-sw3-6.7b-v2,6.7,NVIDIA A100-SXM4-80GB,0.0015,54.4,4.71,pytorch+cuda+float16+awq-4bit+gemv
AI-Sweden-Models/gpt-sw3-40b,40.0,NVIDIA A100-SXM4-80GB,0.00575,16.4,15.6,pytorch+cuda+float16+awq-4bit+gemv
AI-Sweden-Models/gpt-sw3-20b,20.0,NVIDIA A100-SXM4-80GB,0.00331,27.0,9.49,pytorch+cuda+float16+awq-4bit+gemv
AI-Sweden-Models/gpt-sw3-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00153,54.1,4.73,pytorch+cuda+float16+awq-4bit+gemv
AI-Sweden-Models/gpt-sw3-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.0009680000000000001,71.3,3.59,pytorch+cuda+float16+awq-4bit+gemv
AI-Sweden-Models/gpt-sw3-356m,0.356,NVIDIA A100-SXM4-80GB,0.0009220000000000001,70.9,3.61,pytorch+cuda+float16+awq-4bit+gemv
uukuguy/Orca-2-7b-f16,7.0,NVIDIA A100-SXM4-80GB,0.00184,39.9,6.42,pytorch+cuda+float16+awq-4bit+gemv
01-ai/Yi-34B-200K,34.0,NVIDIA A100-SXM4-80GB,0.00471,20.3,12.6,pytorch+cuda+float16+awq-4bit+gemv
01-ai/Yi-34B,34.0,NVIDIA A100-SXM4-80GB,0.0046500000000000005,19.8,12.9,pytorch+cuda+float16+awq-4bit+gemv
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.00193,37.6,6.8,pytorch+cuda+float16+awq-4bit+gemv
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.0019,38.6,6.63,pytorch+cuda+float16+awq-4bit+gemv
scb10x/typhoon-7b,7.0,NVIDIA A100-SXM4-80GB,0.00218,33.9,7.56,pytorch+cuda+float16+awq-4bit+gemv
TheBloke/Llama-2-13B-fp16,13.0,NVIDIA A100-SXM4-80GB,0.00249,33.1,7.74,pytorch+cuda+float16+awq-4bit+gemv
mosaicml/mpt-30b,30.0,NVIDIA A100-SXM4-80GB,0.0028899999999999998,38.5,6.65,pytorch+cuda+float16+awq-4bit+gemv
mosaicml/mpt-7b,7.0,NVIDIA A100-SXM4-80GB,0.00131,61.5,4.16,pytorch+cuda+float16+awq-4bit+gemv
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.0025900000000000003,26.7,9.58,pytorch+cuda+float16+awq-4bit+gemv
Salesforce/codegen-16B-nl,16.0,NVIDIA A100-SXM4-80GB,0.0031200000000000004,25.6,10.0,pytorch+cuda+float16+awq-4bit+gemv
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.00257,27.1,9.44,pytorch+cuda+float16+awq-4bit+gemv
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.00191,40.9,6.26,pytorch+cuda+float16+awq-4bit+gemv
KnutJaegersberg/Qwen-1_8B-Llamafied,8.0,NVIDIA A100-SXM4-80GB,0.00131,50.7,5.05,pytorch+cuda+float16+awq-4bit+gemv
cyberagent/calm2-7b-chat,7.0,NVIDIA A100-SXM4-80GB,0.00191,40.8,6.27,pytorch+cuda+float16+awq-4bit+gemv
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.00195,37.0,6.92,pytorch+cuda+float16+awq-4bit+gemv
cerebras/Cerebras-GPT-111M,0.111,NVIDIA A100-SXM4-80GB,0.000388,158.0,1.62,pytorch+cuda+float16+awq-4bit+gemv
cerebras/Cerebras-GPT-13B,13.0,NVIDIA A100-SXM4-80GB,0.00239,36.3,7.06,pytorch+cuda+float16+awq-4bit+gemv
cerebras/Cerebras-GPT-6.7B,6.7,NVIDIA A100-SXM4-80GB,0.00149,54.5,4.7,pytorch+cuda+float16+awq-4bit+gemv
cerebras/Cerebras-GPT-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.0012699999999999999,54.9,4.66,pytorch+cuda+float16+awq-4bit+gemv
cerebras/Cerebras-GPT-256M,0.256,NVIDIA A100-SXM4-80GB,0.00058,115.0,2.22,pytorch+cuda+float16+awq-4bit+gemv
cerebras/Cerebras-GPT-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.0009620000000000001,72.1,3.55,pytorch+cuda+float16+awq-4bit+gemv
itsliupeng/openllama-7b-base,7.0,NVIDIA A100-SXM4-80GB,0.00185,41.0,6.25,pytorch+cuda+float16+awq-4bit+gemv
itsliupeng/openllama-7b-icl,7.0,NVIDIA A100-SXM4-80GB,0.00182,39.4,6.5,pytorch+cuda+float16+awq-4bit+gemv
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.000339,194.0,1.32,pytorch+cuda+float16+awq-4bit+gemv
tiiuae/falcon-rw-1b,1.0,NVIDIA A100-SXM4-80GB,0.00106,65.6,3.9,pytorch+cuda+float16+awq-4bit+gemv
tiiuae/falcon-40b,40.0,NVIDIA A100-SXM4-80GB,0.00524,17.4,14.7,pytorch+cuda+float16+awq-4bit+gemv
facebook/xglm-7.5B,7.5,NVIDIA A100-SXM4-80GB,0.00162,49.6,5.16,pytorch+cuda+float16+awq-4bit+gemv
facebook/xglm-564M,0.564,NVIDIA A100-SXM4-80GB,0.00103,68.6,3.73,pytorch+cuda+float16+awq-4bit+gemv
facebook/xglm-4.5B,4.5,NVIDIA A100-SXM4-80GB,0.00203,34.2,7.48,pytorch+cuda+float16+awq-4bit+gemv
chargoddard/Yi-34B-Llama,34.0,NVIDIA A100-SXM4-80GB,0.00471,19.8,12.9,pytorch+cuda+float16+awq-4bit+gemv
chargoddard/llama-2-26b-trenchcoat-stack,26.0,NVIDIA A100-SXM4-80GB,0.00502,16.2,15.8,pytorch+cuda+float16+awq-4bit+gemv
bigscience/bloom-7b1,7.0,NVIDIA A100-SXM4-80GB,0.0015400000000000001,51.2,5.0,pytorch+cuda+float16+awq-4bit+gemv
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.00134,53.0,4.83,pytorch+cuda+float16+awq-4bit+gemv
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.000589,109.0,2.34,pytorch+cuda+float16+awq-4bit+gemv
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.00033999999999999997,192.0,1.33,pytorch+cuda+float16+awq-4bit+gemv
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.000355,177.0,1.45,pytorch+cuda+float16+awq-4bit+gemv
seungduk/KoSOLAR-10.7B-v0.1,10.7,NVIDIA A100-SXM4-80GB,0.00296,25.1,10.2,pytorch+cuda+float16+awq-4bit+gemv
TurkuNLP/gpt3-finnish-13B,13.0,NVIDIA A100-SXM4-80GB,0.00219,39.4,6.49,pytorch+cuda+float16+awq-4bit+gemv
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.0012300000000000002,54.9,4.66,pytorch+cuda+float16+awq-4bit+gemv
stabilityai/japanese-stablelm-base-gamma-7b,7.0,NVIDIA A100-SXM4-80GB,0.00215,33.3,7.68,pytorch+cuda+float16+awq-4bit+gemv
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.0011799999999999998,74.2,3.45,pytorch+cuda+float16+awq-4bit+gemv
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.0009540000000000001,77.6,3.3,pytorch+cuda+float16+awq-4bit+gemv
stabilityai/stablelm-base-alpha-7b-v2,7.0,NVIDIA A100-SXM4-80GB,0.00181,41.5,6.17,pytorch+cuda+float16+awq-4bit+gemv
huggyllama/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00249,31.8,8.05,pytorch+cuda+float16+awq-4bit+gemv
NucleusAI/nucleus-22B-token-500B,22.0,NVIDIA A100-SXM4-80GB,0.00294,32.2,7.96,pytorch+cuda+float16+awq-4bit+gemv
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.00021799999999999999,293.0,0.873,pytorch+cuda+float16+awq-4bit+gemv
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.000368,168.0,1.52,pytorch+cuda+float16+awq-4bit+gemv
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.000379,163.0,1.57,pytorch+cuda+float16+awq-4bit+gemv
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.000376,168.0,1.52,pytorch+cuda+float16+awq-4bit+gemv
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.000288,274.0,0.935,pytorch+cuda+float16+awq-4bit+gemv
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.00179,39.7,6.45,pytorch+cuda+float16+awq-4bit+gemv
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.00184,41.3,6.2,pytorch+cuda+float16+awq-4bit+gemv
openlm-research/open_llama_13b,13.0,NVIDIA A100-SXM4-80GB,0.00252,32.6,7.85,pytorch+cuda+float16+awq-4bit+gemv
abhinand/tamil-llama-7b-base-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.0018599999999999999,40.9,6.26,pytorch+cuda+float16+awq-4bit+gemv
abhinand/tamil-llama-13b-base-v0.1,13.0,NVIDIA A100-SXM4-80GB,0.00249,32.6,7.85,pytorch+cuda+float16+awq-4bit+gemv
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.00198,39.0,6.57,pytorch+cuda+float16+awq-4bit+gemv
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.0016899999999999999,39.6,6.46,pytorch+cuda+float16+awq-4bit+gemv
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.0019,40.1,6.39,pytorch+cuda+float16+awq-4bit+gemv
Devio/test-22B,22.0,NVIDIA A100-SXM4-80GB,0.0028799999999999997,32.1,7.97,pytorch+cuda+float16+awq-4bit+gemv
internlm/internlm-20b,20.0,NVIDIA A100-SXM4-80GB,0.004549999999999999,17.8,14.4,pytorch+cuda+float16+awq-4bit+gemv
Delcos/Starling-LM-11B-alpha,11.0,NVIDIA A100-SXM4-80GB,0.0033799999999999998,21.3,12.0,pytorch+cuda+float16+awq-4bit+gemv
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.00247,26.7,9.6,pytorch+cuda+float16+awq-4bit+gemv
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.00165,40.4,6.33,pytorch+cuda+float16+awq-4bit+gemv
upstage/SOLAR-10.7B-v1.0,10.7,NVIDIA A100-SXM4-80GB,0.00296,25.1,10.2,pytorch+cuda+float16+awq-4bit+gemv
huggingface/llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.0018599999999999999,39.9,6.41,pytorch+cuda+float16+awq-4bit+gemv
huggingface/llama-30b,30.0,NVIDIA A100-SXM4-80GB,0.00434,21.7,11.8,pytorch+cuda+float16+awq-4bit+gemv
huggingface/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00248,32.7,7.83,pytorch+cuda+float16+awq-4bit+gemv
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.00194,37.3,6.87,pytorch+cuda+float16+awq-4bit+gemv
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00183,41.0,6.24,pytorch+cuda+float16+awq-4bit+gemv
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00184,39.9,6.42,pytorch+cuda+float16+awq-4bit+gemv
codellama/CodeLlama-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.00248,32.9,7.79,pytorch+cuda+float16+awq-4bit+gemv
codellama/CodeLlama-34b-hf,34.0,NVIDIA A100-SXM4-80GB,0.00406,24.4,10.5,pytorch+cuda+float16+awq-4bit+gemv
EleutherAI/gpt-neox-20b,20.0,NVIDIA A100-SXM4-80GB,0.00662,10.8,23.8,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.00434,15.6,16.4,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.004390000000000001,15.6,16.4,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.00309,20.5,12.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.00567,11.7,21.9,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-12b,12.0,NVIDIA A100-SXM4-80GB,0.00511,13.8,18.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00313,20.8,12.3,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-12b-deduped,12.0,NVIDIA A100-SXM4-80GB,0.00512,13.8,18.6,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.00214,30.3,8.45,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.0020499999999999997,31.3,8.18,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/polyglot-ko-12.8b,12.8,NVIDIA A100-SXM4-80GB,0.00556,12.5,20.4,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.00314,20.3,12.6,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.0041400000000000005,16.1,15.9,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.00161,39.4,6.49,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.00317,20.3,12.6,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.0015999999999999999,40.1,6.38,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.00432,15.3,16.7,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.00438,15.3,16.7,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.00081,78.5,3.26,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.0055,12.1,21.1,pytorch+cuda+float16+bnb-8bit+bettertransformer
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.0042,15.1,16.9,pytorch+cuda+float16+bnb-8bit+bettertransformer
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.00454,13.8,18.6,pytorch+cuda+float16+bnb-8bit+bettertransformer
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.00471,13.5,19.0,pytorch+cuda+float16+bnb-8bit+bettertransformer
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.00469,13.6,18.8,pytorch+cuda+float16+bnb-8bit+bettertransformer
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.00245,25.6,10.0,pytorch+cuda+float16+bnb-8bit+bettertransformer
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.00651,10.2,25.1,pytorch+cuda+float16+bnb-8bit+bettertransformer
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.000793,80.0,3.2,pytorch+cuda+float16+bnb-8bit+bettertransformer
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000799,79.8,3.21,pytorch+cuda+float16+bnb-8bit+bettertransformer
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.000809,79.0,3.24,pytorch+cuda+float16+bnb-8bit+bettertransformer
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000812,78.8,3.25,pytorch+cuda+float16+bnb-8bit+bettertransformer
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.0008150000000000001,78.0,3.28,pytorch+cuda+float16+bnb-8bit+bettertransformer
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.00423,14.8,17.3,pytorch+cuda+float16+bnb-8bit+bettertransformer
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.0042,15.1,17.0,pytorch+cuda+float16+bnb-8bit+bettertransformer
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.00433,14.9,17.2,pytorch+cuda+float16+bnb-8bit+bettertransformer
Deci/DeciLM-7B,7.0,NVIDIA A100-SXM4-80GB,0.0065699999999999995,10.2,25.1,pytorch+cuda+float16+bnb-8bit+bettertransformer
meta-llama/Llama-2-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00647,10.2,25.0,pytorch+cuda+float16+bnb-8bit+bettertransformer
meta-llama/Llama-2-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.008280000000000001,8.37,30.6,pytorch+cuda+float16+bnb-8bit+bettertransformer
meta-llama/Llama-2-70b-hf,70.0,NVIDIA A100-SXM4-80GB,0.0192,4.0,64.0,pytorch+cuda+float16+bnb-8bit+bettertransformer
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.00329,20.5,12.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
mistralai/Mistral-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00692,9.77,26.2,pytorch+cuda+float16+bnb-8bit+bettertransformer
mistralai/Mixtral-8x7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.012700000000000001,5.41,47.3,pytorch+cuda+float16+bnb-8bit+bettertransformer
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.00487,13.9,18.4,pytorch+cuda+float16+bnb-8bit+bettertransformer
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.00486,13.8,18.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
matsuo-lab/weblab-10b,10.0,NVIDIA A100-SXM4-80GB,0.00504,13.8,18.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
augmxnt/shisa-base-7b-v1,7.0,NVIDIA A100-SXM4-80GB,0.0069,9.85,26.0,pytorch+cuda+float16+bnb-8bit+bettertransformer
uukuguy/Orca-2-7b-f16,7.0,NVIDIA A100-SXM4-80GB,0.00653,10.2,25.1,pytorch+cuda+float16+bnb-8bit+bettertransformer
01-ai/Yi-34B-200K,34.0,NVIDIA A100-SXM4-80GB,0.0135,5.45,47.0,pytorch+cuda+float16+bnb-8bit+bettertransformer
01-ai/Yi-34B,34.0,NVIDIA A100-SXM4-80GB,0.0134,5.39,47.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.00641,10.4,24.6,pytorch+cuda+float16+bnb-8bit+bettertransformer
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.00641,10.4,24.6,pytorch+cuda+float16+bnb-8bit+bettertransformer
scb10x/typhoon-7b,7.0,NVIDIA A100-SXM4-80GB,0.00681,10.0,25.6,pytorch+cuda+float16+bnb-8bit+bettertransformer
TheBloke/Llama-2-13B-fp16,13.0,NVIDIA A100-SXM4-80GB,0.00842,8.28,30.9,pytorch+cuda+float16+bnb-8bit+bettertransformer
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.00513,12.9,19.8,pytorch+cuda+float16+bnb-8bit+bettertransformer
Salesforce/codegen-16B-nl,16.0,NVIDIA A100-SXM4-80GB,0.00564,12.4,20.6,pytorch+cuda+float16+bnb-8bit+bettertransformer
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.0052,12.9,19.9,pytorch+cuda+float16+bnb-8bit+bettertransformer
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.0065899999999999995,9.96,25.7,pytorch+cuda+float16+bnb-8bit+bettertransformer
deepseek-ai/deepseek-llm-67b-base,67.0,NVIDIA A100-SXM4-80GB,0.0222,3.4,75.4,pytorch+cuda+float16+bnb-8bit+bettertransformer
cyberagent/calm2-7b-chat,7.0,NVIDIA A100-SXM4-80GB,0.0063999999999999994,10.4,24.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.006350000000000001,10.4,24.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
itsliupeng/openllama-7b-base,7.0,NVIDIA A100-SXM4-80GB,0.00648,10.5,24.4,pytorch+cuda+float16+bnb-8bit+bettertransformer
itsliupeng/Mixtral-8x7B-v0.1-top3,7.0,NVIDIA A100-SXM4-80GB,0.0157,4.6,55.7,pytorch+cuda+float16+bnb-8bit+bettertransformer
itsliupeng/openllama-7b-icl,7.0,NVIDIA A100-SXM4-80GB,0.00642,10.3,24.8,pytorch+cuda+float16+bnb-8bit+bettertransformer
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.000835,78.0,3.28,pytorch+cuda+float16+bnb-8bit+bettertransformer
chargoddard/Yi-34B-Llama,34.0,NVIDIA A100-SXM4-80GB,0.013600000000000001,5.47,46.8,pytorch+cuda+float16+bnb-8bit+bettertransformer
chargoddard/llama-2-26b-trenchcoat-stack,26.0,NVIDIA A100-SXM4-80GB,0.0174,4.04,63.4,pytorch+cuda+float16+bnb-8bit+bettertransformer
bigscience/bloom-7b1,7.0,NVIDIA A100-SXM4-80GB,0.004030000000000001,17.4,14.7,pytorch+cuda+float16+bnb-8bit+bettertransformer
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.00392,17.5,14.6,pytorch+cuda+float16+bnb-8bit+bettertransformer
BEE-spoke-data/Mixtral-GQA-400m-v2,0.4,NVIDIA A100-SXM4-80GB,0.00208,29.6,8.64,pytorch+cuda+float16+bnb-8bit+bettertransformer
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.00196,32.2,7.94,pytorch+cuda+float16+bnb-8bit+bettertransformer
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.0012,52.8,4.85,pytorch+cuda+float16+bnb-8bit+bettertransformer
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.0012100000000000001,53.8,4.76,pytorch+cuda+float16+bnb-8bit+bettertransformer
seungduk/KoSOLAR-10.7B-v0.1,10.7,NVIDIA A100-SXM4-80GB,0.00974,6.88,37.2,pytorch+cuda+float16+bnb-8bit+bettertransformer
TurkuNLP/gpt3-finnish-13B,13.0,NVIDIA A100-SXM4-80GB,0.00549,13.0,19.7,pytorch+cuda+float16+bnb-8bit+bettertransformer
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.00459,13.8,18.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
stabilityai/japanese-stablelm-base-gamma-7b,7.0,NVIDIA A100-SXM4-80GB,0.0067800000000000004,9.81,26.1,pytorch+cuda+float16+bnb-8bit+bettertransformer
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.00232,31.2,8.21,pytorch+cuda+float16+bnb-8bit+bettertransformer
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.00226,31.1,8.24,pytorch+cuda+float16+bnb-8bit+bettertransformer
huggyllama/llama-65b,65.0,NVIDIA A100-SXM4-80GB,0.0191,4.04,63.3,pytorch+cuda+float16+bnb-8bit+bettertransformer
huggyllama/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00853,7.17,35.7,pytorch+cuda+float16+bnb-8bit+bettertransformer
NucleusAI/nucleus-22B-token-500B,22.0,NVIDIA A100-SXM4-80GB,0.008620000000000001,8.31,30.8,pytorch+cuda+float16+bnb-8bit+bettertransformer
Walmart-the-bag/Influxient-4x13B,13.0,NVIDIA A100-SXM4-80GB,0.0152,4.74,54.0,pytorch+cuda+float16+bnb-8bit+bettertransformer
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.000707,89.5,2.86,pytorch+cuda+float16+bnb-8bit+bettertransformer
roneneldan/TinyStories-1M,0.001,NVIDIA A100-SXM4-80GB,0.0013599999999999999,47.0,5.45,pytorch+cuda+float16+bnb-8bit+bettertransformer
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.00134,46.4,5.52,pytorch+cuda+float16+bnb-8bit+bettertransformer
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.0013599999999999999,46.8,5.47,pytorch+cuda+float16+bnb-8bit+bettertransformer
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.00137,46.4,5.52,pytorch+cuda+float16+bnb-8bit+bettertransformer
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.000824,78.5,3.26,pytorch+cuda+float16+bnb-8bit+bettertransformer
openlm-research/open_llama_3b_v2,3.0,NVIDIA A100-SXM4-80GB,0.0052499999999999995,12.3,20.8,pytorch+cuda+float16+bnb-8bit+bettertransformer
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.00645,10.2,25.2,pytorch+cuda+float16+bnb-8bit+bettertransformer
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.00645,10.4,24.7,pytorch+cuda+float16+bnb-8bit+bettertransformer
openlm-research/open_llama_3b,3.0,NVIDIA A100-SXM4-80GB,0.0053,12.1,21.1,pytorch+cuda+float16+bnb-8bit+bettertransformer
openlm-research/open_llama_13b,13.0,NVIDIA A100-SXM4-80GB,0.00851,8.03,31.9,pytorch+cuda+float16+bnb-8bit+bettertransformer
abhinand/tamil-llama-7b-base-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.0065899999999999995,10.2,25.0,pytorch+cuda+float16+bnb-8bit+bettertransformer
abhinand/tamil-llama-13b-base-v0.1,13.0,NVIDIA A100-SXM4-80GB,0.0084,8.05,31.8,pytorch+cuda+float16+bnb-8bit+bettertransformer
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.00434,15.6,16.4,pytorch+cuda+float16+bnb-8bit+bettertransformer
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.00433,15.5,16.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00437,15.8,16.2,pytorch+cuda+float16+bnb-8bit+bettertransformer
Devio/test-22B,22.0,NVIDIA A100-SXM4-80GB,0.00873,7.98,32.1,pytorch+cuda+float16+bnb-8bit+bettertransformer
Delcos/Starling-LM-11B-alpha,11.0,NVIDIA A100-SXM4-80GB,0.0108,6.12,41.8,pytorch+cuda+float16+bnb-8bit+bettertransformer
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.00642,10.4,24.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.0042899999999999995,15.5,16.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
upstage/SOLAR-10.7B-v1.0,10.7,NVIDIA A100-SXM4-80GB,0.00976,6.84,37.4,pytorch+cuda+float16+bnb-8bit+bettertransformer
huggingface/llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00638,10.4,24.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
huggingface/llama-65b,65.0,NVIDIA A100-SXM4-80GB,0.0189,4.1,62.5,pytorch+cuda+float16+bnb-8bit+bettertransformer
huggingface/llama-30b,30.0,NVIDIA A100-SXM4-80GB,0.0132,5.57,46.0,pytorch+cuda+float16+bnb-8bit+bettertransformer
huggingface/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.008450000000000001,8.0,32.0,pytorch+cuda+float16+bnb-8bit+bettertransformer
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.0063999999999999994,10.3,24.9,pytorch+cuda+float16+bnb-8bit+bettertransformer
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00648,10.3,24.8,pytorch+cuda+float16+bnb-8bit+bettertransformer
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00655,10.3,24.9,pytorch+cuda+float16+bnb-8bit+bettertransformer
codellama/CodeLlama-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.00819,8.28,30.9,pytorch+cuda+float16+bnb-8bit+bettertransformer
cloudyu/Mixtral_7Bx2_MoE_13B,7.0,NVIDIA A100-SXM4-80GB,0.011300000000000001,5.94,43.1,pytorch+cuda+float16+bnb-8bit+bettertransformer
cloudyu/Mixtral_7Bx4_MOE_24B,7.0,NVIDIA A100-SXM4-80GB,0.012700000000000001,5.73,44.7,pytorch+cuda+float16+bnb-8bit+bettertransformer
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.00294,37.3,6.86,pytorch+cuda+float32
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00293,37.0,6.91,pytorch+cuda+float32
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.00153,53.6,4.78,pytorch+cuda+float32
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.003,32.7,7.84,pytorch+cuda+float32
EleutherAI/pythia-12b,12.0,NVIDIA A100-SXM4-80GB,0.00445,24.6,10.4,pytorch+cuda+float32
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.0014500000000000001,52.1,4.91,pytorch+cuda+float32
EleutherAI/pythia-12b-deduped,12.0,NVIDIA A100-SXM4-80GB,0.0045000000000000005,24.6,10.4,pytorch+cuda+float32
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.00101,78.5,3.26,pytorch+cuda+float32
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.000544,123.0,2.08,pytorch+cuda+float32
EleutherAI/polyglot-ko-12.8b,12.8,NVIDIA A100-SXM4-80GB,0.004889999999999999,22.3,11.5,pytorch+cuda+float32
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.0012300000000000002,53.1,4.82,pytorch+cuda+float32
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.00128,61.7,4.15,pytorch+cuda+float32
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.0006090000000000001,108.0,2.37,pytorch+cuda+float32
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.00124,54.2,4.72,pytorch+cuda+float32
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.000614,108.0,2.37,pytorch+cuda+float32
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.0019700000000000004,41.0,6.24,pytorch+cuda+float32
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.0020099999999999996,40.8,6.27,pytorch+cuda+float32
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.00032,206.0,1.24,pytorch+cuda+float32
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00176,49.5,5.17,pytorch+cuda+float32
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.00133,56.5,4.53,pytorch+cuda+float32
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.0012699999999999999,54.9,4.66,pytorch+cuda+float32
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.0015600000000000002,60.0,4.27,pytorch+cuda+float32
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.0015799999999999998,59.3,4.32,pytorch+cuda+float32
Locutusque/TinyMistral-248M-v2,0.248,NVIDIA A100-SXM4-80GB,0.0007080000000000001,95.5,2.68,pytorch+cuda+float32
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.000706,97.0,2.64,pytorch+cuda+float32
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.0027700000000000003,40.4,6.34,pytorch+cuda+float32
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.000305,208.0,1.23,pytorch+cuda+float32
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.00031,203.0,1.26,pytorch+cuda+float32
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.000319,206.0,1.24,pytorch+cuda+float32
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000307,205.0,1.25,pytorch+cuda+float32
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.00030199999999999997,206.0,1.24,pytorch+cuda+float32
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.0013,57.3,4.47,pytorch+cuda+float32
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.00131,57.0,4.49,pytorch+cuda+float32
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.0013,57.8,4.43,pytorch+cuda+float32
Deci/DeciLM-7B,7.0,NVIDIA A100-SXM4-80GB,0.00278,39.8,6.44,pytorch+cuda+float32
robowaifudev/megatron-gpt2-345m,0.345,NVIDIA A100-SXM4-80GB,0.00108,62.7,4.08,pytorch+cuda+float32
instructkr/ko-wand-136M,0.136,NVIDIA A100-SXM4-80GB,0.000447,140.0,1.83,pytorch+cuda+float32
TencentARC/LLaMA-Pro-8B,8.0,NVIDIA A100-SXM4-80GB,0.00345,32.2,7.94,pytorch+cuda+float32
meta-llama/Llama-2-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00276,40.2,6.37,pytorch+cuda+float32
meta-llama/Llama-2-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.0046500000000000005,23.5,10.9,pytorch+cuda+float32
team-lucid/mptk-1b,1.0,NVIDIA A100-SXM4-80GB,0.000987,92.1,2.78,pytorch+cuda+float32
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.00142,77.8,3.29,pytorch+cuda+float32
mistralai/Mistral-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00299,37.2,6.89,pytorch+cuda+float32
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.0024200000000000003,35.9,7.14,pytorch+cuda+float32
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.00239,36.8,6.96,pytorch+cuda+float32
matsuo-lab/weblab-10b,10.0,NVIDIA A100-SXM4-80GB,0.00415,26.6,9.62,pytorch+cuda+float32
augmxnt/shisa-base-7b-v1,7.0,NVIDIA A100-SXM4-80GB,0.00311,35.9,7.14,pytorch+cuda+float32
AI-Sweden-Models/gpt-sw3-126m,0.126,NVIDIA A100-SXM4-80GB,0.000486,133.0,1.93,pytorch+cuda+float32
AI-Sweden-Models/gpt-sw3-6.7b-v2,6.7,NVIDIA A100-SXM4-80GB,0.0030299999999999997,34.5,7.42,pytorch+cuda+float32
AI-Sweden-Models/gpt-sw3-20b,20.0,NVIDIA A100-SXM4-80GB,0.00795,13.6,18.8,pytorch+cuda+float32
AI-Sweden-Models/gpt-sw3-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.0030800000000000003,34.6,7.4,pytorch+cuda+float32
AI-Sweden-Models/gpt-sw3-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00117,71.9,3.56,pytorch+cuda+float32
AI-Sweden-Models/gpt-sw3-356m,0.356,NVIDIA A100-SXM4-80GB,0.00095,71.7,3.57,pytorch+cuda+float32
uukuguy/Orca-2-7b-f16,7.0,NVIDIA A100-SXM4-80GB,0.0027300000000000002,40.3,6.35,pytorch+cuda+float32
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.00263,40.3,6.35,pytorch+cuda+float32
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.00263,40.1,6.39,pytorch+cuda+float32
scb10x/typhoon-7b,7.0,NVIDIA A100-SXM4-80GB,0.003,36.8,6.96,pytorch+cuda+float32
TheBloke/Llama-2-13B-fp16,13.0,NVIDIA A100-SXM4-80GB,0.00464,23.5,10.9,pytorch+cuda+float32
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.00353,28.3,9.06,pytorch+cuda+float32
Salesforce/codegen-16B-nl,16.0,NVIDIA A100-SXM4-80GB,0.0055899999999999995,19.7,13.0,pytorch+cuda+float32
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.0035099999999999997,27.9,9.19,pytorch+cuda+float32
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.00276,40.1,6.39,pytorch+cuda+float32
KnutJaegersberg/Qwen-1_8B-Llamafied,8.0,NVIDIA A100-SXM4-80GB,0.00142,54.4,4.71,pytorch+cuda+float32
cyberagent/calm2-7b-chat,7.0,NVIDIA A100-SXM4-80GB,0.00278,39.7,6.45,pytorch+cuda+float32
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.00268,40.4,6.33,pytorch+cuda+float32
cerebras/Cerebras-GPT-111M,0.111,NVIDIA A100-SXM4-80GB,0.00042300000000000004,157.0,1.63,pytorch+cuda+float32
cerebras/Cerebras-GPT-13B,13.0,NVIDIA A100-SXM4-80GB,0.00511,21.5,11.9,pytorch+cuda+float32
cerebras/Cerebras-GPT-6.7B,6.7,NVIDIA A100-SXM4-80GB,0.0030199999999999997,34.5,7.41,pytorch+cuda+float32
cerebras/Cerebras-GPT-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00162,55.9,4.58,pytorch+cuda+float32
cerebras/Cerebras-GPT-256M,0.256,NVIDIA A100-SXM4-80GB,0.000569,123.0,2.08,pytorch+cuda+float32
cerebras/Cerebras-GPT-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.0012,72.3,3.54,pytorch+cuda+float32
itsliupeng/openllama-7b-base,7.0,NVIDIA A100-SXM4-80GB,0.00274,40.4,6.34,pytorch+cuda+float32
itsliupeng/openllama-7b-icl,7.0,NVIDIA A100-SXM4-80GB,0.0027199999999999998,40.3,6.35,pytorch+cuda+float32
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.000312,202.0,1.27,pytorch+cuda+float32
tiiuae/falcon-rw-1b,1.0,NVIDIA A100-SXM4-80GB,0.0011799999999999998,71.5,3.58,pytorch+cuda+float32
tiiuae/falcon-7b,7.0,NVIDIA A100-SXM4-80GB,0.00318,31.1,8.24,pytorch+cuda+float32
facebook/xglm-7.5B,7.5,NVIDIA A100-SXM4-80GB,0.00286,37.8,6.78,pytorch+cuda+float32
facebook/xglm-564M,0.564,NVIDIA A100-SXM4-80GB,0.00101,73.4,3.49,pytorch+cuda+float32
facebook/xglm-4.5B,4.5,NVIDIA A100-SXM4-80GB,0.00252,36.6,6.99,pytorch+cuda+float32
chargoddard/SmolLlamix-8x101M,0.101,NVIDIA A100-SXM4-80GB,0.000741,82.1,3.12,pytorch+cuda+float32
chargoddard/SmolLlamix-8x101M-take2,0.101,NVIDIA A100-SXM4-80GB,0.000744,82.6,3.1,pytorch+cuda+float32
bigscience/bloom-7b1,7.0,NVIDIA A100-SXM4-80GB,0.0025,44.1,5.8,pytorch+cuda+float32
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.0017000000000000001,53.8,4.76,pytorch+cuda+float32
BEE-spoke-data/Mixtral-GQA-400m-v2,0.4,NVIDIA A100-SXM4-80GB,0.000821,83.4,3.07,pytorch+cuda+float32
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.000562,125.0,2.04,pytorch+cuda+float32
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.000311,213.0,1.2,pytorch+cuda+float32
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.00033099999999999997,198.0,1.29,pytorch+cuda+float32
seungduk/KoSOLAR-10.7B-v0.1,10.7,NVIDIA A100-SXM4-80GB,0.00436,25.6,10.0,pytorch+cuda+float32
TurkuNLP/gpt3-finnish-13B,13.0,NVIDIA A100-SXM4-80GB,0.00436,24.9,10.3,pytorch+cuda+float32
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.00139,59.5,4.3,pytorch+cuda+float32
stabilityai/japanese-stablelm-base-gamma-7b,7.0,NVIDIA A100-SXM4-80GB,0.00306,35.6,7.19,pytorch+cuda+float32
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.00263,41.4,6.19,pytorch+cuda+float32
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.00152,71.7,3.57,pytorch+cuda+float32
stabilityai/stablelm-base-alpha-7b-v2,7.0,NVIDIA A100-SXM4-80GB,0.00264,41.9,6.11,pytorch+cuda+float32
stabilityai/stablelm-3b-4e1t,3.0,NVIDIA A100-SXM4-80GB,0.00183,45.2,5.66,pytorch+cuda+float32
huggyllama/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.0047,23.5,10.9,pytorch+cuda+float32
Walmart-the-bag/WordWoven-13B,13.0,NVIDIA A100-SXM4-80GB,0.006240000000000001,16.3,15.7,pytorch+cuda+float32
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.000212,324.0,0.79,pytorch+cuda+float32
roneneldan/TinyStories-1M,0.001,NVIDIA A100-SXM4-80GB,0.000346,182.0,1.41,pytorch+cuda+float32
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.000342,184.0,1.39,pytorch+cuda+float32
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.000372,183.0,1.4,pytorch+cuda+float32
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.000338,186.0,1.38,pytorch+cuda+float32
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.000427,262.0,0.978,pytorch+cuda+float32
openlm-research/open_llama_3b_v2,3.0,NVIDIA A100-SXM4-80GB,0.00175,56.0,4.57,pytorch+cuda+float32
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.0027199999999999998,40.3,6.35,pytorch+cuda+float32
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.0027700000000000003,40.3,6.36,pytorch+cuda+float32
openlm-research/open_llama_3b,3.0,NVIDIA A100-SXM4-80GB,0.00175,55.7,4.6,pytorch+cuda+float32
openlm-research/open_llama_13b,13.0,NVIDIA A100-SXM4-80GB,0.00468,23.5,10.9,pytorch+cuda+float32
abhinand/tamil-llama-7b-base-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.0027700000000000003,40.1,6.39,pytorch+cuda+float32
abhinand/tamil-llama-13b-base-v0.1,13.0,NVIDIA A100-SXM4-80GB,0.0046500000000000005,23.3,11.0,pytorch+cuda+float32
RWKV/rwkv-4-3b-pile,3.0,NVIDIA A100-SXM4-80GB,0.00247,31.5,8.12,pytorch+cuda+float32
RWKV/rwkv-4-430m-pile,0.43,NVIDIA A100-SXM4-80GB,0.00155,41.4,6.19,pytorch+cuda+float32
RWKV/rwkv-4-169m-pile,0.169,NVIDIA A100-SXM4-80GB,0.0008150000000000001,80.3,3.19,pytorch+cuda+float32
RWKV/rwkv-4-7b-pile,7.0,NVIDIA A100-SXM4-80GB,0.00333,30.0,8.53,pytorch+cuda+float32
RWKV/rwkv-raven-14b,14.0,NVIDIA A100-SXM4-80GB,0.00503,22.1,11.6,pytorch+cuda+float32
RWKV/rwkv-4-14b-pile,14.0,NVIDIA A100-SXM4-80GB,0.0051,21.9,11.7,pytorch+cuda+float32
RWKV/rwkv-4-1b5-pile,1.0,NVIDIA A100-SXM4-80GB,0.00189,40.4,6.34,pytorch+cuda+float32
TigerResearch/tigerbot-13b-base,13.0,NVIDIA A100-SXM4-80GB,0.00555,20.3,12.6,pytorch+cuda+float32
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.00294,37.0,6.91,pytorch+cuda+float32
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.00199,41.3,6.2,pytorch+cuda+float32
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00293,37.2,6.89,pytorch+cuda+float32
internlm/internlm-20b,20.0,NVIDIA A100-SXM4-80GB,0.007220000000000001,15.2,16.8,pytorch+cuda+float32
Delcos/Starling-LM-11B-alpha,11.0,NVIDIA A100-SXM4-80GB,0.00478,23.5,10.9,pytorch+cuda+float32
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.0028899999999999998,28.7,8.93,pytorch+cuda+float32
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.0020099999999999996,40.6,6.31,pytorch+cuda+float32
upstage/SOLAR-10.7B-v1.0,10.7,NVIDIA A100-SXM4-80GB,0.00432,25.6,10.0,pytorch+cuda+float32
huggingface/llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00274,40.3,6.36,pytorch+cuda+float32
huggingface/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00462,23.5,10.9,pytorch+cuda+float32
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.0026699999999999996,39.9,6.42,pytorch+cuda+float32
beomi/KoRWKV-6B,6.0,NVIDIA A100-SXM4-80GB,0.0028799999999999997,34.9,7.34,pytorch+cuda+float32
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00276,40.4,6.34,pytorch+cuda+float32
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.0027700000000000003,40.3,6.35,pytorch+cuda+float32
codellama/CodeLlama-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.0047,23.5,10.9,pytorch+cuda+float32
cloudyu/Mixtral_11Bx2_MoE_19B,11.0,NVIDIA A100-SXM4-80GB,0.00948,10.8,23.6,pytorch+cuda+float32
cloudyu/Mixtral_7Bx2_MoE,7.0,NVIDIA A100-SXM4-80GB,0.00617,16.1,15.9,pytorch+cuda+float32
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.0022400000000000002,32.8,7.8,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.0022800000000000003,33.3,7.69,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.00149,43.8,5.85,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.0028,25.1,10.2,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.0014500000000000001,44.7,5.73,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.00102,64.0,4.0,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.00073,85.6,2.99,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.00141,44.5,5.75,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.0015099999999999998,43.8,5.84,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.000721,87.7,2.92,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.0014399999999999999,44.4,5.77,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.000723,82.6,3.1,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.00203,33.8,7.57,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.0020099999999999996,34.0,7.54,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.000375,164.0,1.56,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.0020499999999999997,32.5,7.87,pytorch+cuda+float16+gptq-4bit+cuda-fp16
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.0016899999999999999,36.9,6.94,pytorch+cuda+float16+gptq-4bit+cuda-fp16
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.00177,35.3,7.25,pytorch+cuda+float16+gptq-4bit+cuda-fp16
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.0018,38.6,6.64,pytorch+cuda+float16+gptq-4bit+cuda-fp16
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.00181,38.3,6.69,pytorch+cuda+float16+gptq-4bit+cuda-fp16
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.0009519999999999999,66.1,3.87,pytorch+cuda+float16+gptq-4bit+cuda-fp16
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.00257,28.4,9.02,pytorch+cuda+float16+gptq-4bit+cuda-fp16
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.00037,166.0,1.54,pytorch+cuda+float16+gptq-4bit+cuda-fp16
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000378,163.0,1.57,pytorch+cuda+float16+gptq-4bit+cuda-fp16
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.00037,158.0,1.62,pytorch+cuda+float16+gptq-4bit+cuda-fp16
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.00036899999999999997,166.0,1.54,pytorch+cuda+float16+gptq-4bit+cuda-fp16
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.00037099999999999996,165.0,1.55,pytorch+cuda+float16+gptq-4bit+cuda-fp16
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.00171,38.3,6.69,pytorch+cuda+float16+gptq-4bit+cuda-fp16
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.0017000000000000001,37.8,6.77,pytorch+cuda+float16+gptq-4bit+cuda-fp16
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.00166,38.7,6.61,pytorch+cuda+float16+gptq-4bit+cuda-fp16
robowaifudev/megatron-gpt2-345m,0.345,NVIDIA A100-SXM4-80GB,0.0012300000000000002,51.5,4.97,pytorch+cuda+float16+gptq-4bit+cuda-fp16
meta-llama/Llama-2-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00264,28.5,8.99,pytorch+cuda+float16+gptq-4bit+cuda-fp16
meta-llama/Llama-2-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.00344,23.3,11.0,pytorch+cuda+float16+gptq-4bit+cuda-fp16
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.00128,57.3,4.47,pytorch+cuda+float16+gptq-4bit+cuda-fp16
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.00231,29.9,8.56,pytorch+cuda+float16+gptq-4bit+cuda-fp16
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.00227,30.3,8.46,pytorch+cuda+float16+gptq-4bit+cuda-fp16
matsuo-lab/weblab-10b,10.0,NVIDIA A100-SXM4-80GB,0.00274,28.0,9.14,pytorch+cuda+float16+gptq-4bit+cuda-fp16
augmxnt/shisa-base-7b-v1,7.0,NVIDIA A100-SXM4-80GB,0.00314,24.2,10.6,pytorch+cuda+float16+gptq-4bit+cuda-fp16
AI-Sweden-Models/gpt-sw3-126m,0.126,NVIDIA A100-SXM4-80GB,0.000566,108.0,2.36,pytorch+cuda+float16+gptq-4bit+cuda-fp16
AI-Sweden-Models/gpt-sw3-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00117,57.5,4.45,pytorch+cuda+float16+gptq-4bit+cuda-fp16
AI-Sweden-Models/gpt-sw3-356m,0.356,NVIDIA A100-SXM4-80GB,0.0011200000000000001,56.5,4.53,pytorch+cuda+float16+gptq-4bit+cuda-fp16
uukuguy/Orca-2-7b-f16,7.0,NVIDIA A100-SXM4-80GB,0.00258,27.9,9.19,pytorch+cuda+float16+gptq-4bit+cuda-fp16
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.0027099999999999997,25.1,10.2,pytorch+cuda+float16+gptq-4bit+cuda-fp16
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.00265,27.0,9.49,pytorch+cuda+float16+gptq-4bit+cuda-fp16
TheBloke/Llama-2-13B-fp16,13.0,NVIDIA A100-SXM4-80GB,0.00354,22.5,11.4,pytorch+cuda+float16+gptq-4bit+cuda-fp16
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.00309,23.1,11.1,pytorch+cuda+float16+gptq-4bit+cuda-fp16
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.00311,23.1,11.1,pytorch+cuda+float16+gptq-4bit+cuda-fp16
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.00264,28.4,9.02,pytorch+cuda+float16+gptq-4bit+cuda-fp16
cyberagent/calm2-7b-chat,7.0,NVIDIA A100-SXM4-80GB,0.0026,28.6,8.96,pytorch+cuda+float16+gptq-4bit+cuda-fp16
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.00274,26.4,9.68,pytorch+cuda+float16+gptq-4bit+cuda-fp16
cerebras/Cerebras-GPT-111M,0.111,NVIDIA A100-SXM4-80GB,0.00048800000000000004,131.0,1.95,pytorch+cuda+float16+gptq-4bit+cuda-fp16
cerebras/Cerebras-GPT-13B,13.0,NVIDIA A100-SXM4-80GB,0.00257,33.4,7.67,pytorch+cuda+float16+gptq-4bit+cuda-fp16
cerebras/Cerebras-GPT-6.7B,6.7,NVIDIA A100-SXM4-80GB,0.00184,41.6,6.16,pytorch+cuda+float16+gptq-4bit+cuda-fp16
cerebras/Cerebras-GPT-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00164,42.7,6.0,pytorch+cuda+float16+gptq-4bit+cuda-fp16
cerebras/Cerebras-GPT-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.00115,57.1,4.48,pytorch+cuda+float16+gptq-4bit+cuda-fp16
itsliupeng/openllama-7b-base,7.0,NVIDIA A100-SXM4-80GB,0.00262,28.3,9.04,pytorch+cuda+float16+gptq-4bit+cuda-fp16
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.00037,165.0,1.55,pytorch+cuda+float16+gptq-4bit+cuda-fp16
tiiuae/falcon-rw-1b,1.0,NVIDIA A100-SXM4-80GB,0.00126,53.7,4.77,pytorch+cuda+float16+gptq-4bit+cuda-fp16
facebook/xglm-564M,0.564,NVIDIA A100-SXM4-80GB,0.00131,49.5,5.17,pytorch+cuda+float16+gptq-4bit+cuda-fp16
facebook/xglm-4.5B,4.5,NVIDIA A100-SXM4-80GB,0.0028,25.3,10.1,pytorch+cuda+float16+gptq-4bit+cuda-fp16
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.0016300000000000002,43.3,5.91,pytorch+cuda+float16+gptq-4bit+cuda-fp16
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.000757,81.8,3.13,pytorch+cuda+float16+gptq-4bit+cuda-fp16
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.000446,139.0,1.84,pytorch+cuda+float16+gptq-4bit+cuda-fp16
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.00048100000000000004,130.0,1.97,pytorch+cuda+float16+gptq-4bit+cuda-fp16
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.0017000000000000001,38.3,6.69,pytorch+cuda+float16+gptq-4bit+cuda-fp16
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.00115,64.5,3.97,pytorch+cuda+float16+gptq-4bit+cuda-fp16
stabilityai/stablelm-3b-4e1t,3.0,NVIDIA A100-SXM4-80GB,0.00226,29.7,8.62,pytorch+cuda+float16+gptq-4bit+cuda-fp16
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.000276,227.0,1.13,pytorch+cuda+float16+gptq-4bit+cuda-fp16
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.000479,128.0,2.0,pytorch+cuda+float16+gptq-4bit+cuda-fp16
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.00049,123.0,2.08,pytorch+cuda+float16+gptq-4bit+cuda-fp16
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.000489,125.0,2.04,pytorch+cuda+float16+gptq-4bit+cuda-fp16
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.000359,200.0,1.28,pytorch+cuda+float16+gptq-4bit+cuda-fp16
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.00258,28.3,9.04,pytorch+cuda+float16+gptq-4bit+cuda-fp16
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.00257,28.3,9.06,pytorch+cuda+float16+gptq-4bit+cuda-fp16
openlm-research/open_llama_13b,13.0,NVIDIA A100-SXM4-80GB,0.00349,22.7,11.3,pytorch+cuda+float16+gptq-4bit+cuda-fp16
abhinand/tamil-llama-13b-base-v0.1,13.0,NVIDIA A100-SXM4-80GB,0.0035,23.1,11.1,pytorch+cuda+float16+gptq-4bit+cuda-fp16
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.00227,33.1,7.74,pytorch+cuda+float16+gptq-4bit+cuda-fp16
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.00204,32.9,7.77,pytorch+cuda+float16+gptq-4bit+cuda-fp16
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.0022500000000000003,32.7,7.83,pytorch+cuda+float16+gptq-4bit+cuda-fp16
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.00305,22.5,11.4,pytorch+cuda+float16+gptq-4bit+cuda-fp16
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.0020099999999999996,34.2,7.49,pytorch+cuda+float16+gptq-4bit+cuda-fp16
huggingface/llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00263,28.1,9.1,pytorch+cuda+float16+gptq-4bit+cuda-fp16
huggingface/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00348,22.9,11.2,pytorch+cuda+float16+gptq-4bit+cuda-fp16
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.00264,27.1,9.46,pytorch+cuda+float16+gptq-4bit+cuda-fp16
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.0025900000000000003,28.3,9.03,pytorch+cuda+float16+gptq-4bit+cuda-fp16
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.0025399999999999997,29.0,8.83,pytorch+cuda+float16+gptq-4bit+cuda-fp16
EleutherAI/gpt-neox-20b,20.0,NVIDIA A100-SXM4-80GB,0.00438,24.9,10.3,pytorch+cuda+bfloat16
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.0021100000000000003,39.9,6.41,pytorch+cuda+bfloat16
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.0021,41.5,6.17,pytorch+cuda+bfloat16
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.00135,53.2,4.81,pytorch+cuda+bfloat16
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.00244,32.3,7.92,pytorch+cuda+bfloat16
EleutherAI/pythia-12b,12.0,NVIDIA A100-SXM4-80GB,0.00281,35.5,7.21,pytorch+cuda+bfloat16
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00133,54.1,4.73,pytorch+cuda+bfloat16
EleutherAI/pythia-12b-deduped,12.0,NVIDIA A100-SXM4-80GB,0.00275,36.5,7.01,pytorch+cuda+bfloat16
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.0009379999999999999,75.5,3.39,pytorch+cuda+bfloat16
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.000572,115.0,2.22,pytorch+cuda+bfloat16
EleutherAI/polyglot-ko-12.8b,12.8,NVIDIA A100-SXM4-80GB,0.0030800000000000003,32.5,7.88,pytorch+cuda+bfloat16
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.00126,53.6,4.78,pytorch+cuda+bfloat16
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.00126,59.7,4.29,pytorch+cuda+bfloat16
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.000602,106.0,2.41,pytorch+cuda+bfloat16
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.0012100000000000001,55.1,4.65,pytorch+cuda+bfloat16
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.000651,107.0,2.4,pytorch+cuda+bfloat16
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.00181,40.4,6.34,pytorch+cuda+bfloat16
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.0018,40.7,6.29,pytorch+cuda+bfloat16
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.000317,202.0,1.27,pytorch+cuda+bfloat16
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.0017000000000000001,44.4,5.76,pytorch+cuda+bfloat16
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.00135,53.6,4.78,pytorch+cuda+bfloat16
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.00135,49.2,5.2,pytorch+cuda+bfloat16
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.00141,53.9,4.75,pytorch+cuda+bfloat16
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.0014,54.0,4.74,pytorch+cuda+bfloat16
Locutusque/TinyMistral-248M-v2,0.248,NVIDIA A100-SXM4-80GB,0.000737,87.4,2.93,pytorch+cuda+bfloat16
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.000766,88.0,2.91,pytorch+cuda+bfloat16
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.0020099999999999996,44.0,5.82,pytorch+cuda+bfloat16
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.000305,205.0,1.25,pytorch+cuda+bfloat16
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.00031,205.0,1.25,pytorch+cuda+bfloat16
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.000309,205.0,1.25,pytorch+cuda+bfloat16
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000309,205.0,1.25,pytorch+cuda+bfloat16
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.000313,203.0,1.26,pytorch+cuda+bfloat16
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.00132,52.0,4.92,pytorch+cuda+bfloat16
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.00132,54.8,4.67,pytorch+cuda+bfloat16
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.0013599999999999999,51.8,4.94,pytorch+cuda+bfloat16
Deci/DeciLM-7B,7.0,NVIDIA A100-SXM4-80GB,0.00221,38.8,6.59,pytorch+cuda+bfloat16
robowaifudev/megatron-gpt2-345m,0.345,NVIDIA A100-SXM4-80GB,0.00109,61.1,4.19,pytorch+cuda+bfloat16
instructkr/ko-wand-136M,0.136,NVIDIA A100-SXM4-80GB,0.000483,127.0,2.02,pytorch+cuda+bfloat16
TencentARC/LLaMA-Pro-8B,8.0,NVIDIA A100-SXM4-80GB,0.00258,33.9,7.56,pytorch+cuda+bfloat16
meta-llama/Llama-2-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.0021100000000000003,41.4,6.18,pytorch+cuda+bfloat16
meta-llama/Llama-2-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.0031,33.5,7.65,pytorch+cuda+bfloat16
team-lucid/mptk-1b,1.0,NVIDIA A100-SXM4-80GB,0.000894,87.4,2.93,pytorch+cuda+bfloat16
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.00105,78.5,3.26,pytorch+cuda+bfloat16
mistralai/Mistral-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00244,34.9,7.34,pytorch+cuda+bfloat16
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.0020499999999999997,36.2,7.08,pytorch+cuda+bfloat16
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.0020099999999999996,37.3,6.86,pytorch+cuda+bfloat16
matsuo-lab/weblab-10b,10.0,NVIDIA A100-SXM4-80GB,0.00264,36.5,7.02,pytorch+cuda+bfloat16
augmxnt/shisa-base-7b-v1,7.0,NVIDIA A100-SXM4-80GB,0.00249,34.2,7.49,pytorch+cuda+bfloat16
AI-Sweden-Models/gpt-sw3-126m,0.126,NVIDIA A100-SXM4-80GB,0.000474,137.0,1.87,pytorch+cuda+bfloat16
AI-Sweden-Models/gpt-sw3-6.7b-v2,6.7,NVIDIA A100-SXM4-80GB,0.00171,55.4,4.62,pytorch+cuda+bfloat16
AI-Sweden-Models/gpt-sw3-20b,20.0,NVIDIA A100-SXM4-80GB,0.0039700000000000004,27.2,9.42,pytorch+cuda+bfloat16
AI-Sweden-Models/gpt-sw3-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00175,54.4,4.71,pytorch+cuda+bfloat16
AI-Sweden-Models/gpt-sw3-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00107,70.5,3.63,pytorch+cuda+bfloat16
AI-Sweden-Models/gpt-sw3-356m,0.356,NVIDIA A100-SXM4-80GB,0.000965,69.6,3.68,pytorch+cuda+bfloat16
uukuguy/Orca-2-7b-f16,7.0,NVIDIA A100-SXM4-80GB,0.0020499999999999997,43.1,5.94,pytorch+cuda+bfloat16
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.00214,39.8,6.44,pytorch+cuda+bfloat16
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.00214,39.1,6.55,pytorch+cuda+bfloat16
scb10x/typhoon-7b,7.0,NVIDIA A100-SXM4-80GB,0.00247,34.5,7.43,pytorch+cuda+bfloat16
TheBloke/Llama-2-13B-fp16,13.0,NVIDIA A100-SXM4-80GB,0.00298,34.7,7.37,pytorch+cuda+bfloat16
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.00295,26.4,9.71,pytorch+cuda+bfloat16
Salesforce/codegen-16B-nl,16.0,NVIDIA A100-SXM4-80GB,0.00387,26.2,9.77,pytorch+cuda+bfloat16
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.00292,27.0,9.48,pytorch+cuda+bfloat16
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.00204,43.0,5.95,pytorch+cuda+bfloat16
KnutJaegersberg/Qwen-1_8B-Llamafied,8.0,NVIDIA A100-SXM4-80GB,0.00139,51.6,4.96,pytorch+cuda+bfloat16
cyberagent/calm2-7b-chat,7.0,NVIDIA A100-SXM4-80GB,0.0020499999999999997,41.8,6.13,pytorch+cuda+bfloat16
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.00219,38.6,6.64,pytorch+cuda+bfloat16
cerebras/Cerebras-GPT-111M,0.111,NVIDIA A100-SXM4-80GB,0.000432,152.0,1.68,pytorch+cuda+bfloat16
cerebras/Cerebras-GPT-13B,13.0,NVIDIA A100-SXM4-80GB,0.00279,36.7,6.97,pytorch+cuda+bfloat16
cerebras/Cerebras-GPT-6.7B,6.7,NVIDIA A100-SXM4-80GB,0.00172,55.1,4.65,pytorch+cuda+bfloat16
cerebras/Cerebras-GPT-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00146,54.4,4.71,pytorch+cuda+bfloat16
cerebras/Cerebras-GPT-256M,0.256,NVIDIA A100-SXM4-80GB,0.000581,114.0,2.25,pytorch+cuda+bfloat16
cerebras/Cerebras-GPT-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.0011099999999999999,68.3,3.75,pytorch+cuda+bfloat16
itsliupeng/openllama-7b-base,7.0,NVIDIA A100-SXM4-80GB,0.00204,42.3,6.05,pytorch+cuda+bfloat16
itsliupeng/openllama-7b-icl,7.0,NVIDIA A100-SXM4-80GB,0.0021,42.5,6.03,pytorch+cuda+bfloat16
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.000306,205.0,1.25,pytorch+cuda+bfloat16
tiiuae/falcon-rw-1b,1.0,NVIDIA A100-SXM4-80GB,0.00117,66.7,3.84,pytorch+cuda+bfloat16
tiiuae/falcon-7b,7.0,NVIDIA A100-SXM4-80GB,0.00212,40.5,6.32,pytorch+cuda+bfloat16
facebook/xglm-7.5B,7.5,NVIDIA A100-SXM4-80GB,0.00185,52.4,4.89,pytorch+cuda+bfloat16
facebook/xglm-564M,0.564,NVIDIA A100-SXM4-80GB,0.000914,75.5,3.39,pytorch+cuda+bfloat16
facebook/xglm-4.5B,4.5,NVIDIA A100-SXM4-80GB,0.00217,36.6,6.99,pytorch+cuda+bfloat16
chargoddard/SmolLlamix-8x101M,0.101,NVIDIA A100-SXM4-80GB,0.000818,76.9,3.33,pytorch+cuda+bfloat16
chargoddard/llama-2-26b-trenchcoat-stack,26.0,NVIDIA A100-SXM4-80GB,0.00603,17.3,14.8,pytorch+cuda+bfloat16
chargoddard/SmolLlamix-8x101M-take2,0.101,NVIDIA A100-SXM4-80GB,0.000813,77.1,3.32,pytorch+cuda+bfloat16
bigscience/bloom-7b1,7.0,NVIDIA A100-SXM4-80GB,0.00181,53.0,4.83,pytorch+cuda+bfloat16
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.00149,53.6,4.78,pytorch+cuda+bfloat16
BEE-spoke-data/Mixtral-GQA-400m-v2,0.4,NVIDIA A100-SXM4-80GB,0.000894,75.7,3.38,pytorch+cuda+bfloat16
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.000576,109.0,2.35,pytorch+cuda+bfloat16
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.00033999999999999997,194.0,1.32,pytorch+cuda+bfloat16
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.00035999999999999997,180.0,1.42,pytorch+cuda+bfloat16
seungduk/KoSOLAR-10.7B-v0.1,10.7,NVIDIA A100-SXM4-80GB,0.00332,25.3,10.1,pytorch+cuda+bfloat16
TurkuNLP/gpt3-finnish-13B,13.0,NVIDIA A100-SXM4-80GB,0.00268,40.6,6.31,pytorch+cuda+bfloat16
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.0013,56.1,4.56,pytorch+cuda+bfloat16
stabilityai/japanese-stablelm-base-gamma-7b,7.0,NVIDIA A100-SXM4-80GB,0.00241,35.0,7.31,pytorch+cuda+bfloat16
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.0015799999999999998,67.7,3.78,pytorch+cuda+bfloat16
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.0011099999999999999,79.0,3.24,pytorch+cuda+bfloat16
stabilityai/stablelm-base-alpha-7b-v2,7.0,NVIDIA A100-SXM4-80GB,0.00206,43.5,5.89,pytorch+cuda+bfloat16
stabilityai/stablelm-3b-4e1t,3.0,NVIDIA A100-SXM4-80GB,0.00176,42.6,6.01,pytorch+cuda+bfloat16
huggyllama/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00296,34.5,7.41,pytorch+cuda+bfloat16
NucleusAI/nucleus-22B-token-500B,22.0,NVIDIA A100-SXM4-80GB,0.003940000000000001,27.9,9.16,pytorch+cuda+bfloat16
Walmart-the-bag/WordWoven-13B,13.0,NVIDIA A100-SXM4-80GB,0.00476,17.2,14.9,pytorch+cuda+bfloat16
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.000217,300.0,0.853,pytorch+cuda+bfloat16
roneneldan/TinyStories-1M,0.001,NVIDIA A100-SXM4-80GB,0.00035999999999999997,174.0,1.47,pytorch+cuda+bfloat16
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.000353,171.0,1.5,pytorch+cuda+bfloat16
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.000372,171.0,1.5,pytorch+cuda+bfloat16
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.000365,174.0,1.47,pytorch+cuda+bfloat16
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.00031800000000000003,283.0,0.905,pytorch+cuda+bfloat16
openlm-research/open_llama_3b_v2,3.0,NVIDIA A100-SXM4-80GB,0.0015999999999999999,47.7,5.37,pytorch+cuda+bfloat16
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.00209,42.2,6.07,pytorch+cuda+bfloat16
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.00203,42.9,5.97,pytorch+cuda+bfloat16
openlm-research/open_llama_3b,3.0,NVIDIA A100-SXM4-80GB,0.0016300000000000002,47.1,5.44,pytorch+cuda+bfloat16
openlm-research/open_llama_13b,13.0,NVIDIA A100-SXM4-80GB,0.00301,33.4,7.66,pytorch+cuda+bfloat16
abhinand/tamil-llama-7b-base-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00209,42.9,5.97,pytorch+cuda+bfloat16
abhinand/tamil-llama-13b-base-v0.1,13.0,NVIDIA A100-SXM4-80GB,0.00306,33.7,7.6,pytorch+cuda+bfloat16
RWKV/rwkv-4-3b-pile,3.0,NVIDIA A100-SXM4-80GB,0.0024200000000000003,29.2,8.78,pytorch+cuda+bfloat16
RWKV/rwkv-4-430m-pile,0.43,NVIDIA A100-SXM4-80GB,0.00173,39.3,6.51,pytorch+cuda+bfloat16
RWKV/rwkv-4-169m-pile,0.169,NVIDIA A100-SXM4-80GB,0.000826,78.5,3.26,pytorch+cuda+bfloat16
RWKV/rwkv-4-7b-pile,7.0,NVIDIA A100-SXM4-80GB,0.00268,29.9,8.55,pytorch+cuda+bfloat16
RWKV/rwkv-raven-14b,14.0,NVIDIA A100-SXM4-80GB,0.00378,23.1,11.1,pytorch+cuda+bfloat16
RWKV/rwkv-4-14b-pile,14.0,NVIDIA A100-SXM4-80GB,0.00378,24.2,10.6,pytorch+cuda+bfloat16
RWKV/rwkv-4-1b5-pile,1.0,NVIDIA A100-SXM4-80GB,0.00182,39.1,6.55,pytorch+cuda+bfloat16
TigerResearch/tigerbot-13b-base,13.0,NVIDIA A100-SXM4-80GB,0.00438,20.3,12.6,pytorch+cuda+bfloat16
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.00213,40.8,6.28,pytorch+cuda+bfloat16
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.00185,40.3,6.35,pytorch+cuda+bfloat16
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00212,41.1,6.23,pytorch+cuda+bfloat16
Devio/test-22B,22.0,NVIDIA A100-SXM4-80GB,0.0039299999999999995,27.9,9.17,pytorch+cuda+bfloat16
internlm/internlm-20b,20.0,NVIDIA A100-SXM4-80GB,0.00529,18.7,13.7,pytorch+cuda+bfloat16
Delcos/Starling-LM-11B-alpha,11.0,NVIDIA A100-SXM4-80GB,0.0038299999999999996,22.1,11.6,pytorch+cuda+bfloat16
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.00262,28.2,9.07,pytorch+cuda+bfloat16
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.0018700000000000001,40.3,6.36,pytorch+cuda+bfloat16
upstage/SOLAR-10.7B-v1.0,10.7,NVIDIA A100-SXM4-80GB,0.00332,25.6,10.0,pytorch+cuda+bfloat16
huggingface/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00309,33.7,7.6,pytorch+cuda+bfloat16
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.00214,38.1,6.72,pytorch+cuda+bfloat16
beomi/KoRWKV-6B,6.0,NVIDIA A100-SXM4-80GB,0.00234,34.2,7.49,pytorch+cuda+bfloat16
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.0020499999999999997,42.3,6.05,pytorch+cuda+bfloat16
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00203,43.1,5.94,pytorch+cuda+bfloat16
codellama/CodeLlama-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.003,33.7,7.59,pytorch+cuda+bfloat16
cloudyu/Mixtral_7Bx2_MoE_13B,7.0,NVIDIA A100-SXM4-80GB,0.0046099999999999995,17.4,14.7,pytorch+cuda+bfloat16
cloudyu/Mixtral_11Bx2_MoE_19B,11.0,NVIDIA A100-SXM4-80GB,0.00696,11.6,22.1,pytorch+cuda+bfloat16
cloudyu/Mixtral_7Bx2_MoE,7.0,NVIDIA A100-SXM4-80GB,0.00463,17.3,14.8,pytorch+cuda+bfloat16
cloudyu/Mixtral_7Bx4_MOE_24B,7.0,NVIDIA A100-SXM4-80GB,0.00499,15.8,16.2,pytorch+cuda+bfloat16
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.00232,40.4,6.34,pytorch+cuda+float16
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00232,40.4,6.34,pytorch+cuda+float16
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.00132,53.7,4.77,pytorch+cuda+float16
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.00265,31.0,8.25,pytorch+cuda+float16
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00133,53.4,4.79,pytorch+cuda+float16
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.000912,78.3,3.27,pytorch+cuda+float16
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.0005120000000000001,121.0,2.12,pytorch+cuda+float16
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.0011400000000000002,55.3,4.63,pytorch+cuda+float16
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.00122,59.7,4.29,pytorch+cuda+float16
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.000564,109.0,2.35,pytorch+cuda+float16
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.000563,108.0,2.38,pytorch+cuda+float16
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.00188,41.2,6.21,pytorch+cuda+float16
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.0018599999999999999,40.4,6.34,pytorch+cuda+float16
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.000298,205.0,1.25,pytorch+cuda+float16
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00175,43.9,5.83,pytorch+cuda+float16
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.00133,53.9,4.75,pytorch+cuda+float16
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.00122,51.0,5.02,pytorch+cuda+float16
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.00146,53.2,4.81,pytorch+cuda+float16
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.00146,54.9,4.66,pytorch+cuda+float16
Locutusque/TinyMistral-248M-v2,0.248,NVIDIA A100-SXM4-80GB,0.000737,88.3,2.9,pytorch+cuda+float16
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.0006770000000000001,90.5,2.83,pytorch+cuda+float16
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.00226,42.4,6.04,pytorch+cuda+float16
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.000288,208.0,1.23,pytorch+cuda+float16
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.00029099999999999997,206.0,1.24,pytorch+cuda+float16
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.00029099999999999997,208.0,1.23,pytorch+cuda+float16
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000286,208.0,1.23,pytorch+cuda+float16
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.00029099999999999997,208.0,1.23,pytorch+cuda+float16
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.00128,53.8,4.76,pytorch+cuda+float16
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.0013,52.1,4.91,pytorch+cuda+float16
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.0012699999999999999,53.2,4.81,pytorch+cuda+float16
robowaifudev/megatron-gpt2-345m,0.345,NVIDIA A100-SXM4-80GB,0.001,62.7,4.08,pytorch+cuda+float16
instructkr/ko-wand-136M,0.136,NVIDIA A100-SXM4-80GB,0.000501,128.0,2.0,pytorch+cuda+float16
meta-llama/Llama-2-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00218,42.0,6.1,pytorch+cuda+float16
team-lucid/mptk-1b,1.0,NVIDIA A100-SXM4-80GB,0.000879,85.3,3.0,pytorch+cuda+float16
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.00113,82.3,3.11,pytorch+cuda+float16
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.0022199999999999998,35.8,7.16,pytorch+cuda+float16
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.00216,36.2,7.07,pytorch+cuda+float16
AI-Sweden-Models/gpt-sw3-126m,0.126,NVIDIA A100-SXM4-80GB,0.000453,139.0,1.84,pytorch+cuda+float16
AI-Sweden-Models/gpt-sw3-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00104,70.5,3.63,pytorch+cuda+float16
AI-Sweden-Models/gpt-sw3-356m,0.356,NVIDIA A100-SXM4-80GB,0.0008929999999999999,71.1,3.6,pytorch+cuda+float16
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.00232,38.4,6.66,pytorch+cuda+float16
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.0024,38.0,6.74,pytorch+cuda+float16
scb10x/typhoon-7b,7.0,NVIDIA A100-SXM4-80GB,0.00256,34.4,7.45,pytorch+cuda+float16
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.00306,26.7,9.6,pytorch+cuda+float16
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.00311,26.9,9.51,pytorch+cuda+float16
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.0022199999999999998,41.4,6.18,pytorch+cuda+float16
KnutJaegersberg/Qwen-1_8B-Llamafied,8.0,NVIDIA A100-SXM4-80GB,0.00137,51.9,4.93,pytorch+cuda+float16
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.00231,38.7,6.62,pytorch+cuda+float16
cerebras/Cerebras-GPT-111M,0.111,NVIDIA A100-SXM4-80GB,0.000386,162.0,1.58,pytorch+cuda+float16
cerebras/Cerebras-GPT-6.7B,6.7,NVIDIA A100-SXM4-80GB,0.00181,54.9,4.66,pytorch+cuda+float16
cerebras/Cerebras-GPT-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00141,53.9,4.75,pytorch+cuda+float16
cerebras/Cerebras-GPT-256M,0.256,NVIDIA A100-SXM4-80GB,0.000534,120.0,2.14,pytorch+cuda+float16
cerebras/Cerebras-GPT-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.001,70.3,3.64,pytorch+cuda+float16
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.00028700000000000004,210.0,1.22,pytorch+cuda+float16
tiiuae/falcon-rw-1b,1.0,NVIDIA A100-SXM4-80GB,0.0011200000000000001,65.0,3.94,pytorch+cuda+float16
facebook/xglm-564M,0.564,NVIDIA A100-SXM4-80GB,0.000916,74.4,3.44,pytorch+cuda+float16
facebook/xglm-4.5B,4.5,NVIDIA A100-SXM4-80GB,0.00234,35.3,7.26,pytorch+cuda+float16
chargoddard/SmolLlamix-8x101M,0.101,NVIDIA A100-SXM4-80GB,0.000844,76.4,3.35,pytorch+cuda+float16
chargoddard/SmolLlamix-8x101M-take2,0.101,NVIDIA A100-SXM4-80GB,0.000823,78.0,3.28,pytorch+cuda+float16
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.00149,53.4,4.79,pytorch+cuda+float16
BEE-spoke-data/Mixtral-GQA-400m-v2,0.4,NVIDIA A100-SXM4-80GB,0.000861,79.8,3.21,pytorch+cuda+float16
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.000534,117.0,2.18,pytorch+cuda+float16
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.00031800000000000003,195.0,1.31,pytorch+cuda+float16
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.000332,186.0,1.38,pytorch+cuda+float16
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.00131,54.8,4.67,pytorch+cuda+float16
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.00166,66.1,3.87,pytorch+cuda+float16
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.00117,79.0,3.24,pytorch+cuda+float16
stabilityai/stablelm-base-alpha-7b-v2,7.0,NVIDIA A100-SXM4-80GB,0.0022199999999999998,43.0,5.95,pytorch+cuda+float16
stabilityai/stablelm-3b-4e1t,3.0,NVIDIA A100-SXM4-80GB,0.00177,42.5,6.03,pytorch+cuda+float16
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.000203,309.0,0.829,pytorch+cuda+float16
roneneldan/TinyStories-1M,0.001,NVIDIA A100-SXM4-80GB,0.00033,182.0,1.41,pytorch+cuda+float16
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.000336,178.0,1.44,pytorch+cuda+float16
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.000345,175.0,1.46,pytorch+cuda+float16
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.000338,178.0,1.44,pytorch+cuda+float16
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.000314,278.0,0.921,pytorch+cuda+float16
openlm-research/open_llama_3b_v2,3.0,NVIDIA A100-SXM4-80GB,0.00173,46.5,5.51,pytorch+cuda+float16
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.0022199999999999998,42.5,6.03,pytorch+cuda+float16
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.0022299999999999998,42.6,6.01,pytorch+cuda+float16
openlm-research/open_llama_3b,3.0,NVIDIA A100-SXM4-80GB,0.00171,46.8,5.47,pytorch+cuda+float16
RWKV/rwkv-4-3b-pile,3.0,NVIDIA A100-SXM4-80GB,0.0025399999999999997,29.3,8.73,pytorch+cuda+float16
RWKV/rwkv-4-430m-pile,0.43,NVIDIA A100-SXM4-80GB,0.00152,41.1,6.23,pytorch+cuda+float16
RWKV/rwkv-4-169m-pile,0.169,NVIDIA A100-SXM4-80GB,0.000781,78.5,3.26,pytorch+cuda+float16
RWKV/rwkv-4-7b-pile,7.0,NVIDIA A100-SXM4-80GB,0.00276,30.2,8.49,pytorch+cuda+float16
RWKV/rwkv-4-1b5-pile,1.0,NVIDIA A100-SXM4-80GB,0.00179,39.0,6.57,pytorch+cuda+float16
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.00235,40.0,6.4,pytorch+cuda+float16
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.00191,39.4,6.49,pytorch+cuda+float16
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00233,40.5,6.32,pytorch+cuda+float16
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.0027,27.7,9.25,pytorch+cuda+float16
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.00183,40.1,6.39,pytorch+cuda+float16
huggingface/llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00219,42.2,6.07,pytorch+cuda+float16
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.00234,38.0,6.73,pytorch+cuda+float16
beomi/KoRWKV-6B,6.0,NVIDIA A100-SXM4-80GB,0.00253,33.9,7.55,pytorch+cuda+float16
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00214,42.9,5.97,pytorch+cuda+float16
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00218,43.3,5.91,pytorch+cuda+float16
EleutherAI/gpt-neox-20b,20.0,NVIDIA A100-SXM4-80GB,0.00688,10.4,24.5,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.00462,15.1,17.0,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00459,15.1,16.9,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.00336,19.5,13.1,pytorch+cuda+float16+bnb-8bit
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.00593,11.5,22.3,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-12b,12.0,NVIDIA A100-SXM4-80GB,0.00535,13.3,19.3,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00335,19.8,12.9,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-12b-deduped,12.0,NVIDIA A100-SXM4-80GB,0.00547,13.2,19.4,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.00229,29.1,8.8,pytorch+cuda+float16+bnb-8bit
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.0020499999999999997,31.2,8.2,pytorch+cuda+float16+bnb-8bit
EleutherAI/polyglot-ko-12.8b,12.8,NVIDIA A100-SXM4-80GB,0.00608,11.9,21.6,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.0032600000000000003,20.0,12.8,pytorch+cuda+float16+bnb-8bit
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.0042699999999999995,15.6,16.4,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.00166,39.3,6.51,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.00335,19.1,13.4,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.00164,39.0,6.56,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.00449,14.9,17.2,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.004560000000000001,15.1,17.0,pytorch+cuda+float16+bnb-8bit
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.0008810000000000001,75.5,3.39,pytorch+cuda+float16+bnb-8bit
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00573,11.7,21.8,pytorch+cuda+float16+bnb-8bit
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.00462,14.3,17.9,pytorch+cuda+float16+bnb-8bit
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.00482,13.1,19.5,pytorch+cuda+float16+bnb-8bit
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.0049099999999999994,13.7,18.7,pytorch+cuda+float16+bnb-8bit
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.0049099999999999994,13.7,18.7,pytorch+cuda+float16+bnb-8bit
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.0026,25.6,10.0,pytorch+cuda+float16+bnb-8bit
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.00661,10.4,24.7,pytorch+cuda+float16+bnb-8bit
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.0008320000000000001,74.6,3.43,pytorch+cuda+float16+bnb-8bit
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000841,73.6,3.48,pytorch+cuda+float16+bnb-8bit
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.000855,75.7,3.38,pytorch+cuda+float16+bnb-8bit
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.0008309999999999999,76.0,3.37,pytorch+cuda+float16+bnb-8bit
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.0008449999999999999,76.0,3.37,pytorch+cuda+float16+bnb-8bit
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.00458,14.5,17.7,pytorch+cuda+float16+bnb-8bit
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.004549999999999999,14.5,17.7,pytorch+cuda+float16+bnb-8bit
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.004549999999999999,14.5,17.7,pytorch+cuda+float16+bnb-8bit
Deci/DeciLM-7B,7.0,NVIDIA A100-SXM4-80GB,0.00654,10.2,25.1,pytorch+cuda+float16+bnb-8bit
team-lucid/mptk-1b,1.0,NVIDIA A100-SXM4-80GB,0.00295,22.9,11.2,pytorch+cuda+float16+bnb-8bit
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.00333,20.8,12.3,pytorch+cuda+float16+bnb-8bit
mistralai/Mistral-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00682,9.85,26.0,pytorch+cuda+float16+bnb-8bit
mistralai/Mixtral-8x7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.011899999999999999,5.57,46.0,pytorch+cuda+float16+bnb-8bit
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.00515,13.1,19.5,pytorch+cuda+float16+bnb-8bit
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.0050100000000000006,13.4,19.1,pytorch+cuda+float16+bnb-8bit
matsuo-lab/weblab-10b,10.0,NVIDIA A100-SXM4-80GB,0.00526,13.4,19.1,pytorch+cuda+float16+bnb-8bit
augmxnt/shisa-base-7b-v1,7.0,NVIDIA A100-SXM4-80GB,0.0069,9.85,26.0,pytorch+cuda+float16+bnb-8bit
uukuguy/Orca-2-7b-f16,7.0,NVIDIA A100-SXM4-80GB,0.00636,10.6,24.1,pytorch+cuda+float16+bnb-8bit
01-ai/Yi-34B-200K,34.0,NVIDIA A100-SXM4-80GB,0.0131,5.42,47.2,pytorch+cuda+float16+bnb-8bit
01-ai/Yi-34B,34.0,NVIDIA A100-SXM4-80GB,0.0131,5.37,47.7,pytorch+cuda+float16+bnb-8bit
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.0067599999999999995,10.1,25.3,pytorch+cuda+float16+bnb-8bit
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.00683,10.0,25.5,pytorch+cuda+float16+bnb-8bit
scb10x/typhoon-7b,7.0,NVIDIA A100-SXM4-80GB,0.00675,9.81,26.1,pytorch+cuda+float16+bnb-8bit
TheBloke/Llama-2-13B-fp16,13.0,NVIDIA A100-SXM4-80GB,0.0085,8.26,31.0,pytorch+cuda+float16+bnb-8bit
mosaicml/mpt-30b,30.0,NVIDIA A100-SXM4-80GB,0.0065899999999999995,11.5,22.3,pytorch+cuda+float16+bnb-8bit
mosaicml/mpt-7b,7.0,NVIDIA A100-SXM4-80GB,0.0041400000000000005,17.1,15.0,pytorch+cuda+float16+bnb-8bit
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.00541,12.5,20.5,pytorch+cuda+float16+bnb-8bit
Salesforce/codegen-16B-nl,16.0,NVIDIA A100-SXM4-80GB,0.00588,11.9,21.6,pytorch+cuda+float16+bnb-8bit
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.00543,12.3,20.8,pytorch+cuda+float16+bnb-8bit
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.00644,10.3,24.8,pytorch+cuda+float16+bnb-8bit
deepseek-ai/deepseek-llm-67b-base,67.0,NVIDIA A100-SXM4-80GB,0.020999999999999998,3.38,75.7,pytorch+cuda+float16+bnb-8bit
cyberagent/calm2-7b-chat,7.0,NVIDIA A100-SXM4-80GB,0.00648,10.2,25.0,pytorch+cuda+float16+bnb-8bit
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.0069,9.85,26.0,pytorch+cuda+float16+bnb-8bit
itsliupeng/openllama-7b-base,7.0,NVIDIA A100-SXM4-80GB,0.00636,10.5,24.3,pytorch+cuda+float16+bnb-8bit
itsliupeng/Mixtral-8x7B-v0.1-top3,7.0,NVIDIA A100-SXM4-80GB,0.0146,4.54,56.4,pytorch+cuda+float16+bnb-8bit
itsliupeng/openllama-7b-icl,7.0,NVIDIA A100-SXM4-80GB,0.00634,10.5,24.4,pytorch+cuda+float16+bnb-8bit
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.000824,76.0,3.37,pytorch+cuda+float16+bnb-8bit
tiiuae/falcon-rw-1b,1.0,NVIDIA A100-SXM4-80GB,0.0031200000000000004,21.5,11.9,pytorch+cuda+float16+bnb-8bit
tiiuae/falcon-7b,7.0,NVIDIA A100-SXM4-80GB,0.00435,15.4,16.6,pytorch+cuda+float16+bnb-8bit
tiiuae/falcon-40b,40.0,NVIDIA A100-SXM4-80GB,0.00937,8.05,31.8,pytorch+cuda+float16+bnb-8bit
facebook/xglm-7.5B,7.5,NVIDIA A100-SXM4-80GB,0.00558,12.4,20.7,pytorch+cuda+float16+bnb-8bit
facebook/xglm-564M,0.564,NVIDIA A100-SXM4-80GB,0.004030000000000001,16.5,15.5,pytorch+cuda+float16+bnb-8bit
facebook/xglm-4.5B,4.5,NVIDIA A100-SXM4-80GB,0.00824,8.15,31.4,pytorch+cuda+float16+bnb-8bit
chargoddard/Yi-34B-Llama,34.0,NVIDIA A100-SXM4-80GB,0.013,5.41,47.3,pytorch+cuda+float16+bnb-8bit
chargoddard/llama-2-26b-trenchcoat-stack,26.0,NVIDIA A100-SXM4-80GB,0.0167,4.13,62.0,pytorch+cuda+float16+bnb-8bit
bigscience/bloom-7b1,7.0,NVIDIA A100-SXM4-80GB,0.00408,17.1,15.0,pytorch+cuda+float16+bnb-8bit
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.00399,17.2,14.9,pytorch+cuda+float16+bnb-8bit
BEE-spoke-data/Mixtral-GQA-400m-v2,0.4,NVIDIA A100-SXM4-80GB,0.0022,29.4,8.7,pytorch+cuda+float16+bnb-8bit
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.00206,31.4,8.14,pytorch+cuda+float16+bnb-8bit
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.0012100000000000001,53.6,4.78,pytorch+cuda+float16+bnb-8bit
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.0012300000000000002,51.1,5.01,pytorch+cuda+float16+bnb-8bit
seungduk/KoSOLAR-10.7B-v0.1,10.7,NVIDIA A100-SXM4-80GB,0.01,6.72,38.1,pytorch+cuda+float16+bnb-8bit
TurkuNLP/gpt3-finnish-13B,13.0,NVIDIA A100-SXM4-80GB,0.005710000000000001,12.8,20.0,pytorch+cuda+float16+bnb-8bit
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.0048400000000000006,13.8,18.5,pytorch+cuda+float16+bnb-8bit
stabilityai/japanese-stablelm-base-gamma-7b,7.0,NVIDIA A100-SXM4-80GB,0.00681,9.73,26.3,pytorch+cuda+float16+bnb-8bit
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.00247,29.0,8.83,pytorch+cuda+float16+bnb-8bit
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.00248,29.2,8.76,pytorch+cuda+float16+bnb-8bit
stabilityai/stablelm-base-alpha-7b-v2,7.0,NVIDIA A100-SXM4-80GB,0.00445,15.3,16.7,pytorch+cuda+float16+bnb-8bit
huggyllama/llama-65b,65.0,NVIDIA A100-SXM4-80GB,0.0177,4.14,61.8,pytorch+cuda+float16+bnb-8bit
huggyllama/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00836,8.31,30.8,pytorch+cuda+float16+bnb-8bit
NucleusAI/nucleus-22B-token-500B,22.0,NVIDIA A100-SXM4-80GB,0.00848,8.31,30.8,pytorch+cuda+float16+bnb-8bit
Walmart-the-bag/Influxient-4x13B,13.0,NVIDIA A100-SXM4-80GB,0.0141,4.8,53.3,pytorch+cuda+float16+bnb-8bit
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.00073,88.9,2.88,pytorch+cuda+float16+bnb-8bit
roneneldan/TinyStories-1M,0.001,NVIDIA A100-SXM4-80GB,0.0013599999999999999,45.4,5.64,pytorch+cuda+float16+bnb-8bit
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.00134,46.4,5.52,pytorch+cuda+float16+bnb-8bit
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.00139,45.6,5.62,pytorch+cuda+float16+bnb-8bit
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.0014,45.6,5.62,pytorch+cuda+float16+bnb-8bit
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.000874,78.0,3.28,pytorch+cuda+float16+bnb-8bit
openlm-research/open_llama_3b_v2,3.0,NVIDIA A100-SXM4-80GB,0.00539,12.6,20.3,pytorch+cuda+float16+bnb-8bit
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.00656,10.4,24.6,pytorch+cuda+float16+bnb-8bit
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.0066,10.2,25.1,pytorch+cuda+float16+bnb-8bit
openlm-research/open_llama_3b,3.0,NVIDIA A100-SXM4-80GB,0.00543,12.4,20.7,pytorch+cuda+float16+bnb-8bit
openlm-research/open_llama_13b,13.0,NVIDIA A100-SXM4-80GB,0.008539999999999999,8.26,31.0,pytorch+cuda+float16+bnb-8bit
abhinand/tamil-llama-7b-base-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00638,10.7,24.0,pytorch+cuda+float16+bnb-8bit
abhinand/tamil-llama-13b-base-v0.1,13.0,NVIDIA A100-SXM4-80GB,0.00846,8.26,31.0,pytorch+cuda+float16+bnb-8bit
RWKV/rwkv-4-3b-pile,3.0,NVIDIA A100-SXM4-80GB,0.0072,9.28,27.6,pytorch+cuda+float16+bnb-8bit
RWKV/rwkv-4-430m-pile,0.43,NVIDIA A100-SXM4-80GB,0.005180000000000001,12.4,20.6,pytorch+cuda+float16+bnb-8bit
RWKV/rwkv-4-169m-pile,0.169,NVIDIA A100-SXM4-80GB,0.00265,24.6,10.4,pytorch+cuda+float16+bnb-8bit
RWKV/rwkv-4-7b-pile,7.0,NVIDIA A100-SXM4-80GB,0.0070999999999999995,9.41,27.2,pytorch+cuda+float16+bnb-8bit
RWKV/rwkv-raven-14b,14.0,NVIDIA A100-SXM4-80GB,0.00946,7.42,34.5,pytorch+cuda+float16+bnb-8bit
RWKV/rwkv-4-14b-pile,14.0,NVIDIA A100-SXM4-80GB,0.00919,7.57,33.8,pytorch+cuda+float16+bnb-8bit
RWKV/rwkv-4-1b5-pile,1.0,NVIDIA A100-SXM4-80GB,0.0054600000000000004,12.1,21.1,pytorch+cuda+float16+bnb-8bit
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.0046700000000000005,15.1,17.0,pytorch+cuda+float16+bnb-8bit
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.004560000000000001,14.8,17.3,pytorch+cuda+float16+bnb-8bit
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00473,14.8,17.3,pytorch+cuda+float16+bnb-8bit
Devio/test-22B,22.0,NVIDIA A100-SXM4-80GB,0.008379999999999999,8.34,30.7,pytorch+cuda+float16+bnb-8bit
internlm/internlm-20b,20.0,NVIDIA A100-SXM4-80GB,0.0134,5.21,49.1,pytorch+cuda+float16+bnb-8bit
Delcos/Starling-LM-11B-alpha,11.0,NVIDIA A100-SXM4-80GB,0.0109,6.12,41.8,pytorch+cuda+float16+bnb-8bit
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.0066300000000000005,10.1,25.3,pytorch+cuda+float16+bnb-8bit
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.00454,14.8,17.3,pytorch+cuda+float16+bnb-8bit
upstage/SOLAR-10.7B-v1.0,10.7,NVIDIA A100-SXM4-80GB,0.00997,6.77,37.8,pytorch+cuda+float16+bnb-8bit
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.00665,9.73,26.3,pytorch+cuda+float16+bnb-8bit
beomi/KoRWKV-6B,6.0,NVIDIA A100-SXM4-80GB,0.00645,10.4,24.6,pytorch+cuda+float16+bnb-8bit
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.0065899999999999995,10.3,24.8,pytorch+cuda+float16+bnb-8bit
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.006350000000000001,10.5,24.3,pytorch+cuda+float16+bnb-8bit
codellama/CodeLlama-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.0084,8.39,30.5,pytorch+cuda+float16+bnb-8bit
cloudyu/Mixtral_7Bx2_MoE_13B,7.0,NVIDIA A100-SXM4-80GB,0.0111,6.0,42.7,pytorch+cuda+float16+bnb-8bit
cloudyu/Mixtral_7Bx2_MoE,7.0,NVIDIA A100-SXM4-80GB,0.011,6.12,41.8,pytorch+cuda+float16+bnb-8bit
cloudyu/Mixtral_7Bx4_MOE_24B,7.0,NVIDIA A100-SXM4-80GB,0.011300000000000001,5.91,43.3,pytorch+cuda+float16+bnb-8bit
EleutherAI/gpt-neox-20b,20.0,NVIDIA A100-SXM4-80GB,0.00586,14.9,17.2,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.0029000000000000002,27.1,9.43,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00296,27.1,9.43,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.00188,36.6,6.99,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.0035,21.3,12.0,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-12b,12.0,NVIDIA A100-SXM4-80GB,0.00378,22.9,11.2,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00189,36.3,7.06,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-12b-deduped,12.0,NVIDIA A100-SXM4-80GB,0.0037,22.9,11.2,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.00126,54.0,4.74,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.00102,64.2,3.99,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/polyglot-ko-12.8b,12.8,NVIDIA A100-SXM4-80GB,0.00417,20.6,12.4,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.0018,35.9,7.13,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.00206,32.6,7.85,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.000928,68.8,3.72,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.00181,36.4,7.04,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.0009390000000000001,68.8,3.72,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.0027,26.9,9.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.00265,26.6,9.61,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.0004980000000000001,133.0,1.93,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.0029000000000000002,25.1,10.2,pytorch+cuda+float16+bnb-4bit+bettertransformer
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.00212,32.1,7.97,pytorch+cuda+float16+bnb-4bit+bettertransformer
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.0022,29.4,8.71,pytorch+cuda+float16+bnb-4bit+bettertransformer
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.00238,30.0,8.53,pytorch+cuda+float16+bnb-4bit+bettertransformer
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.0024200000000000003,28.8,8.88,pytorch+cuda+float16+bnb-4bit+bettertransformer
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.00128,51.4,4.98,pytorch+cuda+float16+bnb-4bit+bettertransformer
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.00346,22.3,11.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.00046499999999999997,134.0,1.91,pytorch+cuda+float16+bnb-4bit+bettertransformer
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.00048400000000000006,131.0,1.96,pytorch+cuda+float16+bnb-4bit+bettertransformer
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.000475,133.0,1.92,pytorch+cuda+float16+bnb-4bit+bettertransformer
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.00048100000000000004,133.0,1.92,pytorch+cuda+float16+bnb-4bit+bettertransformer
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.000485,133.0,1.93,pytorch+cuda+float16+bnb-4bit+bettertransformer
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.0021,32.5,7.88,pytorch+cuda+float16+bnb-4bit+bettertransformer
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.00206,32.4,7.91,pytorch+cuda+float16+bnb-4bit+bettertransformer
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.0021,32.3,7.92,pytorch+cuda+float16+bnb-4bit+bettertransformer
Deci/DeciLM-7B,7.0,NVIDIA A100-SXM4-80GB,0.0034300000000000003,21.7,11.8,pytorch+cuda+float16+bnb-4bit+bettertransformer
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.00176,44.4,5.77,pytorch+cuda+float16+bnb-4bit+bettertransformer
mistralai/Mistral-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.0037,19.8,12.9,pytorch+cuda+float16+bnb-4bit+bettertransformer
mistralai/Mixtral-8x7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00732,9.66,26.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.00298,24.6,10.4,pytorch+cuda+float16+bnb-4bit+bettertransformer
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.00294,24.2,10.6,pytorch+cuda+float16+bnb-4bit+bettertransformer
matsuo-lab/weblab-10b,10.0,NVIDIA A100-SXM4-80GB,0.00363,23.7,10.8,pytorch+cuda+float16+bnb-4bit+bettertransformer
augmxnt/shisa-base-7b-v1,7.0,NVIDIA A100-SXM4-80GB,0.00378,20.0,12.8,pytorch+cuda+float16+bnb-4bit+bettertransformer
uukuguy/Orca-2-7b-f16,7.0,NVIDIA A100-SXM4-80GB,0.00348,22.1,11.6,pytorch+cuda+float16+bnb-4bit+bettertransformer
01-ai/Yi-34B-200K,34.0,NVIDIA A100-SXM4-80GB,0.008029999999999999,11.2,22.9,pytorch+cuda+float16+bnb-4bit+bettertransformer
01-ai/Yi-34B,34.0,NVIDIA A100-SXM4-80GB,0.00807,11.1,23.0,pytorch+cuda+float16+bnb-4bit+bettertransformer
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.0033699999999999997,22.3,11.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.00334,22.3,11.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
scb10x/typhoon-7b,7.0,NVIDIA A100-SXM4-80GB,0.0037199999999999998,20.2,12.7,pytorch+cuda+float16+bnb-4bit+bettertransformer
TheBloke/Llama-2-13B-fp16,13.0,NVIDIA A100-SXM4-80GB,0.00457,17.7,14.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.0036899999999999997,20.6,12.4,pytorch+cuda+float16+bnb-4bit+bettertransformer
Salesforce/codegen-16B-nl,16.0,NVIDIA A100-SXM4-80GB,0.004560000000000001,19.2,13.3,pytorch+cuda+float16+bnb-4bit+bettertransformer
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.0037199999999999998,20.5,12.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.00347,22.3,11.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
deepseek-ai/deepseek-llm-67b-base,67.0,NVIDIA A100-SXM4-80GB,0.0146,6.02,42.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
cyberagent/calm2-7b-chat,7.0,NVIDIA A100-SXM4-80GB,0.0034300000000000003,22.3,11.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.00341,22.1,11.6,pytorch+cuda+float16+bnb-4bit+bettertransformer
itsliupeng/openllama-7b-base,7.0,NVIDIA A100-SXM4-80GB,0.0034000000000000002,22.5,11.4,pytorch+cuda+float16+bnb-4bit+bettertransformer
itsliupeng/Mixtral-8x7B-v0.1-top3,7.0,NVIDIA A100-SXM4-80GB,0.00919,7.85,32.6,pytorch+cuda+float16+bnb-4bit+bettertransformer
itsliupeng/openllama-7b-icl,7.0,NVIDIA A100-SXM4-80GB,0.00342,22.5,11.4,pytorch+cuda+float16+bnb-4bit+bettertransformer
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.000478,131.0,1.95,pytorch+cuda+float16+bnb-4bit+bettertransformer
chargoddard/Yi-34B-Llama,34.0,NVIDIA A100-SXM4-80GB,0.008029999999999999,11.2,22.9,pytorch+cuda+float16+bnb-4bit+bettertransformer
chargoddard/llama-2-26b-trenchcoat-stack,26.0,NVIDIA A100-SXM4-80GB,0.009000000000000001,8.95,28.6,pytorch+cuda+float16+bnb-4bit+bettertransformer
bigscience/bloom-7b1,7.0,NVIDIA A100-SXM4-80GB,0.00262,30.9,8.29,pytorch+cuda+float16+bnb-4bit+bettertransformer
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.0023,31.6,8.09,pytorch+cuda+float16+bnb-4bit+bettertransformer
BEE-spoke-data/Mixtral-GQA-400m-v2,0.4,NVIDIA A100-SXM4-80GB,0.00122,54.2,4.72,pytorch+cuda+float16+bnb-4bit+bettertransformer
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.0009379999999999999,69.9,3.66,pytorch+cuda+float16+bnb-4bit+bettertransformer
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.000583,111.0,2.3,pytorch+cuda+float16+bnb-4bit+bettertransformer
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.000583,112.0,2.28,pytorch+cuda+float16+bnb-4bit+bettertransformer
seungduk/KoSOLAR-10.7B-v0.1,10.7,NVIDIA A100-SXM4-80GB,0.00519,14.5,17.7,pytorch+cuda+float16+bnb-4bit+bettertransformer
TurkuNLP/gpt3-finnish-13B,13.0,NVIDIA A100-SXM4-80GB,0.0038500000000000006,23.3,11.0,pytorch+cuda+float16+bnb-4bit+bettertransformer
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.0022800000000000003,30.1,8.51,pytorch+cuda+float16+bnb-4bit+bettertransformer
stabilityai/japanese-stablelm-base-gamma-7b,7.0,NVIDIA A100-SXM4-80GB,0.00367,20.3,12.6,pytorch+cuda+float16+bnb-4bit+bettertransformer
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.00208,41.2,6.21,pytorch+cuda+float16+bnb-4bit+bettertransformer
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.0015099999999999998,53.2,4.81,pytorch+cuda+float16+bnb-4bit+bettertransformer
huggyllama/llama-65b,65.0,NVIDIA A100-SXM4-80GB,0.014199999999999999,6.2,41.3,pytorch+cuda+float16+bnb-4bit+bettertransformer
huggyllama/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00457,17.9,14.3,pytorch+cuda+float16+bnb-4bit+bettertransformer
NucleusAI/nucleus-22B-token-500B,22.0,NVIDIA A100-SXM4-80GB,0.00539,17.0,15.1,pytorch+cuda+float16+bnb-4bit+bettertransformer
Walmart-the-bag/Influxient-4x13B,13.0,NVIDIA A100-SXM4-80GB,0.00933,7.98,32.1,pytorch+cuda+float16+bnb-4bit+bettertransformer
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.00036399999999999996,175.0,1.46,pytorch+cuda+float16+bnb-4bit+bettertransformer
roneneldan/TinyStories-1M,0.001,NVIDIA A100-SXM4-80GB,0.000683,90.8,2.82,pytorch+cuda+float16+bnb-4bit+bettertransformer
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.000668,95.2,2.69,pytorch+cuda+float16+bnb-4bit+bettertransformer
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.000687,93.8,2.73,pytorch+cuda+float16+bnb-4bit+bettertransformer
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.000674,93.8,2.73,pytorch+cuda+float16+bnb-4bit+bettertransformer
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.000486,156.0,1.64,pytorch+cuda+float16+bnb-4bit+bettertransformer
openlm-research/open_llama_3b_v2,3.0,NVIDIA A100-SXM4-80GB,0.00274,26.0,9.85,pytorch+cuda+float16+bnb-4bit+bettertransformer
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.00344,22.3,11.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.00346,22.3,11.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
openlm-research/open_llama_3b,3.0,NVIDIA A100-SXM4-80GB,0.00281,26.1,9.79,pytorch+cuda+float16+bnb-4bit+bettertransformer
openlm-research/open_llama_13b,13.0,NVIDIA A100-SXM4-80GB,0.00454,17.9,14.3,pytorch+cuda+float16+bnb-4bit+bettertransformer
abhinand/tamil-llama-7b-base-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.0033699999999999997,22.5,11.4,pytorch+cuda+float16+bnb-4bit+bettertransformer
abhinand/tamil-llama-13b-base-v0.1,13.0,NVIDIA A100-SXM4-80GB,0.00462,17.5,14.6,pytorch+cuda+float16+bnb-4bit+bettertransformer
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.00292,27.1,9.43,pytorch+cuda+float16+bnb-4bit+bettertransformer
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.00264,26.8,9.56,pytorch+cuda+float16+bnb-4bit+bettertransformer
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.0028899999999999998,27.1,9.45,pytorch+cuda+float16+bnb-4bit+bettertransformer
Devio/test-22B,22.0,NVIDIA A100-SXM4-80GB,0.005370000000000001,16.8,15.2,pytorch+cuda+float16+bnb-4bit+bettertransformer
Delcos/Starling-LM-11B-alpha,11.0,NVIDIA A100-SXM4-80GB,0.00597,12.7,20.1,pytorch+cuda+float16+bnb-4bit+bettertransformer
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.0038900000000000002,18.3,14.0,pytorch+cuda+float16+bnb-4bit+bettertransformer
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.00261,26.8,9.57,pytorch+cuda+float16+bnb-4bit+bettertransformer
upstage/SOLAR-10.7B-v1.0,10.7,NVIDIA A100-SXM4-80GB,0.00521,14.5,17.7,pytorch+cuda+float16+bnb-4bit+bettertransformer
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.00335,22.5,11.4,pytorch+cuda+float16+bnb-4bit+bettertransformer
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00347,22.3,11.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.0035,22.5,11.4,pytorch+cuda+float16+bnb-4bit+bettertransformer
codellama/CodeLlama-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.004549999999999999,17.7,14.5,pytorch+cuda+float16+bnb-4bit+bettertransformer
cloudyu/Mixtral_7Bx2_MoE_13B,7.0,NVIDIA A100-SXM4-80GB,0.00656,11.2,22.8,pytorch+cuda+float16+bnb-4bit+bettertransformer
cloudyu/Mixtral_7Bx2_MoE,7.0,NVIDIA A100-SXM4-80GB,0.006520000000000001,11.2,22.8,pytorch+cuda+float16+bnb-4bit+bettertransformer
cloudyu/Mixtral_7Bx4_MOE_24B,7.0,NVIDIA A100-SXM4-80GB,0.007,10.3,24.9,pytorch+cuda+float16+bnb-4bit+bettertransformer
EleutherAI/gpt-neox-20b,20.0,NVIDIA A100-SXM4-80GB,0.00282,27.5,9.32,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.00167,42.7,6.0,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00168,40.8,6.28,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.00116,55.4,4.62,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.00213,31.2,8.21,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-12b,12.0,NVIDIA A100-SXM4-80GB,0.00195,37.7,6.79,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00116,54.8,4.67,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-12b-deduped,12.0,NVIDIA A100-SXM4-80GB,0.00196,37.6,6.8,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.000793,79.8,3.21,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.000538,115.0,2.22,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/polyglot-ko-12.8b,12.8,NVIDIA A100-SXM4-80GB,0.00216,33.8,7.57,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.0011099999999999999,56.0,4.57,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.00108,60.8,4.21,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.000581,107.0,2.39,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.0011200000000000001,55.9,4.58,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.000594,106.0,2.41,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.0015400000000000001,42.6,6.01,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.00152,42.9,5.97,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.000312,202.0,1.27,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00142,46.4,5.52,pytorch+cuda+float16+gptq-4bit+exllama-v2
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.00124,51.1,5.01,pytorch+cuda+float16+gptq-4bit+exllama-v2
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.00133,47.4,5.4,pytorch+cuda+float16+gptq-4bit+exllama-v2
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.00128,52.2,4.9,pytorch+cuda+float16+gptq-4bit+exllama-v2
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.00126,52.6,4.87,pytorch+cuda+float16+gptq-4bit+exllama-v2
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.000734,81.5,3.14,pytorch+cuda+float16+gptq-4bit+exllama-v2
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.00177,39.6,6.46,pytorch+cuda+float16+gptq-4bit+exllama-v2
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.00030199999999999997,205.0,1.25,pytorch+cuda+float16+gptq-4bit+exllama-v2
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000303,202.0,1.27,pytorch+cuda+float16+gptq-4bit+exllama-v2
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.000299,203.0,1.26,pytorch+cuda+float16+gptq-4bit+exllama-v2
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000306,198.0,1.29,pytorch+cuda+float16+gptq-4bit+exllama-v2
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.000306,200.0,1.28,pytorch+cuda+float16+gptq-4bit+exllama-v2
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.00125,50.6,5.06,pytorch+cuda+float16+gptq-4bit+exllama-v2
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.0012300000000000002,50.1,5.11,pytorch+cuda+float16+gptq-4bit+exllama-v2
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.0012300000000000002,51.4,4.98,pytorch+cuda+float16+gptq-4bit+exllama-v2
instructkr/ko-wand-136M,0.136,NVIDIA A100-SXM4-80GB,0.000511,122.0,2.1,pytorch+cuda+float16+gptq-4bit+exllama-v2
meta-llama/Llama-2-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00173,39.7,6.45,pytorch+cuda+float16+gptq-4bit+exllama-v2
meta-llama/Llama-2-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.0023,31.9,8.02,pytorch+cuda+float16+gptq-4bit+exllama-v2
meta-llama/Llama-2-70b-hf,70.0,NVIDIA A100-SXM4-80GB,0.0061,14.4,17.8,pytorch+cuda+float16+gptq-4bit+exllama-v2
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.000909,76.4,3.35,pytorch+cuda+float16+gptq-4bit+exllama-v2
mistralai/Mistral-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00212,32.7,7.82,pytorch+cuda+float16+gptq-4bit+exllama-v2
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.00177,37.1,6.9,pytorch+cuda+float16+gptq-4bit+exllama-v2
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.00175,37.8,6.78,pytorch+cuda+float16+gptq-4bit+exllama-v2
matsuo-lab/weblab-10b,10.0,NVIDIA A100-SXM4-80GB,0.0020099999999999996,37.3,6.86,pytorch+cuda+float16+gptq-4bit+exllama-v2
augmxnt/shisa-base-7b-v1,7.0,NVIDIA A100-SXM4-80GB,0.00216,32.4,7.89,pytorch+cuda+float16+gptq-4bit+exllama-v2
uukuguy/Orca-2-7b-f16,7.0,NVIDIA A100-SXM4-80GB,0.00176,40.1,6.38,pytorch+cuda+float16+gptq-4bit+exllama-v2
01-ai/Yi-34B-200K,34.0,NVIDIA A100-SXM4-80GB,0.00412,19.4,13.2,pytorch+cuda+float16+gptq-4bit+exllama-v2
01-ai/Yi-34B,34.0,NVIDIA A100-SXM4-80GB,0.00418,19.0,13.5,pytorch+cuda+float16+gptq-4bit+exllama-v2
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.0018599999999999999,36.1,7.09,pytorch+cuda+float16+gptq-4bit+exllama-v2
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.00183,37.0,6.92,pytorch+cuda+float16+gptq-4bit+exllama-v2
scb10x/typhoon-7b,7.0,NVIDIA A100-SXM4-80GB,0.00215,32.2,7.94,pytorch+cuda+float16+gptq-4bit+exllama-v2
TheBloke/Llama-2-13B-fp16,13.0,NVIDIA A100-SXM4-80GB,0.00232,31.6,8.11,pytorch+cuda+float16+gptq-4bit+exllama-v2
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.00245,27.1,9.45,pytorch+cuda+float16+gptq-4bit+exllama-v2
Salesforce/codegen-16B-nl,16.0,NVIDIA A100-SXM4-80GB,0.00275,26.1,9.79,pytorch+cuda+float16+gptq-4bit+exllama-v2
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.0024600000000000004,27.1,9.45,pytorch+cuda+float16+gptq-4bit+exllama-v2
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.00175,39.4,6.49,pytorch+cuda+float16+gptq-4bit+exllama-v2
deepseek-ai/deepseek-llm-67b-base,67.0,NVIDIA A100-SXM4-80GB,0.00681,12.1,21.1,pytorch+cuda+float16+gptq-4bit+exllama-v2
KnutJaegersberg/Qwen-1_8B-Llamafied,8.0,NVIDIA A100-SXM4-80GB,0.0012699999999999999,52.7,4.86,pytorch+cuda+float16+gptq-4bit+exllama-v2
cyberagent/calm2-7b-chat,7.0,NVIDIA A100-SXM4-80GB,0.0018,39.0,6.57,pytorch+cuda+float16+gptq-4bit+exllama-v2
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.00185,36.6,6.99,pytorch+cuda+float16+gptq-4bit+exllama-v2
itsliupeng/openllama-7b-base,7.0,NVIDIA A100-SXM4-80GB,0.00174,37.9,6.75,pytorch+cuda+float16+gptq-4bit+exllama-v2
itsliupeng/openllama-7b-icl,7.0,NVIDIA A100-SXM4-80GB,0.00178,39.6,6.46,pytorch+cuda+float16+gptq-4bit+exllama-v2
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.000304,206.0,1.24,pytorch+cuda+float16+gptq-4bit+exllama-v2
facebook/xglm-7.5B,7.5,NVIDIA A100-SXM4-80GB,0.00141,52.8,4.85,pytorch+cuda+float16+gptq-4bit+exllama-v2
facebook/xglm-564M,0.564,NVIDIA A100-SXM4-80GB,0.0008719999999999999,74.0,3.46,pytorch+cuda+float16+gptq-4bit+exllama-v2
facebook/xglm-4.5B,4.5,NVIDIA A100-SXM4-80GB,0.0018599999999999999,36.7,6.98,pytorch+cuda+float16+gptq-4bit+exllama-v2
chargoddard/Yi-34B-Llama,34.0,NVIDIA A100-SXM4-80GB,0.0041400000000000005,19.4,13.2,pytorch+cuda+float16+gptq-4bit+exllama-v2
chargoddard/llama-2-26b-trenchcoat-stack,26.0,NVIDIA A100-SXM4-80GB,0.004560000000000001,16.0,16.0,pytorch+cuda+float16+gptq-4bit+exllama-v2
bigscience/bloom-7b1,7.0,NVIDIA A100-SXM4-80GB,0.0013599999999999999,54.0,4.74,pytorch+cuda+float16+gptq-4bit+exllama-v2
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.00122,55.5,4.61,pytorch+cuda+float16+gptq-4bit+exllama-v2
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.000583,109.0,2.35,pytorch+cuda+float16+gptq-4bit+exllama-v2
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.000339,184.0,1.39,pytorch+cuda+float16+gptq-4bit+exllama-v2
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.00035800000000000003,173.0,1.48,pytorch+cuda+float16+gptq-4bit+exllama-v2
seungduk/KoSOLAR-10.7B-v0.1,10.7,NVIDIA A100-SXM4-80GB,0.00293,24.6,10.4,pytorch+cuda+float16+gptq-4bit+exllama-v2
TurkuNLP/gpt3-finnish-13B,13.0,NVIDIA A100-SXM4-80GB,0.00188,41.4,6.18,pytorch+cuda+float16+gptq-4bit+exllama-v2
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.00122,52.8,4.85,pytorch+cuda+float16+gptq-4bit+exllama-v2
stabilityai/japanese-stablelm-base-gamma-7b,7.0,NVIDIA A100-SXM4-80GB,0.0021,32.9,7.78,pytorch+cuda+float16+gptq-4bit+exllama-v2
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.000984,79.3,3.23,pytorch+cuda+float16+gptq-4bit+exllama-v2
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.0008500000000000001,79.5,3.22,pytorch+cuda+float16+gptq-4bit+exllama-v2
huggyllama/llama-65b,65.0,NVIDIA A100-SXM4-80GB,0.00552,16.1,15.9,pytorch+cuda+float16+gptq-4bit+exllama-v2
huggyllama/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.0023,32.1,7.98,pytorch+cuda+float16+gptq-4bit+exllama-v2
NucleusAI/nucleus-22B-token-500B,22.0,NVIDIA A100-SXM4-80GB,0.00255,31.7,8.08,pytorch+cuda+float16+gptq-4bit+exllama-v2
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.00020800000000000001,302.0,0.847,pytorch+cuda+float16+gptq-4bit+exllama-v2
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.00036899999999999997,170.0,1.51,pytorch+cuda+float16+gptq-4bit+exllama-v2
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.000367,168.0,1.52,pytorch+cuda+float16+gptq-4bit+exllama-v2
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.00025400000000000005,273.0,0.938,pytorch+cuda+float16+gptq-4bit+exllama-v2
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.00179,39.3,6.52,pytorch+cuda+float16+gptq-4bit+exllama-v2
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.00179,38.9,6.58,pytorch+cuda+float16+gptq-4bit+exllama-v2
openlm-research/open_llama_13b,13.0,NVIDIA A100-SXM4-80GB,0.00232,31.4,8.16,pytorch+cuda+float16+gptq-4bit+exllama-v2
abhinand/tamil-llama-7b-base-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00179,39.4,6.5,pytorch+cuda+float16+gptq-4bit+exllama-v2
abhinand/tamil-llama-13b-base-v0.1,13.0,NVIDIA A100-SXM4-80GB,0.00229,32.0,8.01,pytorch+cuda+float16+gptq-4bit+exllama-v2
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.00166,40.6,6.3,pytorch+cuda+float16+gptq-4bit+exllama-v2
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.00152,41.6,6.16,pytorch+cuda+float16+gptq-4bit+exllama-v2
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00166,41.8,6.12,pytorch+cuda+float16+gptq-4bit+exllama-v2
Devio/test-22B,22.0,NVIDIA A100-SXM4-80GB,0.00251,31.8,8.05,pytorch+cuda+float16+gptq-4bit+exllama-v2
Delcos/Starling-LM-11B-alpha,11.0,NVIDIA A100-SXM4-80GB,0.00334,20.8,12.3,pytorch+cuda+float16+gptq-4bit+exllama-v2
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.0022400000000000002,28.9,8.85,pytorch+cuda+float16+gptq-4bit+exllama-v2
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.00161,41.9,6.11,pytorch+cuda+float16+gptq-4bit+exllama-v2
upstage/SOLAR-10.7B-v1.0,10.7,NVIDIA A100-SXM4-80GB,0.0029000000000000002,24.2,10.6,pytorch+cuda+float16+gptq-4bit+exllama-v2
huggingface/llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00177,39.4,6.5,pytorch+cuda+float16+gptq-4bit+exllama-v2
huggingface/llama-65b,65.0,NVIDIA A100-SXM4-80GB,0.0055899999999999995,15.6,16.4,pytorch+cuda+float16+gptq-4bit+exllama-v2
huggingface/llama-30b,30.0,NVIDIA A100-SXM4-80GB,0.0038500000000000006,21.3,12.0,pytorch+cuda+float16+gptq-4bit+exllama-v2
huggingface/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.0023599999999999997,32.2,7.96,pytorch+cuda+float16+gptq-4bit+exllama-v2
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.00191,35.8,7.16,pytorch+cuda+float16+gptq-4bit+exllama-v2
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00175,39.6,6.46,pytorch+cuda+float16+gptq-4bit+exllama-v2
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00174,39.5,6.48,pytorch+cuda+float16+gptq-4bit+exllama-v2
codellama/CodeLlama-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.00232,31.7,8.07,pytorch+cuda+float16+gptq-4bit+exllama-v2
EleutherAI/gpt-neox-20b,20.0,NVIDIA A100-SXM4-80GB,0.00567,14.7,17.4,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.0031,25.3,10.1,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.0030800000000000003,25.1,10.2,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.00202,32.8,7.8,pytorch+cuda+float16+bnb-4bit
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.00353,20.5,12.5,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-12b,12.0,NVIDIA A100-SXM4-80GB,0.00364,22.1,11.6,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.0020099999999999996,33.4,7.67,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-12b-deduped,12.0,NVIDIA A100-SXM4-80GB,0.00364,22.1,11.6,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.00137,49.9,5.13,pytorch+cuda+float16+bnb-4bit
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.00104,59.8,4.28,pytorch+cuda+float16+bnb-4bit
EleutherAI/polyglot-ko-12.8b,12.8,NVIDIA A100-SXM4-80GB,0.00398,20.0,12.8,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.0018700000000000001,34.3,7.47,pytorch+cuda+float16+bnb-4bit
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.00215,32.2,7.95,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.000973,65.0,3.94,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.00191,33.6,7.61,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.000965,65.8,3.89,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.0028,24.9,10.3,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.00281,25.3,10.1,pytorch+cuda+float16+bnb-4bit
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.0005020000000000001,127.0,2.01,pytorch+cuda+float16+bnb-4bit
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00295,24.4,10.5,pytorch+cuda+float16+bnb-4bit
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.00215,31.3,8.18,pytorch+cuda+float16+bnb-4bit
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.0022500000000000003,28.3,9.05,pytorch+cuda+float16+bnb-4bit
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.0024,30.2,8.49,pytorch+cuda+float16+bnb-4bit
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.00238,29.9,8.57,pytorch+cuda+float16+bnb-4bit
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.00122,53.3,4.8,pytorch+cuda+float16+bnb-4bit
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.00332,22.9,11.2,pytorch+cuda+float16+bnb-4bit
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.0004980000000000001,125.0,2.05,pytorch+cuda+float16+bnb-4bit
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000496,126.0,2.03,pytorch+cuda+float16+bnb-4bit
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.000491,127.0,2.01,pytorch+cuda+float16+bnb-4bit
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.00048800000000000004,125.0,2.04,pytorch+cuda+float16+bnb-4bit
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.00048800000000000004,127.0,2.01,pytorch+cuda+float16+bnb-4bit
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.0021,31.6,8.11,pytorch+cuda+float16+bnb-4bit
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.00217,31.1,8.23,pytorch+cuda+float16+bnb-4bit
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.00212,31.1,8.24,pytorch+cuda+float16+bnb-4bit
Deci/DeciLM-7B,7.0,NVIDIA A100-SXM4-80GB,0.0035099999999999997,21.3,12.0,pytorch+cuda+float16+bnb-4bit
team-lucid/mptk-1b,1.0,NVIDIA A100-SXM4-80GB,0.00148,46.7,5.48,pytorch+cuda+float16+bnb-4bit
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.00175,44.8,5.72,pytorch+cuda+float16+bnb-4bit
mistralai/Mistral-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00364,20.5,12.5,pytorch+cuda+float16+bnb-4bit
mistralai/Mixtral-8x7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.0074800000000000005,9.45,27.1,pytorch+cuda+float16+bnb-4bit
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.00324,22.3,11.5,pytorch+cuda+float16+bnb-4bit
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.00318,22.3,11.5,pytorch+cuda+float16+bnb-4bit
matsuo-lab/weblab-10b,10.0,NVIDIA A100-SXM4-80GB,0.0035499999999999998,22.7,11.3,pytorch+cuda+float16+bnb-4bit
augmxnt/shisa-base-7b-v1,7.0,NVIDIA A100-SXM4-80GB,0.0037,20.3,12.6,pytorch+cuda+float16+bnb-4bit
uukuguy/Orca-2-7b-f16,7.0,NVIDIA A100-SXM4-80GB,0.0034300000000000003,22.7,11.3,pytorch+cuda+float16+bnb-4bit
01-ai/Yi-34B-200K,34.0,NVIDIA A100-SXM4-80GB,0.00809,10.9,23.4,pytorch+cuda+float16+bnb-4bit
01-ai/Yi-34B,34.0,NVIDIA A100-SXM4-80GB,0.0081,11.0,23.3,pytorch+cuda+float16+bnb-4bit
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.0034300000000000003,21.7,11.8,pytorch+cuda+float16+bnb-4bit
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.00344,21.7,11.8,pytorch+cuda+float16+bnb-4bit
scb10x/typhoon-7b,7.0,NVIDIA A100-SXM4-80GB,0.0038,20.2,12.7,pytorch+cuda+float16+bnb-4bit
TheBloke/Llama-2-13B-fp16,13.0,NVIDIA A100-SXM4-80GB,0.00433,18.3,14.0,pytorch+cuda+float16+bnb-4bit
mosaicml/mpt-30b,30.0,NVIDIA A100-SXM4-80GB,0.00638,13.8,18.6,pytorch+cuda+float16+bnb-4bit
mosaicml/mpt-7b,7.0,NVIDIA A100-SXM4-80GB,0.00248,33.1,7.74,pytorch+cuda+float16+bnb-4bit
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.00392,19.2,13.3,pytorch+cuda+float16+bnb-4bit
Salesforce/codegen-16B-nl,16.0,NVIDIA A100-SXM4-80GB,0.0044800000000000005,18.4,13.9,pytorch+cuda+float16+bnb-4bit
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.0039,19.2,13.3,pytorch+cuda+float16+bnb-4bit
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.0033900000000000002,22.7,11.3,pytorch+cuda+float16+bnb-4bit
deepseek-ai/deepseek-llm-67b-base,67.0,NVIDIA A100-SXM4-80GB,0.015099999999999999,5.91,43.3,pytorch+cuda+float16+bnb-4bit
cyberagent/calm2-7b-chat,7.0,NVIDIA A100-SXM4-80GB,0.00342,22.5,11.4,pytorch+cuda+float16+bnb-4bit
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.00347,21.2,12.1,pytorch+cuda+float16+bnb-4bit
itsliupeng/openllama-7b-base,7.0,NVIDIA A100-SXM4-80GB,0.0034300000000000003,22.9,11.2,pytorch+cuda+float16+bnb-4bit
itsliupeng/Mixtral-8x7B-v0.1-top3,7.0,NVIDIA A100-SXM4-80GB,0.009219999999999999,7.8,32.8,pytorch+cuda+float16+bnb-4bit
itsliupeng/openllama-7b-icl,7.0,NVIDIA A100-SXM4-80GB,0.00331,22.9,11.2,pytorch+cuda+float16+bnb-4bit
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.000492,126.0,2.03,pytorch+cuda+float16+bnb-4bit
tiiuae/falcon-rw-1b,1.0,NVIDIA A100-SXM4-80GB,0.00179,38.8,6.6,pytorch+cuda+float16+bnb-4bit
tiiuae/falcon-7b,7.0,NVIDIA A100-SXM4-80GB,0.0030199999999999997,25.9,9.9,pytorch+cuda+float16+bnb-4bit
tiiuae/falcon-40b,40.0,NVIDIA A100-SXM4-80GB,0.0106,7.85,32.6,pytorch+cuda+float16+bnb-4bit
facebook/xglm-7.5B,7.5,NVIDIA A100-SXM4-80GB,0.00301,25.1,10.2,pytorch+cuda+float16+bnb-4bit
facebook/xglm-564M,0.564,NVIDIA A100-SXM4-80GB,0.0019199999999999998,33.5,7.64,pytorch+cuda+float16+bnb-4bit
facebook/xglm-4.5B,4.5,NVIDIA A100-SXM4-80GB,0.00416,17.1,15.0,pytorch+cuda+float16+bnb-4bit
chargoddard/Yi-34B-Llama,34.0,NVIDIA A100-SXM4-80GB,0.00814,10.9,23.4,pytorch+cuda+float16+bnb-4bit
chargoddard/llama-2-26b-trenchcoat-stack,26.0,NVIDIA A100-SXM4-80GB,0.008790000000000001,9.14,28.0,pytorch+cuda+float16+bnb-4bit
bigscience/bloom-7b1,7.0,NVIDIA A100-SXM4-80GB,0.00262,30.3,8.44,pytorch+cuda+float16+bnb-4bit
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.00235,30.5,8.38,pytorch+cuda+float16+bnb-4bit
BEE-spoke-data/Mixtral-GQA-400m-v2,0.4,NVIDIA A100-SXM4-80GB,0.00124,53.9,4.75,pytorch+cuda+float16+bnb-4bit
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.0009530000000000001,67.7,3.78,pytorch+cuda+float16+bnb-4bit
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.0005740000000000001,112.0,2.29,pytorch+cuda+float16+bnb-4bit
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.000587,110.0,2.33,pytorch+cuda+float16+bnb-4bit
seungduk/KoSOLAR-10.7B-v0.1,10.7,NVIDIA A100-SXM4-80GB,0.00502,14.8,17.3,pytorch+cuda+float16+bnb-4bit
TurkuNLP/gpt3-finnish-13B,13.0,NVIDIA A100-SXM4-80GB,0.00368,23.1,11.1,pytorch+cuda+float16+bnb-4bit
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.00219,30.6,8.36,pytorch+cuda+float16+bnb-4bit
stabilityai/japanese-stablelm-base-gamma-7b,7.0,NVIDIA A100-SXM4-80GB,0.0036100000000000004,20.5,12.5,pytorch+cuda+float16+bnb-4bit
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.00206,40.1,6.39,pytorch+cuda+float16+bnb-4bit
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.00161,49.1,5.21,pytorch+cuda+float16+bnb-4bit
stabilityai/stablelm-base-alpha-7b-v2,7.0,NVIDIA A100-SXM4-80GB,0.0029000000000000002,26.8,9.56,pytorch+cuda+float16+bnb-4bit
huggyllama/llama-65b,65.0,NVIDIA A100-SXM4-80GB,0.014199999999999999,6.2,41.3,pytorch+cuda+float16+bnb-4bit
huggyllama/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00432,18.3,14.0,pytorch+cuda+float16+bnb-4bit
NucleusAI/nucleus-22B-token-500B,22.0,NVIDIA A100-SXM4-80GB,0.00524,16.8,15.2,pytorch+cuda+float16+bnb-4bit
Walmart-the-bag/Influxient-4x13B,13.0,NVIDIA A100-SXM4-80GB,0.00925,7.98,32.1,pytorch+cuda+float16+bnb-4bit
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.000378,172.0,1.49,pytorch+cuda+float16+bnb-4bit
roneneldan/TinyStories-1M,0.001,NVIDIA A100-SXM4-80GB,0.00066,93.8,2.73,pytorch+cuda+float16+bnb-4bit
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.00067,92.8,2.76,pytorch+cuda+float16+bnb-4bit
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.0006889999999999999,91.1,2.81,pytorch+cuda+float16+bnb-4bit
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.0006770000000000001,92.1,2.78,pytorch+cuda+float16+bnb-4bit
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.000456,162.0,1.58,pytorch+cuda+float16+bnb-4bit
openlm-research/open_llama_3b_v2,3.0,NVIDIA A100-SXM4-80GB,0.0027,26.6,9.61,pytorch+cuda+float16+bnb-4bit
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.00332,23.1,11.1,pytorch+cuda+float16+bnb-4bit
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.00334,23.1,11.1,pytorch+cuda+float16+bnb-4bit
openlm-research/open_llama_3b,3.0,NVIDIA A100-SXM4-80GB,0.0027300000000000002,26.4,9.71,pytorch+cuda+float16+bnb-4bit
openlm-research/open_llama_13b,13.0,NVIDIA A100-SXM4-80GB,0.00435,18.3,14.0,pytorch+cuda+float16+bnb-4bit
abhinand/tamil-llama-7b-base-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00333,23.1,11.1,pytorch+cuda+float16+bnb-4bit
abhinand/tamil-llama-13b-base-v0.1,13.0,NVIDIA A100-SXM4-80GB,0.00438,18.2,14.1,pytorch+cuda+float16+bnb-4bit
RWKV/rwkv-4-3b-pile,3.0,NVIDIA A100-SXM4-80GB,0.003909999999999999,17.5,14.6,pytorch+cuda+float16+bnb-4bit
RWKV/rwkv-4-430m-pile,0.43,NVIDIA A100-SXM4-80GB,0.0027300000000000002,23.3,11.0,pytorch+cuda+float16+bnb-4bit
RWKV/rwkv-4-169m-pile,0.169,NVIDIA A100-SXM4-80GB,0.00139,45.8,5.59,pytorch+cuda+float16+bnb-4bit
RWKV/rwkv-4-7b-pile,7.0,NVIDIA A100-SXM4-80GB,0.0041400000000000005,17.2,14.9,pytorch+cuda+float16+bnb-4bit
RWKV/rwkv-raven-14b,14.0,NVIDIA A100-SXM4-80GB,0.00545,13.8,18.6,pytorch+cuda+float16+bnb-4bit
RWKV/rwkv-4-14b-pile,14.0,NVIDIA A100-SXM4-80GB,0.0055899999999999995,13.6,18.8,pytorch+cuda+float16+bnb-4bit
RWKV/rwkv-4-1b5-pile,1.0,NVIDIA A100-SXM4-80GB,0.0028899999999999998,23.1,11.1,pytorch+cuda+float16+bnb-4bit
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.00315,25.3,10.1,pytorch+cuda+float16+bnb-4bit
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.00276,25.1,10.2,pytorch+cuda+float16+bnb-4bit
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.0030800000000000003,25.1,10.2,pytorch+cuda+float16+bnb-4bit
Devio/test-22B,22.0,NVIDIA A100-SXM4-80GB,0.00529,16.7,15.3,pytorch+cuda+float16+bnb-4bit
internlm/internlm-20b,20.0,NVIDIA A100-SXM4-80GB,0.00763,10.3,24.9,pytorch+cuda+float16+bnb-4bit
Delcos/Starling-LM-11B-alpha,11.0,NVIDIA A100-SXM4-80GB,0.00567,12.9,19.9,pytorch+cuda+float16+bnb-4bit
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.00412,17.2,14.9,pytorch+cuda+float16+bnb-4bit
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.00276,25.3,10.1,pytorch+cuda+float16+bnb-4bit
upstage/SOLAR-10.7B-v1.0,10.7,NVIDIA A100-SXM4-80GB,0.00511,14.4,17.8,pytorch+cuda+float16+bnb-4bit
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.00345,21.5,11.9,pytorch+cuda+float16+bnb-4bit
beomi/KoRWKV-6B,6.0,NVIDIA A100-SXM4-80GB,0.00377,20.2,12.7,pytorch+cuda+float16+bnb-4bit
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00331,23.1,11.1,pytorch+cuda+float16+bnb-4bit
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.0034000000000000002,22.7,11.3,pytorch+cuda+float16+bnb-4bit
codellama/CodeLlama-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.00434,18.4,13.9,pytorch+cuda+float16+bnb-4bit
cloudyu/Mixtral_7Bx2_MoE_13B,7.0,NVIDIA A100-SXM4-80GB,0.006350000000000001,11.2,22.9,pytorch+cuda+float16+bnb-4bit
cloudyu/Mixtral_7Bx2_MoE,7.0,NVIDIA A100-SXM4-80GB,0.006319999999999999,11.1,23.1,pytorch+cuda+float16+bnb-4bit
cloudyu/Mixtral_7Bx4_MOE_24B,7.0,NVIDIA A100-SXM4-80GB,0.00705,10.2,25.1,pytorch+cuda+float16+bnb-4bit
EleutherAI/gpt-neox-20b,20.0,NVIDIA A100-SXM4-80GB,0.00349,23.5,10.9,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.00198,37.4,6.84,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00199,37.5,6.82,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.00137,48.8,5.25,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.00239,29.0,8.84,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-12b,12.0,NVIDIA A100-SXM4-80GB,0.00241,32.9,7.79,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00133,49.5,5.17,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-12b-deduped,12.0,NVIDIA A100-SXM4-80GB,0.00239,33.0,7.76,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.000936,72.3,3.54,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.000625,103.0,2.49,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/polyglot-ko-12.8b,12.8,NVIDIA A100-SXM4-80GB,0.0027199999999999998,29.4,8.72,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.00129,49.0,5.22,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.00129,52.8,4.85,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.0006770000000000001,95.5,2.68,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.0014,49.1,5.21,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.0006799999999999999,92.4,2.77,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.00179,37.8,6.77,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.00178,37.3,6.86,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.000357,180.0,1.42,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00165,41.1,6.23,pytorch+cuda+float16+awq-4bit+gemm
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.00141,48.4,5.29,pytorch+cuda+float16+awq-4bit+gemm
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.00149,44.1,5.81,pytorch+cuda+float16+awq-4bit+gemm
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.0014399999999999999,49.3,5.19,pytorch+cuda+float16+awq-4bit+gemm
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.00142,48.9,5.24,pytorch+cuda+float16+awq-4bit+gemm
Locutusque/TinyMistral-248M-v2,0.248,NVIDIA A100-SXM4-80GB,0.000855,76.6,3.34,pytorch+cuda+float16+awq-4bit+gemm
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.000833,75.7,3.38,pytorch+cuda+float16+awq-4bit+gemm
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.00196,37.0,6.91,pytorch+cuda+float16+awq-4bit+gemm
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.00034700000000000003,182.0,1.41,pytorch+cuda+float16+awq-4bit+gemm
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000357,184.0,1.39,pytorch+cuda+float16+awq-4bit+gemm
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.000367,183.0,1.4,pytorch+cuda+float16+awq-4bit+gemm
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000344,182.0,1.41,pytorch+cuda+float16+awq-4bit+gemm
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.000349,183.0,1.4,pytorch+cuda+float16+awq-4bit+gemm
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.0014399999999999999,47.5,5.39,pytorch+cuda+float16+awq-4bit+gemm
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.0014,47.8,5.36,pytorch+cuda+float16+awq-4bit+gemm
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.00141,45.9,5.58,pytorch+cuda+float16+awq-4bit+gemm
Deci/DeciLM-7B,7.0,NVIDIA A100-SXM4-80GB,0.00212,34.5,7.42,pytorch+cuda+float16+awq-4bit+gemm
robowaifudev/megatron-gpt2-345m,0.345,NVIDIA A100-SXM4-80GB,0.00105,61.8,4.14,pytorch+cuda+float16+awq-4bit+gemm
TencentARC/LLaMA-Pro-8B,8.0,NVIDIA A100-SXM4-80GB,0.00248,29.2,8.77,pytorch+cuda+float16+awq-4bit+gemm
meta-llama/Llama-2-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00199,36.3,7.05,pytorch+cuda+float16+awq-4bit+gemm
meta-llama/Llama-2-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.0027099999999999997,28.5,8.98,pytorch+cuda+float16+awq-4bit+gemm
meta-llama/Llama-2-70b-hf,70.0,NVIDIA A100-SXM4-80GB,0.0072699999999999996,13.5,19.0,pytorch+cuda+float16+awq-4bit+gemm
team-lucid/mptk-1b,1.0,NVIDIA A100-SXM4-80GB,0.000897,76.4,3.35,pytorch+cuda+float16+awq-4bit+gemm
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.00104,69.8,3.67,pytorch+cuda+float16+awq-4bit+gemm
mistralai/Mistral-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00232,30.9,8.29,pytorch+cuda+float16+awq-4bit+gemm
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.00213,32.6,7.85,pytorch+cuda+float16+awq-4bit+gemm
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.0020099999999999996,33.5,7.64,pytorch+cuda+float16+awq-4bit+gemm
matsuo-lab/weblab-10b,10.0,NVIDIA A100-SXM4-80GB,0.00235,32.7,7.84,pytorch+cuda+float16+awq-4bit+gemm
augmxnt/shisa-base-7b-v1,7.0,NVIDIA A100-SXM4-80GB,0.00238,29.5,8.69,pytorch+cuda+float16+awq-4bit+gemm
AI-Sweden-Models/gpt-sw3-126m,0.126,NVIDIA A100-SXM4-80GB,0.000468,136.0,1.88,pytorch+cuda+float16+awq-4bit+gemm
AI-Sweden-Models/gpt-sw3-6.7b-v2,6.7,NVIDIA A100-SXM4-80GB,0.0015400000000000001,53.8,4.76,pytorch+cuda+float16+awq-4bit+gemm
AI-Sweden-Models/gpt-sw3-40b,40.0,NVIDIA A100-SXM4-80GB,0.0057799999999999995,16.5,15.5,pytorch+cuda+float16+awq-4bit+gemm
AI-Sweden-Models/gpt-sw3-20b,20.0,NVIDIA A100-SXM4-80GB,0.00333,27.1,9.46,pytorch+cuda+float16+awq-4bit+gemm
AI-Sweden-Models/gpt-sw3-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.0015099999999999998,54.2,4.72,pytorch+cuda+float16+awq-4bit+gemm
AI-Sweden-Models/gpt-sw3-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.000958,72.7,3.52,pytorch+cuda+float16+awq-4bit+gemm
AI-Sweden-Models/gpt-sw3-356m,0.356,NVIDIA A100-SXM4-80GB,0.000937,69.8,3.67,pytorch+cuda+float16+awq-4bit+gemm
uukuguy/Orca-2-7b-f16,7.0,NVIDIA A100-SXM4-80GB,0.00202,36.5,7.01,pytorch+cuda+float16+awq-4bit+gemm
01-ai/Yi-34B-200K,34.0,NVIDIA A100-SXM4-80GB,0.004889999999999999,17.9,14.3,pytorch+cuda+float16+awq-4bit+gemm
01-ai/Yi-34B,34.0,NVIDIA A100-SXM4-80GB,0.00498,17.8,14.4,pytorch+cuda+float16+awq-4bit+gemm
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.0020700000000000002,34.2,7.49,pytorch+cuda+float16+awq-4bit+gemm
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.00214,33.5,7.64,pytorch+cuda+float16+awq-4bit+gemm
TheBloke/Llama-2-13B-fp16,13.0,NVIDIA A100-SXM4-80GB,0.00274,28.9,8.86,pytorch+cuda+float16+awq-4bit+gemm
mosaicml/mpt-30b,30.0,NVIDIA A100-SXM4-80GB,0.00304,33.9,7.55,pytorch+cuda+float16+awq-4bit+gemm
mosaicml/mpt-7b,7.0,NVIDIA A100-SXM4-80GB,0.00143,55.5,4.61,pytorch+cuda+float16+awq-4bit+gemm
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.0027099999999999997,25.3,10.1,pytorch+cuda+float16+awq-4bit+gemm
Salesforce/codegen-16B-nl,16.0,NVIDIA A100-SXM4-80GB,0.00319,24.4,10.5,pytorch+cuda+float16+awq-4bit+gemm
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.0027300000000000002,25.9,9.9,pytorch+cuda+float16+awq-4bit+gemm
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.0021,35.4,7.23,pytorch+cuda+float16+awq-4bit+gemm
deepseek-ai/deepseek-llm-67b-base,67.0,NVIDIA A100-SXM4-80GB,0.00813,11.2,22.8,pytorch+cuda+float16+awq-4bit+gemm
KnutJaegersberg/Qwen-1_8B-Llamafied,8.0,NVIDIA A100-SXM4-80GB,0.00146,45.8,5.59,pytorch+cuda+float16+awq-4bit+gemm
cyberagent/calm2-7b-chat,7.0,NVIDIA A100-SXM4-80GB,0.00204,36.4,7.04,pytorch+cuda+float16+awq-4bit+gemm
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.00216,33.9,7.56,pytorch+cuda+float16+awq-4bit+gemm
cerebras/Cerebras-GPT-111M,0.111,NVIDIA A100-SXM4-80GB,0.00039999999999999996,158.0,1.62,pytorch+cuda+float16+awq-4bit+gemm
cerebras/Cerebras-GPT-13B,13.0,NVIDIA A100-SXM4-80GB,0.00238,36.8,6.96,pytorch+cuda+float16+awq-4bit+gemm
cerebras/Cerebras-GPT-6.7B,6.7,NVIDIA A100-SXM4-80GB,0.00155,53.7,4.77,pytorch+cuda+float16+awq-4bit+gemm
cerebras/Cerebras-GPT-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00129,55.7,4.6,pytorch+cuda+float16+awq-4bit+gemm
cerebras/Cerebras-GPT-256M,0.256,NVIDIA A100-SXM4-80GB,0.000579,114.0,2.24,pytorch+cuda+float16+awq-4bit+gemm
cerebras/Cerebras-GPT-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.00101,67.5,3.79,pytorch+cuda+float16+awq-4bit+gemm
itsliupeng/openllama-7b-base,7.0,NVIDIA A100-SXM4-80GB,0.0021,35.4,7.24,pytorch+cuda+float16+awq-4bit+gemm
itsliupeng/openllama-7b-icl,7.0,NVIDIA A100-SXM4-80GB,0.0020099999999999996,36.7,6.97,pytorch+cuda+float16+awq-4bit+gemm
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.00036899999999999997,175.0,1.46,pytorch+cuda+float16+awq-4bit+gemm
tiiuae/falcon-rw-1b,1.0,NVIDIA A100-SXM4-80GB,0.0011400000000000002,60.1,4.26,pytorch+cuda+float16+awq-4bit+gemm
tiiuae/falcon-40b,40.0,NVIDIA A100-SXM4-80GB,0.00539,16.1,15.9,pytorch+cuda+float16+awq-4bit+gemm
facebook/xglm-7.5B,7.5,NVIDIA A100-SXM4-80GB,0.00181,43.2,5.93,pytorch+cuda+float16+awq-4bit+gemm
facebook/xglm-564M,0.564,NVIDIA A100-SXM4-80GB,0.00116,58.3,4.39,pytorch+cuda+float16+awq-4bit+gemm
facebook/xglm-4.5B,4.5,NVIDIA A100-SXM4-80GB,0.00231,29.9,8.55,pytorch+cuda+float16+awq-4bit+gemm
chargoddard/Yi-34B-Llama,34.0,NVIDIA A100-SXM4-80GB,0.0049,18.0,14.2,pytorch+cuda+float16+awq-4bit+gemm
chargoddard/llama-2-26b-trenchcoat-stack,26.0,NVIDIA A100-SXM4-80GB,0.00545,14.7,17.4,pytorch+cuda+float16+awq-4bit+gemm
bigscience/bloom-7b1,7.0,NVIDIA A100-SXM4-80GB,0.00166,47.4,5.4,pytorch+cuda+float16+awq-4bit+gemm
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.0014399999999999999,49.5,5.17,pytorch+cuda+float16+awq-4bit+gemm
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.000645,98.5,2.6,pytorch+cuda+float16+awq-4bit+gemm
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.000377,172.0,1.49,pytorch+cuda+float16+awq-4bit+gemm
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.000419,158.0,1.62,pytorch+cuda+float16+awq-4bit+gemm
seungduk/KoSOLAR-10.7B-v0.1,10.7,NVIDIA A100-SXM4-80GB,0.0032600000000000003,22.5,11.4,pytorch+cuda+float16+awq-4bit+gemm
TurkuNLP/gpt3-finnish-13B,13.0,NVIDIA A100-SXM4-80GB,0.00233,36.7,6.97,pytorch+cuda+float16+awq-4bit+gemm
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.00141,48.1,5.32,pytorch+cuda+float16+awq-4bit+gemm
stabilityai/japanese-stablelm-base-gamma-7b,7.0,NVIDIA A100-SXM4-80GB,0.00237,30.1,8.51,pytorch+cuda+float16+awq-4bit+gemm
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.00119,72.1,3.55,pytorch+cuda+float16+awq-4bit+gemm
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.000988,72.9,3.51,pytorch+cuda+float16+awq-4bit+gemm
stabilityai/stablelm-base-alpha-7b-v2,7.0,NVIDIA A100-SXM4-80GB,0.00193,38.6,6.63,pytorch+cuda+float16+awq-4bit+gemm
stabilityai/stablelm-3b-4e1t,3.0,NVIDIA A100-SXM4-80GB,0.00173,38.2,6.71,pytorch+cuda+float16+awq-4bit+gemm
huggyllama/llama-65b,65.0,NVIDIA A100-SXM4-80GB,0.00688,14.7,17.4,pytorch+cuda+float16+awq-4bit+gemm
huggyllama/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.0027,29.0,8.82,pytorch+cuda+float16+awq-4bit+gemm
NucleusAI/nucleus-22B-token-500B,22.0,NVIDIA A100-SXM4-80GB,0.00306,29.0,8.83,pytorch+cuda+float16+awq-4bit+gemm
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.000241,272.0,0.942,pytorch+cuda+float16+awq-4bit+gemm
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.000408,149.0,1.72,pytorch+cuda+float16+awq-4bit+gemm
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.00044,151.0,1.7,pytorch+cuda+float16+awq-4bit+gemm
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.000412,152.0,1.68,pytorch+cuda+float16+awq-4bit+gemm
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.00030199999999999997,251.0,1.02,pytorch+cuda+float16+awq-4bit+gemm
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.00203,36.9,6.94,pytorch+cuda+float16+awq-4bit+gemm
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.002,36.7,6.97,pytorch+cuda+float16+awq-4bit+gemm
openlm-research/open_llama_13b,13.0,NVIDIA A100-SXM4-80GB,0.00275,28.8,8.89,pytorch+cuda+float16+awq-4bit+gemm
abhinand/tamil-llama-7b-base-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00202,35.0,7.31,pytorch+cuda+float16+awq-4bit+gemm
abhinand/tamil-llama-13b-base-v0.1,13.0,NVIDIA A100-SXM4-80GB,0.0027199999999999998,29.4,8.72,pytorch+cuda+float16+awq-4bit+gemm
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.002,36.6,7.0,pytorch+cuda+float16+awq-4bit+gemm
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.00179,37.5,6.82,pytorch+cuda+float16+awq-4bit+gemm
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00196,37.2,6.88,pytorch+cuda+float16+awq-4bit+gemm
Devio/test-22B,22.0,NVIDIA A100-SXM4-80GB,0.00309,28.4,9.0,pytorch+cuda+float16+awq-4bit+gemm
internlm/internlm-20b,20.0,NVIDIA A100-SXM4-80GB,0.004889999999999999,15.8,16.2,pytorch+cuda+float16+awq-4bit+gemm
Delcos/Starling-LM-11B-alpha,11.0,NVIDIA A100-SXM4-80GB,0.00367,19.7,13.0,pytorch+cuda+float16+awq-4bit+gemm
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.00264,25.3,10.1,pytorch+cuda+float16+awq-4bit+gemm
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.00178,37.7,6.79,pytorch+cuda+float16+awq-4bit+gemm
upstage/SOLAR-10.7B-v1.0,10.7,NVIDIA A100-SXM4-80GB,0.0031599999999999996,22.3,11.5,pytorch+cuda+float16+awq-4bit+gemm
huggingface/llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00206,36.1,7.09,pytorch+cuda+float16+awq-4bit+gemm
huggingface/llama-65b,65.0,NVIDIA A100-SXM4-80GB,0.00683,14.5,17.7,pytorch+cuda+float16+awq-4bit+gemm
huggingface/llama-30b,30.0,NVIDIA A100-SXM4-80GB,0.00462,19.4,13.2,pytorch+cuda+float16+awq-4bit+gemm
huggingface/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00275,28.5,8.97,pytorch+cuda+float16+awq-4bit+gemm
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.00215,33.9,7.55,pytorch+cuda+float16+awq-4bit+gemm
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.00199,35.8,7.15,pytorch+cuda+float16+awq-4bit+gemm
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00203,36.7,6.97,pytorch+cuda+float16+awq-4bit+gemm
codellama/CodeLlama-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.0027300000000000002,29.0,8.82,pytorch+cuda+float16+awq-4bit+gemm
codellama/CodeLlama-34b-hf,34.0,NVIDIA A100-SXM4-80GB,0.004189999999999999,22.7,11.3,pytorch+cuda+float16+awq-4bit+gemm
EleutherAI/gpt-neox-20b,20.0,NVIDIA A100-SXM4-80GB,0.0039,28.8,8.9,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.00196,48.6,5.27,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00198,48.7,5.26,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.0011400000000000002,62.0,4.13,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-12b,12.0,NVIDIA A100-SXM4-80GB,0.00262,43.4,5.9,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00113,63.7,4.02,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-12b-deduped,12.0,NVIDIA A100-SXM4-80GB,0.0026,43.1,5.94,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.000748,93.1,2.75,pytorch+cuda+float16+flash-attention-v2
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.00043,147.0,1.74,pytorch+cuda+float16+flash-attention-v2
EleutherAI/polyglot-ko-12.8b,12.8,NVIDIA A100-SXM4-80GB,0.0028799999999999997,38.8,6.6,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.00101,63.8,4.01,pytorch+cuda+float16+flash-attention-v2
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.000987,75.5,3.39,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.000493,127.0,2.01,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.000977,65.5,3.91,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.000489,129.0,1.98,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.00155,49.6,5.16,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.0015400000000000001,48.9,5.24,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.00026,239.0,1.07,pytorch+cuda+float16+flash-attention-v2
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.0014,56.6,4.52,pytorch+cuda+float16+flash-attention-v2
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA A100-SXM4-80GB,0.0012,57.1,4.48,pytorch+cuda+float16+flash-attention-v2
ahxt/llama2_xs_460M_experimental,0.46,NVIDIA A100-SXM4-80GB,0.00117,52.8,4.85,pytorch+cuda+float16+flash-attention-v2
GeneZC/MiniMA-3B,3.0,NVIDIA A100-SXM4-80GB,0.00148,51.6,4.96,pytorch+cuda+float16+flash-attention-v2
GeneZC/MiniMA-2-3B,3.0,NVIDIA A100-SXM4-80GB,0.0015,51.9,4.93,pytorch+cuda+float16+flash-attention-v2
Locutusque/TinyMistral-248m,0.248,NVIDIA A100-SXM4-80GB,0.000778,83.9,3.05,pytorch+cuda+float16+flash-attention-v2
DevaMalla/llama-base-7b,7.0,NVIDIA A100-SXM4-80GB,0.0022,40.4,6.33,pytorch+cuda+float16+flash-attention-v2
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.000246,242.0,1.06,pytorch+cuda+float16+flash-attention-v2
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000248,246.0,1.04,pytorch+cuda+float16+flash-attention-v2
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.00025,249.0,1.03,pytorch+cuda+float16+flash-attention-v2
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.00025100000000000003,244.0,1.05,pytorch+cuda+float16+flash-attention-v2
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.00025400000000000005,244.0,1.05,pytorch+cuda+float16+flash-attention-v2
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA A100-SXM4-80GB,0.0011799999999999998,57.7,4.44,pytorch+cuda+float16+flash-attention-v2
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA A100-SXM4-80GB,0.0012100000000000001,57.9,4.42,pytorch+cuda+float16+flash-attention-v2
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA A100-SXM4-80GB,0.00119,57.8,4.43,pytorch+cuda+float16+flash-attention-v2
Deci/DeciLM-7B,7.0,NVIDIA A100-SXM4-80GB,0.00233,39.0,6.57,pytorch+cuda+float16+flash-attention-v2
winglian/Llama-2-3b-hf,3.0,NVIDIA A100-SXM4-80GB,0.0011400000000000002,79.3,3.23,pytorch+cuda+float16+flash-attention-v2
mistralai/Mistral-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00256,34.0,7.52,pytorch+cuda+float16+flash-attention-v2
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.00182,43.0,5.95,pytorch+cuda+float16+flash-attention-v2
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.00183,43.3,5.91,pytorch+cuda+float16+flash-attention-v2
matsuo-lab/weblab-10b,10.0,NVIDIA A100-SXM4-80GB,0.00258,42.9,5.97,pytorch+cuda+float16+flash-attention-v2
augmxnt/shisa-base-7b-v1,7.0,NVIDIA A100-SXM4-80GB,0.00269,33.4,7.66,pytorch+cuda+float16+flash-attention-v2
uukuguy/Orca-2-7b-f16,7.0,NVIDIA A100-SXM4-80GB,0.0022199999999999998,40.8,6.28,pytorch+cuda+float16+flash-attention-v2
01-ai/Yi-34B-200K,34.0,NVIDIA A100-SXM4-80GB,0.006039999999999999,18.2,14.1,pytorch+cuda+float16+flash-attention-v2
01-ai/Yi-34B,34.0,NVIDIA A100-SXM4-80GB,0.00602,18.4,13.9,pytorch+cuda+float16+flash-attention-v2
01-ai/Yi-6B-200K,6.0,NVIDIA A100-SXM4-80GB,0.00214,39.8,6.43,pytorch+cuda+float16+flash-attention-v2
01-ai/Yi-6B,6.0,NVIDIA A100-SXM4-80GB,0.00216,39.4,6.49,pytorch+cuda+float16+flash-attention-v2
scb10x/typhoon-7b,7.0,NVIDIA A100-SXM4-80GB,0.00257,33.7,7.6,pytorch+cuda+float16+flash-attention-v2
TheBloke/Llama-2-13B-fp16,13.0,NVIDIA A100-SXM4-80GB,0.0033799999999999998,31.7,8.08,pytorch+cuda+float16+flash-attention-v2
sarvamai/OpenHathi-7B-Hi-v0.1-Base,7.0,NVIDIA A100-SXM4-80GB,0.0022299999999999998,40.7,6.29,pytorch+cuda+float16+flash-attention-v2
cyberagent/calm2-7b-chat,7.0,NVIDIA A100-SXM4-80GB,0.00231,40.6,6.3,pytorch+cuda+float16+flash-attention-v2
Kunhao/pile-7b-250b-tokens,7.0,NVIDIA A100-SXM4-80GB,0.00215,40.1,6.38,pytorch+cuda+float16+flash-attention-v2
itsliupeng/openllama-7b-base,7.0,NVIDIA A100-SXM4-80GB,0.0022,41.4,6.19,pytorch+cuda+float16+flash-attention-v2
itsliupeng/openllama-7b-icl,7.0,NVIDIA A100-SXM4-80GB,0.0022400000000000002,39.0,6.57,pytorch+cuda+float16+flash-attention-v2
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.00025400000000000005,239.0,1.07,pytorch+cuda+float16+flash-attention-v2
chargoddard/Yi-34B-Llama,34.0,NVIDIA A100-SXM4-80GB,0.00602,18.4,13.9,pytorch+cuda+float16+flash-attention-v2
chargoddard/llama-2-26b-trenchcoat-stack,26.0,NVIDIA A100-SXM4-80GB,0.0066,15.6,16.4,pytorch+cuda+float16+flash-attention-v2
BEE-spoke-data/Mixtral-GQA-400m-v2,0.4,NVIDIA A100-SXM4-80GB,0.0008619999999999999,78.0,3.28,pytorch+cuda+float16+flash-attention-v2
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA A100-SXM4-80GB,0.000527,120.0,2.14,pytorch+cuda+float16+flash-attention-v2
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA A100-SXM4-80GB,0.000327,195.0,1.31,pytorch+cuda+float16+flash-attention-v2
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA A100-SXM4-80GB,0.000328,192.0,1.33,pytorch+cuda+float16+flash-attention-v2
seungduk/KoSOLAR-10.7B-v0.1,10.7,NVIDIA A100-SXM4-80GB,0.00348,26.0,9.83,pytorch+cuda+float16+flash-attention-v2
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA A100-SXM4-80GB,0.00134,53.6,4.78,pytorch+cuda+float16+flash-attention-v2
stabilityai/japanese-stablelm-base-gamma-7b,7.0,NVIDIA A100-SXM4-80GB,0.00257,34.1,7.5,pytorch+cuda+float16+flash-attention-v2
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.00141,78.3,3.27,pytorch+cuda+float16+flash-attention-v2
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.00104,93.8,2.73,pytorch+cuda+float16+flash-attention-v2
huggyllama/llama-13b,13.0,NVIDIA A100-SXM4-80GB,0.00328,32.5,7.87,pytorch+cuda+float16+flash-attention-v2
NucleusAI/nucleus-22B-token-500B,22.0,NVIDIA A100-SXM4-80GB,0.004,27.8,9.21,pytorch+cuda+float16+flash-attention-v2
Walmart-the-bag/Influxient-4x13B,13.0,NVIDIA A100-SXM4-80GB,0.00713,12.4,20.6,pytorch+cuda+float16+flash-attention-v2
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.000175,354.0,0.723,pytorch+cuda+float16+flash-attention-v2
roneneldan/TinyStories-1M,0.001,NVIDIA A100-SXM4-80GB,0.000307,194.0,1.32,pytorch+cuda+float16+flash-attention-v2
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.000282,219.0,1.17,pytorch+cuda+float16+flash-attention-v2
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.00029299999999999997,213.0,1.2,pytorch+cuda+float16+flash-attention-v2
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.000275,221.0,1.16,pytorch+cuda+float16+flash-attention-v2
budecosystem/boomer-1b,1.0,NVIDIA A100-SXM4-80GB,0.000324,268.0,0.956,pytorch+cuda+float16+flash-attention-v2
openlm-research/open_llama_3b_v2,3.0,NVIDIA A100-SXM4-80GB,0.00179,43.8,5.84,pytorch+cuda+float16+flash-attention-v2
openlm-research/open_llama_7b_v2,7.0,NVIDIA A100-SXM4-80GB,0.0022299999999999998,40.0,6.4,pytorch+cuda+float16+flash-attention-v2
openlm-research/open_llama_7b,7.0,NVIDIA A100-SXM4-80GB,0.0022,40.8,6.27,pytorch+cuda+float16+flash-attention-v2
openlm-research/open_llama_3b,3.0,NVIDIA A100-SXM4-80GB,0.00179,43.0,5.96,pytorch+cuda+float16+flash-attention-v2
openlm-research/open_llama_13b,13.0,NVIDIA A100-SXM4-80GB,0.00333,32.4,7.9,pytorch+cuda+float16+flash-attention-v2
abhinand/tamil-llama-7b-base-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.0022500000000000003,40.7,6.29,pytorch+cuda+float16+flash-attention-v2
abhinand/tamil-llama-13b-base-v0.1,13.0,NVIDIA A100-SXM4-80GB,0.00333,32.0,8.01,pytorch+cuda+float16+flash-attention-v2
TigerResearch/tigerbot-13b-base,13.0,NVIDIA A100-SXM4-80GB,0.0047,19.5,13.1,pytorch+cuda+float16+flash-attention-v2
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.00196,48.7,5.26,pytorch+cuda+float16+flash-attention-v2
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.0015999999999999999,48.9,5.24,pytorch+cuda+float16+flash-attention-v2
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00199,48.2,5.31,pytorch+cuda+float16+flash-attention-v2
Devio/test-22B,22.0,NVIDIA A100-SXM4-80GB,0.004019999999999999,27.8,9.2,pytorch+cuda+float16+flash-attention-v2
Delcos/Starling-LM-11B-alpha,11.0,NVIDIA A100-SXM4-80GB,0.00411,21.5,11.9,pytorch+cuda+float16+flash-attention-v2
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.0022500000000000003,33.9,7.56,pytorch+cuda+float16+flash-attention-v2
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.0015799999999999998,47.6,5.38,pytorch+cuda+float16+flash-attention-v2
upstage/SOLAR-10.7B-v1.0,10.7,NVIDIA A100-SXM4-80GB,0.00349,26.5,9.65,pytorch+cuda+float16+flash-attention-v2
beomi/Yi-Ko-6B,6.0,NVIDIA A100-SXM4-80GB,0.00216,39.5,6.48,pytorch+cuda+float16+flash-attention-v2
fblgit/una-llama-7b,7.0,NVIDIA A100-SXM4-80GB,0.0030800000000000003,41.0,6.24,pytorch+cuda+float16+flash-attention-v2
codellama/CodeLlama-7b-hf,7.0,NVIDIA A100-SXM4-80GB,0.00221,40.6,6.3,pytorch+cuda+float16+flash-attention-v2
codellama/CodeLlama-13b-hf,13.0,NVIDIA A100-SXM4-80GB,0.00335,31.8,8.05,pytorch+cuda+float16+flash-attention-v2
cloudyu/Mixtral_7Bx2_MoE_13B,7.0,NVIDIA A100-SXM4-80GB,0.00485,17.3,14.8,pytorch+cuda+float16+flash-attention-v2
cloudyu/Mixtral_7Bx2_MoE,7.0,NVIDIA A100-SXM4-80GB,0.00488,17.4,14.7,pytorch+cuda+float16+flash-attention-v2
cloudyu/Mixtral_7Bx4_MOE_24B,7.0,NVIDIA A100-SXM4-80GB,0.005169999999999999,15.6,16.4,pytorch+cuda+float16+flash-attention-v2
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA A100-SXM4-80GB,0.00209,47.1,5.44,pytorch+cuda+float16+bettertransformer
EleutherAI/pythia-6.7b,6.7,NVIDIA A100-SXM4-80GB,0.00221,45.2,5.66,pytorch+cuda+float16+bettertransformer
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA A100-SXM4-80GB,0.00124,61.7,4.15,pytorch+cuda+float16+bettertransformer
EleutherAI/gpt-j-6b,6.0,NVIDIA A100-SXM4-80GB,0.00253,33.5,7.65,pytorch+cuda+float16+bettertransformer
EleutherAI/pythia-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.00124,61.5,4.16,pytorch+cuda+float16+bettertransformer
EleutherAI/pythia-1b-deduped,1.0,NVIDIA A100-SXM4-80GB,0.000855,88.6,2.89,pytorch+cuda+float16+bettertransformer
EleutherAI/gpt-neo-125m,0.125,NVIDIA A100-SXM4-80GB,0.000535,122.0,2.1,pytorch+cuda+float16+bettertransformer
EleutherAI/pythia-410m,0.41,NVIDIA A100-SXM4-80GB,0.0011400000000000002,59.1,4.33,pytorch+cuda+float16+bettertransformer
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.00116,63.8,4.01,pytorch+cuda+float16+bettertransformer
EleutherAI/pythia-160m-deduped,0.16,NVIDIA A100-SXM4-80GB,0.000567,118.0,2.17,pytorch+cuda+float16+bettertransformer
EleutherAI/pythia-410m-deduped,0.41,NVIDIA A100-SXM4-80GB,0.0011400000000000002,59.7,4.29,pytorch+cuda+float16+bettertransformer
EleutherAI/pythia-160m,0.16,NVIDIA A100-SXM4-80GB,0.000562,115.0,2.22,pytorch+cuda+float16+bettertransformer
EleutherAI/pythia-2.7b,2.7,NVIDIA A100-SXM4-80GB,0.00173,43.1,5.94,pytorch+cuda+float16+bettertransformer
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA A100-SXM4-80GB,0.00182,44.0,5.82,pytorch+cuda+float16+bettertransformer
EleutherAI/pythia-70m-deduped,0.07,NVIDIA A100-SXM4-80GB,0.00028700000000000004,221.0,1.16,pytorch+cuda+float16+bettertransformer
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.0016899999999999999,46.6,5.49,pytorch+cuda+float16+bettertransformer
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA A100-SXM4-80GB,0.000288,221.0,1.16,pytorch+cuda+float16+bettertransformer
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.00028000000000000003,225.0,1.14,pytorch+cuda+float16+bettertransformer
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA A100-SXM4-80GB,0.00028500000000000004,221.0,1.16,pytorch+cuda+float16+bettertransformer
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA A100-SXM4-80GB,0.000284,221.0,1.16,pytorch+cuda+float16+bettertransformer
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA A100-SXM4-80GB,0.000294,219.0,1.17,pytorch+cuda+float16+bettertransformer
robowaifudev/megatron-gpt2-345m,0.345,NVIDIA A100-SXM4-80GB,0.0009739999999999999,68.6,3.73,pytorch+cuda+float16+bettertransformer
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA A100-SXM4-80GB,0.0020099999999999996,40.6,6.3,pytorch+cuda+float16+bettertransformer
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA A100-SXM4-80GB,0.0019700000000000004,41.7,6.14,pytorch+cuda+float16+bettertransformer
AI-Sweden-Models/gpt-sw3-126m,0.126,NVIDIA A100-SXM4-80GB,0.000424,154.0,1.66,pytorch+cuda+float16+bettertransformer
AI-Sweden-Models/gpt-sw3-1.3b,1.3,NVIDIA A100-SXM4-80GB,0.000943,78.3,3.27,pytorch+cuda+float16+bettertransformer
AI-Sweden-Models/gpt-sw3-356m,0.356,NVIDIA A100-SXM4-80GB,0.00084,78.5,3.26,pytorch+cuda+float16+bettertransformer
Salesforce/codegen-6B-multi,6.0,NVIDIA A100-SXM4-80GB,0.0028899999999999998,29.0,8.84,pytorch+cuda+float16+bettertransformer
Salesforce/codegen-6B-nl,6.0,NVIDIA A100-SXM4-80GB,0.00286,29.3,8.75,pytorch+cuda+float16+bettertransformer
cerebras/Cerebras-GPT-111M,0.111,NVIDIA A100-SXM4-80GB,0.00036899999999999997,179.0,1.43,pytorch+cuda+float16+bettertransformer
cerebras/Cerebras-GPT-6.7B,6.7,NVIDIA A100-SXM4-80GB,0.00166,63.1,4.06,pytorch+cuda+float16+bettertransformer
cerebras/Cerebras-GPT-2.7B,2.7,NVIDIA A100-SXM4-80GB,0.00137,62.3,4.11,pytorch+cuda+float16+bettertransformer
cerebras/Cerebras-GPT-256M,0.256,NVIDIA A100-SXM4-80GB,0.0005390000000000001,130.0,1.97,pytorch+cuda+float16+bettertransformer
cerebras/Cerebras-GPT-1.3B,1.3,NVIDIA A100-SXM4-80GB,0.000885,86.5,2.96,pytorch+cuda+float16+bettertransformer
ethzanalytics/pythia-31m,0.031,NVIDIA A100-SXM4-80GB,0.00028500000000000004,225.0,1.14,pytorch+cuda+float16+bettertransformer
bigscience/bloom-3b,3.0,NVIDIA A100-SXM4-80GB,0.00152,55.4,4.62,pytorch+cuda+float16+bettertransformer
stabilityai/stablelm-base-alpha-7b,7.0,NVIDIA A100-SXM4-80GB,0.00155,70.9,3.61,pytorch+cuda+float16+bettertransformer
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA A100-SXM4-80GB,0.00109,89.8,2.85,pytorch+cuda+float16+bettertransformer
roneneldan/TinyStories-33M,0.033,NVIDIA A100-SXM4-80GB,0.000217,313.0,0.818,pytorch+cuda+float16+bettertransformer
roneneldan/TinyStories-1M,0.001,NVIDIA A100-SXM4-80GB,0.00035800000000000003,173.0,1.48,pytorch+cuda+float16+bettertransformer
roneneldan/TinyStories-3M,0.003,NVIDIA A100-SXM4-80GB,0.000344,179.0,1.43,pytorch+cuda+float16+bettertransformer
roneneldan/TinyStories-28M,0.028,NVIDIA A100-SXM4-80GB,0.00035600000000000003,177.0,1.45,pytorch+cuda+float16+bettertransformer
roneneldan/TinyStories-8M,0.008,NVIDIA A100-SXM4-80GB,0.00034700000000000003,183.0,1.4,pytorch+cuda+float16+bettertransformer
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA A100-SXM4-80GB,0.00216,46.4,5.52,pytorch+cuda+float16+bettertransformer
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA A100-SXM4-80GB,0.0018,43.5,5.89,pytorch+cuda+float16+bettertransformer
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA A100-SXM4-80GB,0.00212,44.9,5.7,pytorch+cuda+float16+bettertransformer
Dampish/StellarX-4B-V0,4.0,NVIDIA A100-SXM4-80GB,0.00256,30.7,8.34,pytorch+cuda+float16+bettertransformer
Dampish/StellarX-4B-V0.2,4.0,NVIDIA A100-SXM4-80GB,0.00177,44.6,5.74,pytorch+cuda+float16+bettertransformer
GeneZC/MiniMA-2-3B,3.0,NVIDIA GeForce RTX 4090,0.00065,102.0,2.52,pytorch+cuda+float16
GeneZC/MiniMA-3B,3.0,NVIDIA GeForce RTX 4090,0.000651,102.0,2.52,pytorch+cuda+float16
BEE-spoke-data/Mixtral-GQA-400m-v2,0.4,NVIDIA GeForce RTX 4090,0.00026199999999999997,159.0,1.61,pytorch+cuda+float16
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA GeForce RTX 4090,0.000136,246.0,1.04,pytorch+cuda+float16
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA GeForce RTX 4090,7.33e-05,410.0,0.625,pytorch+cuda+float16
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA GeForce RTX 4090,7.81e-05,401.0,0.638,pytorch+cuda+float16
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA GeForce RTX 4090,0.000419,131.0,1.95,pytorch+cuda+float16
mistralai/Mistral-7B-v0.1,7.0,NVIDIA GeForce RTX 4090,0.0014500000000000001,49.1,5.21,pytorch+cuda+float16
Deci/DeciLM-7B,7.0,NVIDIA GeForce RTX 4090,0.00141,51.2,5.0,pytorch+cuda+float16
team-lucid/mptk-1b,1.0,NVIDIA GeForce RTX 4090,0.00031800000000000003,191.0,1.34,pytorch+cuda+float16
AI-Sweden-Models/gpt-sw3-1.3b,1.3,NVIDIA GeForce RTX 4090,0.00036899999999999997,151.0,1.69,pytorch+cuda+float16
scb10x/typhoon-7b,7.0,NVIDIA GeForce RTX 4090,0.00147,49.2,5.2,pytorch+cuda+float16
stabilityai/japanese-stablelm-base-gamma-7b,7.0,NVIDIA GeForce RTX 4090,0.00149,49.2,5.2,pytorch+cuda+float16
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA GeForce RTX 4090,0.000762,98.8,2.59,pytorch+cuda+float16
EleutherAI/pythia-70m-deduped,0.07,NVIDIA GeForce RTX 4090,6.599999999999999e-05,421.0,0.608,pytorch+cuda+float16
EleutherAI/pythia-2.7b,2.7,NVIDIA GeForce RTX 4090,0.000721,88.3,2.9,pytorch+cuda+float16
EleutherAI/pythia-160m-deduped,0.16,NVIDIA GeForce RTX 4090,0.000139,231.0,1.11,pytorch+cuda+float16
EleutherAI/pythia-6.7b,6.7,NVIDIA GeForce RTX 4090,0.00146,51.1,5.01,pytorch+cuda+float16
EleutherAI/pythia-1b-deduped,1.0,NVIDIA GeForce RTX 4090,0.000303,174.0,1.47,pytorch+cuda+float16
EleutherAI/gpt-j-6b,6.0,NVIDIA GeForce RTX 4090,0.00132,53.7,4.77,pytorch+cuda+float16
EleutherAI/pythia-12b-deduped,12.0,NVIDIA GeForce RTX 4090,0.00243,32.5,7.87,pytorch+cuda+float16
EleutherAI/pythia-6.9b-deduped,6.9,NVIDIA GeForce RTX 4090,0.00147,50.8,5.04,pytorch+cuda+float16
EleutherAI/pythia-1.3b,1.3,NVIDIA GeForce RTX 4090,0.000446,121.0,2.12,pytorch+cuda+float16
EleutherAI/pythia-12b,12.0,NVIDIA GeForce RTX 4090,0.00248,32.4,7.9,pytorch+cuda+float16
EleutherAI/pythia-410m-deduped,0.41,NVIDIA GeForce RTX 4090,0.000277,120.0,2.13,pytorch+cuda+float16
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA GeForce RTX 4090,0.000451,120.0,2.13,pytorch+cuda+float16
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA GeForce RTX 4090,0.000714,89.8,2.85,pytorch+cuda+float16
EleutherAI/pythia-160m,0.16,NVIDIA GeForce RTX 4090,0.000137,223.0,1.15,pytorch+cuda+float16
EleutherAI/pythia-410m,0.41,NVIDIA GeForce RTX 4090,0.000276,116.0,2.21,pytorch+cuda+float16
Locutusque/TinyMistral-248M-v2,0.248,NVIDIA GeForce RTX 4090,0.000173,203.0,1.26,pytorch+cuda+float16
Locutusque/TinyMistral-248m,0.248,NVIDIA GeForce RTX 4090,0.000173,200.0,1.28,pytorch+cuda+float16
roneneldan/TinyStories-1M,0.001,NVIDIA GeForce RTX 4090,7.21e-05,384.0,0.667,pytorch+cuda+float16
cyberagent/calm2-7b-chat,7.0,NVIDIA GeForce RTX 4090,0.00143,51.8,4.94,pytorch+cuda+float16
upstage/SOLAR-10.7B-v1.0,10.7,NVIDIA GeForce RTX 4090,0.0022,33.3,7.69,pytorch+cuda+float16
seungduk/KoSOLAR-10.7B-v0.1,10.7,NVIDIA GeForce RTX 4090,0.0022800000000000003,33.2,7.71,pytorch+cuda+float16
ethzanalytics/pythia-31m,0.031,NVIDIA GeForce RTX 4090,6.65e-05,416.0,0.615,pytorch+cuda+float16
budecosystem/boomer-1b,1.0,NVIDIA GeForce RTX 4090,0.00019500000000000002,354.0,0.723,pytorch+cuda+float16
chargoddard/SmolLlamix-8x101M,0.101,NVIDIA GeForce RTX 4090,0.00018199999999999998,167.0,1.53,pytorch+cuda+float16
chargoddard/SmolLlamix-8x101M-take2,0.101,NVIDIA GeForce RTX 4090,0.000172,172.0,1.49,pytorch+cuda+float16
instructkr/ko-wand-136M,0.136,NVIDIA GeForce RTX 4090,0.00012200000000000001,303.0,0.844,pytorch+cuda+float16
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA GeForce RTX 4090,0.00039200000000000004,117.0,2.18,pytorch+cuda+float16
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA GeForce RTX 4090,0.000399,117.0,2.18,pytorch+cuda+float16
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA GeForce RTX 4090,0.000396,122.0,2.1,pytorch+cuda+float16
openlm-research/open_llama_7b_v2,7.0,NVIDIA GeForce RTX 4090,0.00139,52.6,4.87,pytorch+cuda+float16
openlm-research/open_llama_3b_v2,3.0,NVIDIA GeForce RTX 4090,0.000771,89.8,2.85,pytorch+cuda+float16
openlm-research/open_llama_7b,7.0,NVIDIA GeForce RTX 4090,0.00137,52.8,4.85,pytorch+cuda+float16
openlm-research/open_llama_3b,3.0,NVIDIA GeForce RTX 4090,0.0007740000000000001,90.1,2.84,pytorch+cuda+float16
cerebras/Cerebras-GPT-6.7B,6.7,NVIDIA GeForce RTX 4090,0.00137,53.4,4.79,pytorch+cuda+float16
cerebras/Cerebras-GPT-111M,0.111,NVIDIA GeForce RTX 4090,9.04e-05,352.0,0.727,pytorch+cuda+float16
cerebras/Cerebras-GPT-1.3B,1.3,NVIDIA GeForce RTX 4090,0.000367,151.0,1.69,pytorch+cuda+float16
cerebras/Cerebras-GPT-256M,0.256,NVIDIA GeForce RTX 4090,0.000139,266.0,0.963,pytorch+cuda+float16
cerebras/Cerebras-GPT-2.7B,2.7,NVIDIA GeForce RTX 4090,0.000644,96.6,2.65,pytorch+cuda+float16
itsliupeng/openllama-7b-base,7.0,NVIDIA GeForce RTX 4090,0.00138,52.6,4.87,pytorch+cuda+float16
itsliupeng/openllama-7b-icl,7.0,NVIDIA GeForce RTX 4090,0.00142,52.7,4.86,pytorch+cuda+float16
tiiuae/falcon-7b,7.0,NVIDIA GeForce RTX 4090,0.00157,43.2,5.93,pytorch+cuda+float16
tiiuae/falcon-rw-1b,1.0,NVIDIA GeForce RTX 4090,0.000383,152.0,1.68,pytorch+cuda+float16
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA GeForce RTX 4090,0.000409,121.0,2.11,pytorch+cuda+float16
robowaifudev/megatron-gpt2-345m,0.345,NVIDIA GeForce RTX 4090,0.000241,137.0,1.87,pytorch+cuda+float16
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA GeForce RTX 4090,6.319999999999999e-05,425.0,0.603,pytorch+cuda+float16
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA GeForce RTX 4090,6.44e-05,423.0,0.605,pytorch+cuda+float16
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA GeForce RTX 4090,6.209999999999999e-05,441.0,0.58,pytorch+cuda+float16
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA GeForce RTX 4090,6.59e-05,436.0,0.587,pytorch+cuda+float16
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA GeForce RTX 4090,6.24e-05,440.0,0.582,pytorch+cuda+float16
augmxnt/shisa-base-7b-v1,7.0,NVIDIA GeForce RTX 4090,0.00157,47.3,5.41,pytorch+cuda+float16
bigscience/bloom-7b1,7.0,NVIDIA GeForce RTX 4090,0.00148,55.9,4.58,pytorch+cuda+float16
bigscience/bloom-3b,3.0,NVIDIA GeForce RTX 4090,0.0006929999999999999,107.0,2.39,pytorch+cuda+float16
togethercomputer/RedPajama-INCITE-Base-7B-v0.1,7.0,NVIDIA GeForce RTX 4090,0.00148,50.9,5.03,pytorch+cuda+float16
togethercomputer/RedPajama-INCITE-7B-Base,7.0,NVIDIA GeForce RTX 4090,0.00147,50.8,5.04,pytorch+cuda+float16
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA GeForce RTX 4090,0.000733,88.0,2.91,pytorch+cuda+float16
DevaMalla/llama-base-7b,7.0,NVIDIA GeForce RTX 4090,0.00138,52.8,4.85,pytorch+cuda+float16
Salesforce/codegen-6B-nl,6.0,NVIDIA GeForce RTX 4090,0.00155,45.7,5.6,pytorch+cuda+float16
GeneZC/MiniMA-2-3B,3.0,NVIDIA GeForce RTX 4090,0.00117,60.2,4.25,pytorch+cuda+float32
GeneZC/MiniMA-3B,3.0,NVIDIA GeForce RTX 4090,0.0012,60.2,4.25,pytorch+cuda+float32
BEE-spoke-data/Mixtral-GQA-400m-v2,0.4,NVIDIA GeForce RTX 4090,0.000357,142.0,1.8,pytorch+cuda+float32
BEE-spoke-data/smol_llama-220M-GQA,0.22,NVIDIA GeForce RTX 4090,0.000152,292.0,0.878,pytorch+cuda+float32
BEE-spoke-data/smol_llama-81M-tied,0.081,NVIDIA GeForce RTX 4090,8.869999999999999e-05,479.0,0.535,pytorch+cuda+float32
BEE-spoke-data/smol_llama-101M-GQA,0.101,NVIDIA GeForce RTX 4090,8.88e-05,462.0,0.554,pytorch+cuda+float32
Dans-DiscountModels/ShearedLlama-1.3b-FFT-Test1,1.3,NVIDIA GeForce RTX 4090,0.000585,104.0,2.46,pytorch+cuda+float32
TheBloke/Llama-2-7B-GPTQ,7.0,NVIDIA GeForce RTX 4090,0.000671,81.8,3.13,pytorch+cuda+float32
team-lucid/mptk-1b,1.0,NVIDIA GeForce RTX 4090,0.0005080000000000001,141.0,1.82,pytorch+cuda+float32
AI-Sweden-Models/gpt-sw3-126m,0.126,NVIDIA GeForce RTX 4090,0.000149,286.0,0.894,pytorch+cuda+float32
AI-Sweden-Models/gpt-sw3-1.3b,1.3,NVIDIA GeForce RTX 4090,0.000678,103.0,2.49,pytorch+cuda+float32
AI-Sweden-Models/gpt-sw3-356m,0.356,NVIDIA GeForce RTX 4090,0.00029499999999999996,156.0,1.64,pytorch+cuda+float32
facebook/xglm-4.5B,4.5,NVIDIA GeForce RTX 4090,0.00176,40.1,6.39,pytorch+cuda+float32
stabilityai/stablelm-3b-4e1t,3.0,NVIDIA GeForce RTX 4090,0.00109,67.9,3.77,pytorch+cuda+float32
stabilityai/stablelm-base-alpha-3b,3.0,NVIDIA GeForce RTX 4090,0.00142,55.2,4.64,pytorch+cuda+float32
RWKV/rwkv-4-430m-pile,0.43,NVIDIA GeForce RTX 4090,0.000381,101.0,2.54,pytorch+cuda+float32
RWKV/rwkv-4-169m-pile,0.169,NVIDIA GeForce RTX 4090,0.000188,194.0,1.32,pytorch+cuda+float32
EleutherAI/gpt-neo-2.7B,2.7,NVIDIA GeForce RTX 4090,0.00106,63.1,4.06,pytorch+cuda+float32
EleutherAI/pythia-70m-deduped,0.07,NVIDIA GeForce RTX 4090,7.79e-05,431.0,0.594,pytorch+cuda+float32
EleutherAI/pythia-2.7b,2.7,NVIDIA GeForce RTX 4090,0.0011,60.8,4.21,pytorch+cuda+float32
EleutherAI/pythia-160m-deduped,0.16,NVIDIA GeForce RTX 4090,0.000166,231.0,1.11,pytorch+cuda+float32
EleutherAI/pythia-1b-deduped,1.0,NVIDIA GeForce RTX 4090,0.000413,151.0,1.7,pytorch+cuda+float32
EleutherAI/gpt-neo-1.3B,1.3,NVIDIA GeForce RTX 4090,0.000592,110.0,2.33,pytorch+cuda+float32
EleutherAI/pythia-1.3b,1.3,NVIDIA GeForce RTX 4090,0.000588,105.0,2.44,pytorch+cuda+float32
EleutherAI/gpt-neo-125m,0.125,NVIDIA GeForce RTX 4090,0.000138,270.0,0.948,pytorch+cuda+float32
EleutherAI/pythia-410m-deduped,0.41,NVIDIA GeForce RTX 4090,0.000349,120.0,2.14,pytorch+cuda+float32
EleutherAI/pythia-1.4b-deduped,1.4,NVIDIA GeForce RTX 4090,0.0005819999999999999,103.0,2.48,pytorch+cuda+float32
EleutherAI/pythia-2.8b-deduped,2.8,NVIDIA GeForce RTX 4090,0.0011099999999999999,60.8,4.21,pytorch+cuda+float32
EleutherAI/pythia-160m,0.16,NVIDIA GeForce RTX 4090,0.00016999999999999999,227.0,1.13,pytorch+cuda+float32
EleutherAI/pythia-410m,0.41,NVIDIA GeForce RTX 4090,0.000359,123.0,2.08,pytorch+cuda+float32
Dampish/StellarX-4B-V0.2,4.0,NVIDIA GeForce RTX 4090,0.00109,60.5,4.23,pytorch+cuda+float32
Dampish/StellarX-4B-V0,4.0,NVIDIA GeForce RTX 4090,0.00157,41.9,6.11,pytorch+cuda+float32
Locutusque/TinyMistral-248M-v2,0.248,NVIDIA GeForce RTX 4090,0.00019500000000000002,227.0,1.13,pytorch+cuda+float32
Locutusque/TinyMistral-248m,0.248,NVIDIA GeForce RTX 4090,0.00019,221.0,1.16,pytorch+cuda+float32
roneneldan/TinyStories-3M,0.003,NVIDIA GeForce RTX 4090,7.3e-05,415.0,0.617,pytorch+cuda+float32
roneneldan/TinyStories-33M,0.033,NVIDIA GeForce RTX 4090,6.330000000000001e-05,650.0,0.394,pytorch+cuda+float32
roneneldan/TinyStories-1M,0.001,NVIDIA GeForce RTX 4090,7.020000000000001e-05,410.0,0.625,pytorch+cuda+float32
roneneldan/TinyStories-28M,0.028,NVIDIA GeForce RTX 4090,7.88e-05,405.0,0.632,pytorch+cuda+float32
roneneldan/TinyStories-8M,0.008,NVIDIA GeForce RTX 4090,7.549999999999999e-05,396.0,0.646,pytorch+cuda+float32
ethzanalytics/pythia-31m,0.031,NVIDIA GeForce RTX 4090,6.69e-05,432.0,0.593,pytorch+cuda+float32
budecosystem/boomer-1b,1.0,NVIDIA GeForce RTX 4090,0.000373,205.0,1.25,pytorch+cuda+float32
chargoddard/SmolLlamix-8x101M,0.101,NVIDIA GeForce RTX 4090,0.000201,175.0,1.46,pytorch+cuda+float32
chargoddard/SmolLlamix-8x101M-take2,0.101,NVIDIA GeForce RTX 4090,0.000192,180.0,1.42,pytorch+cuda+float32
instructkr/ko-wand-136M,0.136,NVIDIA GeForce RTX 4090,0.000126,311.0,0.824,pytorch+cuda+float32
PY007/TinyLlama-1.1B-step-50K-105b,1.1,NVIDIA GeForce RTX 4090,0.000494,126.0,2.03,pytorch+cuda+float32
PY007/TinyLlama-1.1B-intermediate-step-240k-503b,1.1,NVIDIA GeForce RTX 4090,0.000486,125.0,2.04,pytorch+cuda+float32
PY007/TinyLlama-1.1B-intermediate-step-480k-1T,1.1,NVIDIA GeForce RTX 4090,0.000485,125.0,2.05,pytorch+cuda+float32
openlm-research/open_llama_3b_v2,3.0,NVIDIA GeForce RTX 4090,0.0013599999999999999,52.4,4.89,pytorch+cuda+float32
openlm-research/open_llama_3b,3.0,NVIDIA GeForce RTX 4090,0.00137,52.4,4.89,pytorch+cuda+float32
cerebras/Cerebras-GPT-111M,0.111,NVIDIA GeForce RTX 4090,0.00011999999999999999,357.0,0.717,pytorch+cuda+float32
cerebras/Cerebras-GPT-1.3B,1.3,NVIDIA GeForce RTX 4090,0.0006810000000000001,105.0,2.43,pytorch+cuda+float32
cerebras/Cerebras-GPT-256M,0.256,NVIDIA GeForce RTX 4090,0.00018199999999999998,249.0,1.03,pytorch+cuda+float32
cerebras/Cerebras-GPT-2.7B,2.7,NVIDIA GeForce RTX 4090,0.00128,61.5,4.16,pytorch+cuda+float32
tiiuae/falcon-rw-1b,1.0,NVIDIA GeForce RTX 4090,0.0005489999999999999,131.0,1.95,pytorch+cuda+float32
TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T,1.1,NVIDIA GeForce RTX 4090,0.0005080000000000001,127.0,2.02,pytorch+cuda+float32
robowaifudev/megatron-gpt2-345m,0.345,NVIDIA GeForce RTX 4090,0.000315,142.0,1.8,pytorch+cuda+float32
pszemraj/pythia-31m-KI_v1-2048-scratch,0.031,NVIDIA GeForce RTX 4090,6.63e-05,437.0,0.586,pytorch+cuda+float32
pszemraj/pythia-31m-goodwiki-deduped-2048-scratch,0.031,NVIDIA GeForce RTX 4090,6.45e-05,449.0,0.57,pytorch+cuda+float32
pszemraj/pythia-31m-simplewiki-scratch-bf16,0.031,NVIDIA GeForce RTX 4090,6.330000000000001e-05,456.0,0.562,pytorch+cuda+float32
pszemraj/pythia-31m-simplewiki-2048,0.031,NVIDIA GeForce RTX 4090,6.65e-05,450.0,0.569,pytorch+cuda+float32
pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e,0.031,NVIDIA GeForce RTX 4090,6.57e-05,450.0,0.569,pytorch+cuda+float32
rinna/bilingual-gpt-neox-4b-8k,4.0,NVIDIA GeForce RTX 4090,0.00142,46.8,5.47,pytorch+cuda+float32
rinna/bilingual-gpt-neox-4b,4.0,NVIDIA GeForce RTX 4090,0.0014500000000000001,47.1,5.44,pytorch+cuda+float32
01-ai/Yi-6B,6.0,NVIDIA GeForce RTX 4090,0.00219,33.5,7.64,pytorch+cuda+float32
bigscience/bloom-3b,3.0,NVIDIA GeForce RTX 4090,0.00113,65.3,3.92,pytorch+cuda+float32
togethercomputer/RedPajama-INCITE-Base-3B-v1,3.0,NVIDIA GeForce RTX 4090,0.00113,60.4,4.24,pytorch+cuda+float32
ahxt/LiteLlama-460M-1T,0.46,NVIDIA GeForce RTX 4090,0.000349,127.0,2.01,pytorch+cuda+float32
