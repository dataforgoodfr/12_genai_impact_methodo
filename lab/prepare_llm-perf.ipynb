{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T14:03:59.641713Z",
     "start_time": "2024-02-09T14:03:59.634844Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd5bfc118d08f8a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T14:15:17.670764Z",
     "start_time": "2024-02-09T14:15:17.619998Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_csv('./data/llm_perf/hf-dgx-01_perf-report.csv'),\n",
    "    pd.read_csv('./data/llm_perf/audace_perf-report.csv')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b906eefa3694df9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T14:15:20.223968Z",
     "start_time": "2024-02-09T14:15:20.217783Z"
    }
   },
   "outputs": [],
   "source": [
    "df['gpu'] = df['environment.gpus'].apply(lambda x: json.loads(x.replace('\\'', '\"'))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8006ba",
   "metadata": {},
   "source": [
    "Le nombre de paramètres des modèles n'est pas directement disponible. Une fonction de parsing est donc nécessaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dbfdacc6f770498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T14:15:20.574738Z",
     "start_time": "2024-02-09T14:15:20.566107Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_model_parameters_count(model_name: str) -> Optional[tuple[float, str]]:\n",
    "    match = re.search(r'([0-9.]+)(b|m)', model_name, re.IGNORECASE)\n",
    "    if match is not None:\n",
    "        count, unit = float(match[1]), match[2].lower()\n",
    "        if unit == 'm':\n",
    "            count /= 1000\n",
    "        return count\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4906f39ce29d0c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T14:15:21.561763Z",
     "start_time": "2024-02-09T14:15:21.554652Z"
    }
   },
   "outputs": [],
   "source": [
    "df['parameters_count'] = df['model'].apply(parse_model_parameters_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2d4b5",
   "metadata": {},
   "source": [
    "Certains modèles ne sont pas pris en compte par cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18f7738",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_params_models = df.loc[df['parameters_count'].isnull(), 'model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbca8fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NYTK/PULI-GPTrio',\n",
       " 'ai-forever/mGPT',\n",
       " 'Writer/palmyra-base',\n",
       " 'Writer/palmyra-large',\n",
       " 'gpt2',\n",
       " 'cyberagent/open-calm-large',\n",
       " 'BEE-spoke-data/NanoLlama-GQA-L10-A32_KV8-v13-KI',\n",
       " 'BEE-spoke-data/verysmol_llama-v11-KIx2',\n",
       " 'TurkuNLP/gpt3-finnish-large',\n",
       " 'TurkuNLP/gpt3-finnish-small',\n",
       " 'rishiraj/CatPPT-base',\n",
       " 'LLM360/Amber',\n",
       " 'golaxy/gowizardlm',\n",
       " 'bigcode/tiny_starcoder_py',\n",
       " 'bigcode/gpt_bigcode-santacoder',\n",
       " 'bit-dny/MindLLM',\n",
       " 'SaylorTwift/gpt2_test',\n",
       " 'microsoft/phi-1_5',\n",
       " 'gpt2-xl',\n",
       " 'bn22/tinyllama_frankenmerge',\n",
       " 'microsoft/phi-2',\n",
       " 'vishesht27/22-Neuro_Model']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(no_params_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ba731",
   "metadata": {},
   "source": [
    "Il est possible de récupérer manuellement cette info sur le site d'HuggingFace (ou sur llm.extractum.io pour *golaxy/gowizardlm*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85f90f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: huggingface.co, llm.extractum.io for gowizardlm\n",
    "params = [7.67, 1.3, 5, 20, 0.124, 0.4, 0.218, 0.058, 0.881, 0.186, 7.24, 6.74, 7, 0.164, 1.12, 1.3, 0.137, 1.3, 1.61, 1.54, 2.78, 7.24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5668546",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_params_models_dict = dict(zip(no_params_models, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59ee1798",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in no_params_models_dict:\n",
    "    df.loc[df['model'] == model, 'parameters_count'] = no_params_models_dict[model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31530d5c",
   "metadata": {},
   "source": [
    "Les informations concernant les data types, les méthodes d'optimisation et les péthodes de quantization sont dans le champ `experiment_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d547fe67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pytorch+cuda+bfloat16',\n",
       " 'pytorch+cuda+float16',\n",
       " 'pytorch+cuda+float16+awq-4bit+gemm',\n",
       " 'pytorch+cuda+float16+awq-4bit+gemv',\n",
       " 'pytorch+cuda+float16+bettertransformer',\n",
       " 'pytorch+cuda+float16+bnb-4bit',\n",
       " 'pytorch+cuda+float16+bnb-4bit+bettertransformer',\n",
       " 'pytorch+cuda+float16+bnb-8bit',\n",
       " 'pytorch+cuda+float16+bnb-8bit+bettertransformer',\n",
       " 'pytorch+cuda+float16+flash-attention-v2',\n",
       " 'pytorch+cuda+float16+gptq-4bit+cuda-fp16',\n",
       " 'pytorch+cuda+float16+gptq-4bit+exllama-v1',\n",
       " 'pytorch+cuda+float16+gptq-4bit+exllama-v2',\n",
       " 'pytorch+cuda+float32']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(df['experiment_name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a10de3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dtype'] = df['experiment_name'].apply(lambda x:x.split('+')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9301f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim(exp_name):\n",
    "    if 'bettertransformer' in exp_name:\n",
    "        return 'BetterTransformer'\n",
    "    elif 'flash-attention-v2' in exp_name:\n",
    "        return 'FlashAttentionV2'\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "565a9047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['optimization'] = df['experiment_name'].apply(get_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d13d6d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quant(exp_name):\n",
    "    if ('bnb' in exp_name) or ('cuda-fp16' in exp_name):\n",
    "        return exp_name.split('+')[3]\n",
    "    elif ('awq' in exp_name) or ('gptq' in exp_name):\n",
    "        return '+'.join(exp_name.split('+')[3:5])\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e42f65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quantization'] = df['experiment_name'].apply(get_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c12e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cuda-fp16'] = df['experiment_name'].apply(lambda x: 'cuda-fp16' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31e031f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response_length'] = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18e6a57947e0e0bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T14:15:21.926720Z",
     "start_time": "2024-02-09T14:15:21.923706Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert kWh to Wh\n",
    "df['energy_per_token'] = df['generate.energy_consumption(kWh/token)'] * 1000\n",
    "\n",
    "# convert Wh to J\n",
    "df['energy'] = 3600 * df['energy_per_token'] * df['response_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c583942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'generate.throughput(tokens/s)':'throughput', 'generate.latency(s)':'latency'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "452c4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['task'] = 'chat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57914452fbc57eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T14:15:22.287949Z",
     "start_time": "2024-02-09T14:15:22.283656Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = df[[\n",
    "    'model',\n",
    "    'throughput',\n",
    "    'response_length',\n",
    "    'latency',    \n",
    "    'energy',\n",
    "    'gpu',\n",
    "    'task',\n",
    "    'parameters_count',\n",
    "    'energy_per_token',\n",
    "    'dtype',\n",
    "    'optimization',\n",
    "    'quantization',\n",
    "    'cuda-fp16'\n",
    "]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11514018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1944 entries, 0 to 175\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   model             1944 non-null   object \n",
      " 1   throughput        1944 non-null   float64\n",
      " 2   response_length   1944 non-null   int64  \n",
      " 3   latency           1944 non-null   float64\n",
      " 4   energy            1944 non-null   float64\n",
      " 5   gpu               1944 non-null   object \n",
      " 6   task              1944 non-null   object \n",
      " 7   parameters_count  1944 non-null   float64\n",
      " 8   energy_per_token  1944 non-null   float64\n",
      " 9   dtype             1944 non-null   object \n",
      " 10  optimization      1944 non-null   object \n",
      " 11  quantization      1944 non-null   object \n",
      " 12  cuda-fp16         1944 non-null   bool   \n",
      "dtypes: bool(1), float64(5), int64(1), object(6)\n",
      "memory usage: 199.3+ KB\n"
     ]
    }
   ],
   "source": [
    "sub.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "426fd0a48aacd01c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T14:18:25.281311Z",
     "start_time": "2024-02-09T14:18:25.266141Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv('./data/aggregated_llm_perf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9dcdbb512c96d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
